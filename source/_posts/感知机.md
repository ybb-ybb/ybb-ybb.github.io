---
date: 2020-05-10 10:02:00
description: 感知机
title: 感知机
author: 鱼摆摆
comments: true
tags: 
 - 感知机
photos: https://w.wallhaven.cc/full/r2/wallhaven-r2lm57.jpg
categories: 学习
---



1．感知机是根据输入实例的特征向量 $x$ 对其进行二类分类的线性分类模型：
$$
f(x)=(w \cdot x + b)
$$
感知机模型对应于输入空间（特征空间）中的分离超平面 $w \cdot x+b=0$

2．感知机学习的策略是极小化损失函数：
$$
\min _{w, b} L(w, b)=-\sum_{x_{i} \in M} y_{i}\left(w \cdot x_{i}+b\right)
$$
对应于误分类点到分离超平面的总距离。

# 原始形式：

误分类点集合$M$ ，损失函数$L(w,b)$ 的梯度由
$$
\begin{array}{l}
\nabla_{w} L(w, b)=-\sum_{x_{i} \in M} y_{i} x_{i} \\
\nabla_{b} L(w, b)=-\sum_{x_{i} \in M} y_{i}
\end{array}
$$
给出

随机选取一个误分类点$(x_i,y_i)$ ，对$w,b$ 进行更新（$\eta$ 为学习率）：
$$
\begin{array}{c}
w \leftarrow w+\eta y_{i} x_{i} \\
b \leftarrow b+\eta y_{i}
\end{array}
$$
**收敛性：**

设训练数据集$T=\left\{\left(x_{1}, y_{1}\right),\left(x_{2}, y_{2}\right), \cdots,\left(x_{N}, y_{N}\right)\right\}$ 是线性可分的，其中$x_{i} \in \mathcal{X}=\mathbf{R}^{n}, \quad y_{i} \in \mathcal{Y}=\{-1,+1\}, \quad i=1,2, \cdots, N$。则：

(1) 存在满足条件$\|\hat w _{opt}\|=1$的超平面$\hat{w}_{opt} \cdot \hat{x}=w_{opt} \cdot x+b_{opt}=0$将训练数据集完全正确分开；且存在$\gamma > 0$，对所有$i=1,2,…,N$
$$
y_{i}\left(\hat{w}_{opt} \cdot \hat{x}_{i}\right)=y_{i}\left(w_{opt} \cdot x_{i}+b_{opt}\right) \ge \gamma
$$
(2) 令$R=\max _{1 \leqslant i\leqslant N }\left\|\hat{x}_{i}\right\|$ ,则原始感知机算法在训练数据集上的误分类次数$k$ 满足：
$$
k \leqslant\left(\frac{R}{\gamma}\right)^{2}
$$

# 对偶形式

最后学习到的$w,b$ 可以表示为
$$
\begin{array}{l}
w=\sum_{i=1}^{N} \alpha_{i} y_{i} x_{i} \\
b=\sum_{i=1}^{N} \alpha_{i} y_{i}
\end{array}
$$
如果$y_{i}\left(\sum_{j=1}^{N} \alpha_{j} y_{j} x_{j} \cdot x_{i}+b\right) \leqslant 0$
$$
\begin{array}{l}
\alpha_{i} \leftarrow \alpha_{i}+\eta \\
b \leftarrow b+\eta y_{i}
\end{array}
$$
