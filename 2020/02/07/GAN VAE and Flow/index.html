<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <meta name="description" content="前言GAN，VAE和FLOW的目标是一致的——希望构建一个从隐变量$Z$生成目标数据$X$的模型，其中先验分布$P(z)$通常被设置为高斯分布。我们希望找到一个变换函数$f(x)$，他能建立一个从$z$到$x$的映射：$f:z\to x$，然后在$P(Z)$中随机采样一个点$z’$，通过映射$f$，" />
  

  
  
  
  
  
  
  <title>GAN VAE and Flow | 鱼摆摆的blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="前言GAN，VAE和FLOW的目标是一致的——希望构建一个从隐变量$Z$生成目标数据$X$的模型，其中先验分布$P(z)$通常被设置为高斯分布。我们希望找到一个变换函数$f(x)$，他能建立一个从$z$到$x$的映射：$f:z\to x$，然后在$P(Z)$中随机采样一个点$z’$，通过映射$f$，就可以找到一个新的样本点$x’$。    举个栗子： 如何将均匀分布$U[0,1]$映射成正态分布$">
<meta property="og:type" content="article">
<meta property="og:title" content="GAN VAE and Flow">
<meta property="og:url" content="http://yoursite.com/2020/02/07/GAN%20VAE%20and%20Flow/index.html">
<meta property="og:site_name" content="鱼摆摆的blog">
<meta property="og:description" content="前言GAN，VAE和FLOW的目标是一致的——希望构建一个从隐变量$Z$生成目标数据$X$的模型，其中先验分布$P(z)$通常被设置为高斯分布。我们希望找到一个变换函数$f(x)$，他能建立一个从$z$到$x$的映射：$f:z\to x$，然后在$P(Z)$中随机采样一个点$z’$，通过映射$f$，就可以找到一个新的样本点$x’$。    举个栗子： 如何将均匀分布$U[0,1]$映射成正态分布$">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://i.loli.net/2020/02/06/LpCERGiuF4ahBDN.png">
<meta property="og:image" content="https://i.loli.net/2020/02/07/a8ofIEU4XyZdRL2.png">
<meta property="article:published_time" content="2020-02-07T13:02:16.651Z">
<meta property="article:modified_time" content="2020-02-07T13:32:03.650Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://i.loli.net/2020/02/06/LpCERGiuF4ahBDN.png">
  
  
    <link rel="icon" href="/css/images/favicon.ico">
  
  
<link rel="stylesheet" href="/css/style.css">

  

  
  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script>
<meta name="generator" content="Hexo 4.2.0"></head>
<body class="home blog custom-background custom-font-enabled single-author">
  <div id="page" class="hfeed site">
      <header id="masthead" class="site-header" role="banner">
    <hgroup>
      <h1 class="site-title">
        <a href="/" title="鱼摆摆的blog" rel="home">鱼摆摆的blog</a>
      </h1>
      
        <h2 class="site-description hitokoto"></h2>
        <script type="text/javascript" src="https://v1.hitokoto.cn/?encode=js"></script>
      
    </hgroup>

    <nav id="site-navigation" class="main-navigation" role="navigation">
            <button class="menu-toggle">菜单</button>
            <a class="assistive-text" href="/#content" title="跳至内容">跳至内容</a><!--TODO-->
            <div class="menu-main-container">
                <ul id="menu-main" class="nav-menu">
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/">Home</a></li>
                
                    <li class="menu-item menu-item-type-post_type menu-item-object-page"><a href="/archives">Archives</a></li>
                
                </ul>
            </div>
    </nav>
</header>

      <div id="main" class="wrapper">
        <div id="primary" class="site-content"><div id="content" role="main"><article id="post-GAN VAE and Flow" class="post-GAN VAE and Flow post type-post status-publish format-standard hentry">
    <!---->

      <header class="entry-header">
        
        
  
    <h1 class="entry-title article-title">
      GAN VAE and Flow
    </h1>
  

        
        <div class="comments-link">
            
            <a href="javascript:void(0);" data-url="http://yoursite.com/2020/02/07/GAN%20VAE%20and%20Flow/" data-id="ck6c7ln340000ae5we0bj8yii" class="leave-reply bdsharebuttonbox" data-cmd="more">Share</a>
        </div><!-- .comments-link -->
      </header><!-- .entry-header -->

    <div class="entry-content">
      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>GAN，VAE和FLOW的目标是一致的——希望构建一个从隐变量$Z$生成目标数据$X$的模型，其中先验分布$P(z)$通常被设置为高斯分布。我们希望找到一个变换函数$f(x)$，他能建立一个从$z$到$x$的映射：$f:z\to x$，然后在$P(Z)$中随机采样一个点$z’$，通过映射$f$，就可以找到一个新的样本点$x’$。  </p>
<p><img src="https://i.loli.net/2020/02/06/LpCERGiuF4ahBDN.png" alt="image.png"></p>
<p>举个栗子：</p>
<p>如何将均匀分布$U[0,1]$映射成正态分布$N(0,1)$？</p>
<p>将$X \sim U[0,1]$经过函数$Y = f(x)$映射之后，就有$Y\sim N(0,1)$了那么$[x,x+dx]$和$[y,y+dy]$两个区间上的概率应该相等，即：</p>
<script type="math/tex; mode=display">
\rho(x) d x=\frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{y^{2}}{2}\right) d y</script><p>对其进行积分，有：</p>
<script type="math/tex; mode=display">
\int_{0}^{x} \rho(t) d t=\int_{-\infty}^{y} \frac{1}{\sqrt{2 \pi}} \exp \left(-\frac{t^{2}}{2}\right) d t=\Phi(y)</script><script type="math/tex; mode=display">
y=\Phi^{-1}\left(\int_{0}^{x} \rho(t) d t\right)=f(x)</script><p>可以看到$Y = f(X)$的解是存在的，但很复杂，无法用初等函数进行显示的表示，因此在大多数情况下，我们都是通过神经网络来拟合这个函数。</p>
<p>假设我们现在已经有一个映射$f$，我们如何衡量映射$f$构造出来的数据集$f(z_1),f(z_2),…,f(z_n)$，是否和目标数据$X$分布相同？(注：KL和JS距离根据两个概率分布的表达式计算分布的相似度，而我们现在只有从构造的分布采样的数据和真实分布采样的数据，而离散化的KL和JS距离因为图像维度问题，计算量非常大)。在这里GAN采用了一个暴力的办法：训练一个判别器作为两者相似性的度量，而VAE(变分自编码器)和FLOW(流模型)在最大化最大似然。</p>
<h1 id="VAE-变分自编码器"><a href="#VAE-变分自编码器" class="headerlink" title="VAE(变分自编码器)"></a>VAE(变分自编码器)</h1><h2 id="VAE的基本思路"><a href="#VAE的基本思路" class="headerlink" title="VAE的基本思路"></a>VAE的基本思路</h2><p>对于连续随机变量，概率分布$P$和$Q$，KL散度(又称相对熵)的定义为：</p>
<script type="math/tex; mode=display">
D_{\mathrm{KL}}(P \| Q)=\int_{-\infty}^{\infty} p(x) \ln \frac{p(x)}{q(x)} \mathrm{d} x=E_{x \sim P(x)}[logP(x)-logQ(x)]</script><p>给定一个概率分布$D$,已知其概率密度函数(连续分布)或概率质量函数()离散分布为$f_D$，以及一个分布参数$\theta$，我们可以从这个分布中抽出一个具有$n$个值的采样$X_1,X_2,…,X_n$，利用$f_D$计算出其似然函数：</p>
<script type="math/tex; mode=display">
\mathbf{L}\left(\theta | x_{1}, \ldots, x_{n}\right)=f_{\theta}\left(x_{1}, \ldots, x_{n}\right)</script><p> 若$D$是离散分布，$f_{\theta}$即是在参数为$\theta$时观测到这一采样的概率。若其是连续分布，$f_{\theta}$则为$X_1,X_2,…,X_n$联合分布的概率密度函数在观测值处的取值。一旦我们获得$X_1,X_2,…,X_n$，我们就能求得一个关于$\theta$的估计。最大似然估计会寻找关于的最可能的值（即，在所有可能的取值中，寻找一个值使这个采样的“可能性”最大化）。从数学上来说，我们可以在的所有可能取值中寻找一个值使得似然函数取到最大值。这个使可能性最大的值即称为的最大似然估计。由定义，最大似然估计是样本的函数。</p>
<p>VAE做最大似然估计，也就是要最大化概率：</p>
<script type="math/tex; mode=display">
P(X)=\sum_{i} P\left(X | z_{i} ; \theta\right) P\left(z_{i}\right)</script><p>这里可以理解为使用积分创造更多的分布，一般选择$P(Z)$服从一个高斯分布，而$p(X|z)$可以是任意分布，例如条件高斯分布或狄拉克分布，理论上讲，这个积分形式的分布可以拟合任意分布。</p>
<p>但是这里的$P(X)$是积分形式的，很难进行计算。VAE从让人望而生畏的变分和贝叶斯理论出发，推导出了一个很接地气的公式：</p>
<script type="math/tex; mode=display">
\log P(X)-\mathcal{D}[Q(z | X) \| P(z | X)]=E_{z \sim Q}[\log P(X | z)]-\mathcal{D}[Q(z | X) \| P(z)] \tag{1}</script><p>VAE并没有选择直接去优化$P(X)$，而是选择去优化他的一个变分下界（公式1右端）。</p>
<p>而VAE的自编码器性质也从这个公式里开始体现出来：我们可以将$\mathcal{D}[Q(z | X) | P(z)]$视作编码器的优化，使由真实数据编码出的隐变量分布$Q(z|X)$去尽量近似$P(z)$（标准高斯分布），而将$E_{z \sim Q}[\log P(X | z)]$视作解码器的优化，使得服从分布$Q$的隐变量$z$解码出的$x$尽可能地服从真是数据分布，而将$\mathcal{D}[Q(z | X) | P(z | X)]$视作误差项。</p>
<p>但VAE也因为它并没有直接去优化$P(X)$，而选择去优化它的变分下界，使得他只是一个近似模型，无法保证良好的生成效果。</p>
<h2 id="VAE的优化过程"><a href="#VAE的优化过程" class="headerlink" title="VAE的优化过程"></a>VAE的优化过程</h2><p>首先要确定概率密度$Q(z|X)$的形式，一般选择正态分布，即$\mathcal{N}\left(\mu, \sigma^{2}\right)$，其中$\mu\left(X ; \theta_{\mu}\right) $和$\sigma^{2}\left(X ; \theta_{\sigma}\right)$通过两个神经网络(编码器)训练出来。公式中的$\mathcal{D}[Q(z | X) | P(z)]$变为$D\left[\mathcal{N}\left(\mu\left(X ; \theta_{\mu}\right), \sigma^{2}\left(X ; \theta_{\sigma}\right)\right) | \mathcal{N}(0, I)\right]$，这个时候就可以通过两个正态分布的KL散度的计算公式来计算这一项。</p>
<p>对于第一项$E_{z \sim Q}[\log P(X | z)]$，对于一个batch来说，可以在$Q$中采样，然后将单个样本的$\log P(X|z)$求和取平均数作为期望的估计。但这样出现一个问题：把$Q(z|X)$弄丢了，也就是每次训练的时候梯度不传进$Q$里，论文里采用了一个称为重参数化技巧(reparamenterization trick)的方法，如图：</p>
<p><img src="https://i.loli.net/2020/02/07/a8ofIEU4XyZdRL2.png" alt="image.png"></p>
<p>至此，整个VAE网络就可以训练了。</p>
<h2 id="公式推导部分"><a href="#公式推导部分" class="headerlink" title="公式推导部分"></a>公式推导部分</h2><script type="math/tex; mode=display">
\begin{align} \mathcal{D}[Q(z|X)||P(z|X)] &= E_{z \sim Q}[\log Q(z|X) - \log P(z|X)] \\ &= E_{z \sim Q}[\log Q(z|X) - \log P(z|X) - \log P(X)] + \log P(X) \end{align}</script><p>移项得</p>
<script type="math/tex; mode=display">
\log P(X)-\mathcal{D}[Q(z | X) \| P(z | X)]=E_{z \sim Q}[\log P(X | z)]-\mathcal{D}[Q(z | X) \| P(z)]</script><h1 id="GAN"><a href="#GAN" class="headerlink" title="GAN"></a>GAN</h1><p>由于大家都对GAN比较熟悉，本文直接从变分推断的角度去理解GAN。</p>
<p>不同于VAE将$P(X|z)$选为高斯分布，GAN的选择是：</p>
<script type="math/tex; mode=display">
P(x | z)=\delta(x-G(z)), \quad P(x)=\int P(x | z) P(z) d z</script><p>其中$\delta (x)$是狄拉克函数，$G(z)$为生成器网络。</p>
<p>在VAE中z被当作是一个隐变量，但在GAN中，狄拉克函数意味着单点分布，即x和z为一一对应的关系。于是在GAN中z没有被当作隐变量处理(不需要考虑后验分布$P(z|x)$)</p>
<p>判别器的理解：</p>
<p>在GAN中引入了一个二元的隐变量y来构成联合分布，其中$\tilde{p}(x)为真实样本的分布$：</p>
<script type="math/tex; mode=display">
q(x, y)=\left\{\begin{array}{l}
{\tilde{p}(x) p_{1}, y=1} \\
{p(x) p_{0}, y=0}
\end{array}\right.</script><p>这里y是图像的真实标签，当图片为真实图片时，y=1，当图片是生成图片时，y=0。</p>
<p>其中$p_1+p_0=1$描述了一个二元概率分布，比如：从真实样本采集m个样本，从生成样本中采集m个样本，同时传入判别器，则$p_0=p_1=1/2$。在下面讨论中我们直接取$p_0=p_1=1/2$</p>
<p>另一方面，我们需要使判别器的判别结果尽可能真实，设$p(x,y)=p(y|x)\tilde{p}(x)$，$p(y|x)$为一个条件伯努利分布(判别器的判别结果)。优化目标是$KL(q(x,y)||p(x,y))$：</p>
<script type="math/tex; mode=display">
\begin{aligned}
K L(q(x, y) \| p(x, y)) &=\int \tilde{p}(x) p_{1} \log \frac{\tilde{p}(x) p_{1}}{p(1 | x) \tilde{p}(x)} d x+\int p(x) p_{0} \log \frac{p(x) p_{0}}{p(0 | x) \tilde{p}(x)} d x \\
& \sim \int \tilde{p}(x) \log \frac{1}{p(1 | x)} d x+\int p(x) \log \frac{p(x)}{p(0 | x) \tilde{p}(x)} d x
\end{aligned}</script><p>一旦成功优化，就有$q(x,y)\to p(x,y)$，对于x求边缘概率分布，有：</p>
<script type="math/tex; mode=display">
\frac{1}{2}\tilde{p}(x)+\frac{1}{2}p(x)\to p(1|x)\tilde{p}(x)+p(0|x)\tilde{p}(x)=\tilde{p}(x)</script><p>即：</p>
<script type="math/tex; mode=display">
p(x)\to \tilde{p}(x)</script><p>这就完成了对模型的构建。</p>
<p>不太理解为什么要选择这个优化目标……待补充</p>
<p>现在我们有优化目标：$p(y|x)$和$G(z)$，分别是判别器和生成器($p(x)$由$G(z)$决定)。</p>

      
    </div><!-- .entry-content -->

    <footer class="entry-meta">
    <a href="/2020/02/07/GAN%20VAE%20and%20Flow/">
    <time datetime="2020-02-07T13:02:16.651Z" class="entry-date">
        2020-02-07
    </time>
</a>
    
    
    </footer>
</article>


    
<nav class="nav-single">
    <h3 class="assistive-text">文章导航</h3>
    
    
        <span class="nav-next"><a href="/2020/02/07/Emacs%E7%AC%94%E8%AE%B0/" rel="next">Emacs笔记 <span class="meta-nav">→</span></a></span>
    
</nav><!-- .nav-single -->







</div></div>
        <div id="secondary" class="widget-area" role="complementary">
  
    <aside id="search" class="widget widget_search"><form role="search" method="get" accept-charset="utf-8" id="searchform" class="searchform" action="//google.com/search">
    <div>
        <input type="text" value="" name="s" id="s" />
        <input type="submit" id="searchsubmit" value="搜索" />
    </div>
</form></aside>
  
    
  
    
  
    
  <aside class="widget">
    <h3 class="widget-title">Recents</h3>
    <div class="widget-content">
      <ul>
        
          <li>
            <a href="/2020/02/07/GAN%20VAE%20and%20Flow/">GAN VAE and Flow</a>
          </li>
        
          <li>
            <a href="/2020/02/07/Emacs%E7%AC%94%E8%AE%B0/">Emacs笔记</a>
          </li>
        
          <li>
            <a href="/2020/01/28/%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91/">科学上网</a>
          </li>
        
          <li>
            <a href="/2020/01/28/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8tensorboard%E5%92%8Cvisdom/">服务器使用tensorboard和visdom</a>
          </li>
        
          <li>
            <a href="/2020/01/28/shell%E8%84%9A%E6%9C%AC/">shell脚本</a>
          </li>
        
      </ul>
    </div>
  </aside>

  
    
  
    
  
</div>
      </div>
      <footer id="colophon" role="contentinfo">
    <p>&copy; 2020 John Doe
    All rights reserved.</p>
    <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</footer>
    <script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='/js/share.js'];</script>

<script src="/js/jquery-3.3.1.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>




<script src="/js/script.js"></script>


<script src="/js/navigation.js"></script>

<div id="bg"></div>

  </div>
</body>
</html>