{"meta":{"title":"鱼摆摆的blog","subtitle":null,"description":"自童年起，我就独自一人，照顾着历代星辰","author":"鱼摆摆","url":""},"pages":[{"title":"comment","date":"2018-12-20T15:13:48.000Z","updated":"2020-02-14T09:11:23.000Z","comments":true,"path":"comment/index.html","permalink":"/comment/index.html","excerpt":"","text":"念两句诗 叙别梦、扬州一觉。 【宋代】吴文英《夜游宫·人去西楼雁杳》","keywords":"留言板"},{"title":"about","date":"2018-12-12T14:14:36.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"about/index.html","permalink":"/about/index.html","excerpt":"","text":"[さくら荘のhojun] 与&nbsp; Mashiro&nbsp; （ 真（ま）白（しろ） ） 对话中... bot_ui_ini()","keywords":"关于"},{"title":"bangumi","date":"2019-02-10T13:32:48.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"bangumi/index.html","permalink":"/bangumi/index.html","excerpt":"","text":"","keywords":null},{"title":"donate","date":"2018-12-20T15:13:05.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"donate/index.html","permalink":"/donate/index.html","excerpt":"","text":"","keywords":"谢谢饲主了喵~"},{"title":"client","date":"2018-12-20T15:13:35.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"client/index.html","permalink":"/client/index.html","excerpt":"","text":"直接下载 or 扫码下载：","keywords":"Android客户端"},{"title":"lab","date":"2019-01-05T13:47:59.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"lab/index.html","permalink":"/lab/index.html","excerpt":"","text":"sakura主题 balabala","keywords":"Lab实验室"},{"title":"rss","date":"2018-12-20T15:09:03.000Z","updated":"2020-02-14T09:11:23.000Z","comments":true,"path":"rss/index.html","permalink":"/rss/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-12-12T14:14:16.000Z","updated":"2020-02-14T09:11:23.000Z","comments":true,"path":"tags/index.html","permalink":"/tags/index.html","excerpt":"","text":""},{"title":"theme-sakura","date":"2019-01-04T14:53:25.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"theme-sakura/index.html","permalink":"/theme-sakura/index.html","excerpt":"","text":"Hexo主题Sakura修改自WordPress主题Sakura，感谢原作者Mashiro","keywords":"Hexo 主题 Sakura 🌸"},{"title":"video","date":"2018-12-20T15:14:38.000Z","updated":"2020-02-14T09:11:23.000Z","comments":false,"path":"video/index.html","permalink":"/video/index.html","excerpt":"","text":"var videos = [ { img: 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '放送时间: 2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' }, { img : 'https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg', title: '朝花夕誓——于离别之朝束起约定之花', status: '已追完', progress: 100, jp: 'さよならの朝に約束の花をかざろう', time: '2018-02-24 SUN.', desc: ' 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。' } ] .should-ellipsis{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:95%;}.should-ellipsis-full{overflow:hidden;text-overflow:ellipsis;white-space:nowrap;width:100%;}.should-ellipsis i{position:absolute;right:24px;}.grey-text{color:#9e9e9e !important}.grey-text.text-darken-4{color:#212121 !important}html{line-height:1.15;-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}img{border-style:none}progress{display:inline-block;vertical-align:baseline}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}html{-webkit-box-sizing:border-box;box-sizing:border-box}*,*:before,*:after{-webkit-box-sizing:inherit;box-sizing:inherit}ul:not(.browser-default){padding-left:0;list-style-type:none}ul:not(.browser-default)>li{list-style-type:none}.card{-webkit-box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2);box-shadow:0 2px 2px 0 rgba(0,0,0,0.14),0 3px 1px -2px rgba(0,0,0,0.12),0 1px 5px 0 rgba(0,0,0,0.2)}.hoverable{-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s}.hoverable:hover{-webkit-box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19);box-shadow:0 8px 17px 0 rgba(0,0,0,0.2),0 6px 20px 0 rgba(0,0,0,0.19)}i{line-height:inherit}i.right{float:right;margin-left:15px}.bangumi .right{float:right !important}.material-icons{text-rendering:optimizeLegibility;-webkit-font-feature-settings:'liga';-moz-font-feature-settings:'liga';font-feature-settings:'liga'}.row{margin-left:auto;margin-right:auto;margin-bottom:20px}.row:after{content:\"\";display:table;clear:both}.row .col{float:left;-webkit-box-sizing:border-box;box-sizing:border-box;padding:0 .75rem;min-height:1px}.row .col.s12{width:100%;margin-left:auto;left:auto;right:auto}@media only screen and (min-width:601px){.row .col.m6{width:50%;margin-left:auto;left:auto;right:auto}}html{line-height:1.5;font-family:-apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;font-weight:normal;color:rgba(0,0,0,0.87)}@media only screen and (min-width:0){html{font-size:14px}}@media only screen and (min-width:992px){html{font-size:14.5px}}@media only screen and (min-width:1200px){html{font-size:15px}}.card{position:relative;margin:.5rem 0 1rem 0;background-color:#fff;-webkit-transition:-webkit-box-shadow .25s;transition:-webkit-box-shadow .25s;transition:box-shadow .25s;transition:box-shadow .25s,-webkit-box-shadow .25s;border-radius:2px}.card .card-title{font-size:24px;font-weight:300}.card .card-title.activator{cursor:pointer}.card .card-image{position:relative}.card .card-image img{display:block;border-radius:2px 2px 0 0;position:relative;left:0;right:0;top:0;bottom:0;width:100%}.card .card-content{padding:24px;border-radius:0 0 2px 2px}.card .card-content p{margin:0}.card .card-content .card-title{display:block;line-height:32px;margin-bottom:8px}.card .card-content .card-title i{line-height:32px}.card .card-reveal{padding:24px;position:absolute;background-color:#fff;width:100%;overflow-y:auto;left:0;top:100%;height:100%;z-index:3;display:none}.card .card-reveal .card-title{cursor:pointer;display:block}.waves-effect{position:relative;cursor:pointer;display:inline-block;overflow:hidden;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;-webkit-tap-highlight-color:transparent;vertical-align:middle;z-index:1;-webkit-transition:.3s ease-out;transition:.3s ease-out}.waves-effect img{position:relative;z-index:-1}.waves-block{display:block}::-webkit-input-placeholder{color:#d1d1d1}::-moz-placeholder{color:#d1d1d1}:-ms-input-placeholder{color:#d1d1d1}::-ms-input-placeholder{color:#d1d1d1}[type=\"radio\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"radio\"]:not(:checked)+span{position:relative;padding-left:35px;cursor:pointer;display:inline-block;height:25px;line-height:25px;font-size:1rem;-webkit-transition:.28s ease;transition:.28s ease;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border-radius:50%}[type=\"radio\"]:not(:checked)+span:before,[type=\"radio\"]:not(:checked)+span:after{border:2px solid #5a5a5a}[type=\"radio\"]:not(:checked)+span:after{-webkit-transform:scale(0);transform:scale(0)}[type=\"checkbox\"]:not(:checked){position:absolute;opacity:0;pointer-events:none}[type=\"checkbox\"]:not(:checked):disabled+span:not(.lever):before{border:none;background-color:rgba(0,0,0,0.42)}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):before{width:0;height:0;border:3px solid transparent;left:6px;top:10px;-webkit-transform:rotateZ(37deg);transform:rotateZ(37deg);-webkit-transform-origin:100% 100%;transform-origin:100% 100%}[type=\"checkbox\"].filled-in:not(:checked)+span:not(.lever):after{height:20px;width:20px;background-color:transparent;border:2px solid #5a5a5a;top:0px;z-index:0}input[type=checkbox]:not(:disabled) ~ .lever:active:before,input[type=checkbox]:not(:disabled).tabbed:focus ~ .lever::before{-webkit-transform:scale(2.4);transform:scale(2.4);background-color:rgba(0,0,0,0.08)}input[type=range].focused:focus:not(.active)::-webkit-slider-thumb{-webkit-box-shadow:0 0 0 10px rgba(38,166,154,0.26);box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-moz-range-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)}input[type=range].focused:focus:not(.active)::-ms-thumb{box-shadow:0 0 0 10px rgba(38,166,154,0.26)} 番组计划 这里将是永远的回忆 window.onload = function(){ videos.forEach(function(video, i){ $('#rootRow').append(` ${video.title} ${video.jp} ${video.status} ${video.title} ${video.jp} 放送时间: ${video.time} ${video.desc} ${video.status} `) }) }","keywords":"B站"},{"title":"music","date":"2020-01-11T15:14:28.000Z","updated":"2020-03-09T12:35:33.243Z","comments":false,"path":"music/index.html","permalink":"/music/index.html","excerpt":"","text":"","keywords":"喜欢的音乐"},{"title":"links","date":"2018-12-19T15:11:06.000Z","updated":"2020-03-09T12:29:18.823Z","comments":true,"path":"links/index.html","permalink":"/links/index.html","excerpt":"","text":"","keywords":"友人帐"}],"posts":[{"title":"实验室NAS挂载教程","slug":"实验室NAS设备挂载教程","date":"2020-11-21T12:22:00.000Z","updated":"2020-11-21T12:58:55.812Z","comments":true,"path":"2020/11/21/实验室NAS设备挂载教程/","link":"","permalink":"/2020/11/21/实验室NAS设备挂载教程/","excerpt":"The article has been encrypted, please enter your password to view.","text":"Please enter the password to read the blog. Incorrect Password! No content to display! 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","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"/tags/服务器/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"现代微分几何","slug":"现代微分几何","date":"2020-09-24T08:42:00.000Z","updated":"2020-09-24T11:24:43.862Z","comments":true,"path":"2020/09/24/现代微分几何/","link":"","permalink":"/2020/09/24/现代微分几何/","excerpt":"","text":"光滑流形的定义，会用定义证明某些拓扑空间是光滑流形。 设MMM 是mmm 维拓扑流形，A\\mathcal{A}A 是MMM 的一个CrC^rCr 微分结构，则称(M,A)(M,\\mathcal{A})(M,A) 是一个mmm 维CrC^rCr 微分流形。特别地，C∞C^{\\infty}C∞ 微分结构称为光滑结构， C∞C^{\\infty}C∞ 微分流形称为光滑流形。 证明某些拓扑空间是CrC^rCr 微分流形(或光滑流形)： (1). 证明MMM是Hausdorff空间(拓扑空间上的任意两点可由其邻域分离) (2). 证明MMM是mmm 维拓扑流形(每一点xxx 存在其邻域UUU, UUU是MMM上的开邻域，UUU同胚于RmR^mRm的开集) (3). 构造MMM的CrC^rCr 微分结构(或光滑结构)A\\mathcal{A}A (A={(Uα,φα)∣α∈I}\\mathcal{A}=\\{(U_{\\alpha},\\varphi_{\\alpha})|\\alpha \\in I\\}A={(Uα​,φα​)∣α∈I}，满足Uα∣α∈IU_{\\alpha}|\\alpha \\in IUα​∣α∈I 是M的开覆盖、$\\left(U_{\\alpha}, \\varphi_{\\alpha}\\right) $和 (Uβ,φβ)\\left(U_{\\beta}, \\varphi_{\\beta}\\right)(Uβ​,φβ​)相容、A\\mathcal{A}A是极大的) 参考例1.2和例1.6 例1.2 Rm+1\\mathcal{R}^{m+1}Rm+1中的单位球面Sm={(x1,⋯ ,xm+1)}∈Rm+1∣∑i=1m+1(xi)2=1S^m = \\{(x^1,\\cdots,x^{m+1})\\}\\in \\mathbb{R}^{m+1}|\\sum_{i=1}^{m+1}(x^i)^2=1Sm={(x1,⋯,xm+1)}∈Rm+1∣∑i=1m+1​(xi)2=1 (1).证明SmS^mSm是Hausdroff空间 取其拓扑为它在Rm+1\\mathcal{R}^{m+1}Rm+1中的相对拓扑，则其是一个具有可数基的Hausdroff空间。 (2)证明SmS^mSm是拓扑流形 (i)相对开集的选取： 记 Uˉi+={(x1,⋯ ,xm+1)∣xi&gt;0}Uˉi−={(x1,⋯ ,xm+1)∣xi&lt;0},i=1,⋯ ,m+1\\begin{array}{c} \\bar{U}_{i}^{+}=\\left\\{\\left(x^{1}, \\cdots, x^{m+1}\\right) \\mid x^{i}&gt;0\\right\\} \\\\ \\bar{U}_{i}^{-}=\\left\\{\\left(x^{1}, \\cdots, x^{m+1}\\right) \\mid x^{i}&lt;0\\right\\}, \\quad i=1, \\cdots, m+1 \\end{array} Uˉi+​={(x1,⋯,xm+1)∣xi&gt;0}Uˉi−​={(x1,⋯,xm+1)∣xi&lt;0},i=1,⋯,m+1​ 他们都是Rm+1\\mathcal{R}^{m+1}Rm+1 中的开集，则相对开集Ui±=Uˉi±∩Sm(i=1,⋯ ,m+1) U_{i}^{\\pm}=\\bar{U}_{i}^{\\pm} \\cap S^{m}(i=1, \\cdots, m+1) Ui±​=Uˉi±​∩Sm(i=1,⋯,m+1) 构成SmS^mSm 的开覆盖。 (ii)每一个相对开集与$ R^m$中的开集同胚 如下定义φi±:Ui±→Rm\\varphi_{i}^{\\pm}:U_{i}^{\\pm} \\to \\mathcal{R}^mφi±​:Ui±​→Rm φi±(x1,⋯ ,xm+1)=(x1,⋯ ,xi,⋯ ,xm+1)\\varphi_{i}^{\\pm}\\left(x_{1}, \\cdots, x^{m+1}\\right)=\\left(x_{1}, \\cdots, x^{i}, \\cdots, x^{m+1}\\right) φi±​(x1​,⋯,xm+1)=(x1​,⋯,xi,⋯,xm+1) 其中^表示 去掉该坐标，易见这些映射分别是Ui±U_{i}^{\\pm}Ui±​到Rm\\mathbb{R}^mRm的开集 Wi={(x1,⋯ ,x^i,⋯ ,xm+1)∈Rm∣(x1)2+⋯+(x^i)2+⋯+(xm+1)2&lt;1}W_{i}=\\left\\{\\left(x_{1}, \\cdots, \\hat{x}^{i}, \\cdots, x^{m+1}\\right) \\in \\mathbb{R}^{m} \\mid\\left(x^{1}\\right)^{2}+\\cdots+\\left(\\hat{x}^{i}\\right)^{2}+\\cdots+\\left(x^{m+1}\\right)^{2}&lt;1\\right\\} Wi​={(x1​,⋯,x^i,⋯,xm+1)∈Rm∣(x1)2+⋯+(x^i)2+⋯+(xm+1)2&lt;1} 的同胚，因此SmS^mSm是mmm维拓扑流形。 (3)证明光滑结构，开覆盖在(2)中满足，关键是证明坐标卡的相容性 考虑φ2−∘(φ1+)−1:φ1+(U2−∩U1+)→φ2−(U2−∩U1+)\\varphi_{2}^{-} \\circ\\left(\\varphi_{1}^{+}\\right)^{-1}: \\varphi_{1}^{+}\\left(U_{2}^{-} \\cap U_{1}^{+}\\right) \\rightarrow \\varphi_{2}^{-}\\left(U_{2}^{-} \\cap U_{1}^{+}\\right)φ2−​∘(φ1+​)−1:φ1+​(U2−​∩U1+​)→φ2−​(U2−​∩U1+​) φ2−∘(φ1+)−1(x2,⋯ ,xm+1)=φ2−([1−∑i=2m+1(xi)2]12,x2,⋯ ,xm+1)=([1−∑i=2m+1(xi)2]12,x3,⋯ ,xm+1)\\varphi_{2}^{-} \\circ\\left(\\varphi_{1}^{+}\\right)^{-1}\\left(x^{2}, \\cdots, x^{m+1}\\right)=\\varphi_{2}^{-}\\left(\\left[1-\\sum_{i=2}^{m+1}\\left(x^{i}\\right)^{2}\\right]^{\\frac{1}{2}}, x^{2}, \\cdots, x^{m+1}\\right)=\\left(\\left[1-\\sum_{i=2}^{m+1}\\left(x^{i}\\right)^{2}\\right]^{\\frac{1}{2}}, x^{3}, \\cdots, x^{m+1}\\right) φ2−​∘(φ1+​)−1(x2,⋯,xm+1)=φ2−​⎝⎛​[1−i=2∑m+1​(xi)2]21​,x2,⋯,xm+1⎠⎞​=⎝⎛​[1−i=2∑m+1​(xi)2]21​,x3,⋯,xm+1⎠⎞​ 若用(u1,⋯ ,um)(u^1,\\cdots,u^m)(u1,⋯,um)记U1+U^+_1U1+​ 上点的坐标，用(u1,⋯ ,um)(u^1,\\cdots,u^m)(u1,⋯,um)记U2−U^-_2U2−​上点的坐标，则φ2−∘(φ1+)−1\\varphi_{2}^{-} \\circ\\left(\\varphi_{1}^{+}\\right)^{-1}φ2−​∘(φ1+​)−1的坐标表达式为 v1=[1−∑i=1m(ui)2]12,vl=ul,l=2,⋯ ,mv^{1}=\\left[1-\\sum_{i=1}^{m}\\left(u^{i}\\right)^{2}\\right]^{\\frac{1}{2}}, \\quad v^{l}=u^{l}, l=2, \\cdots, m v1=[1−i=1∑m​(ui)2]21​,vl=ul,l=2,⋯,m 显然vi(i=1,⋯ ,m)v^i(i=1,\\cdots,m)vi(i=1,⋯,m)是uj(j=1,⋯ ,m)u^j(j=1,\\cdots,m)uj(j=1,⋯,m)的光滑函数，从而坐标卡(U1+,φ1+)(U^+_1,\\varphi^+_1)(U1+​,φ1+​) 和(U2−,φ2−)(U^-_2,\\varphi^-_2)(U2−​,φ2−​)是C∞C^\\inftyC∞相容的，同理可证，坐标卡(Ui±,φi±)(U^{\\pm}_i,\\varphi^{\\pm}_i)(Ui±​,φi±​)是 C∞C^\\inftyC∞相容的，SmS^mSm是mmm维光滑流形。 例1.6 mmm维实射影空间RPm\\mathbb{R}P^mRPm 用RPm\\mathbb{R}P^mRPm表示Rm+1\\mathbb{R}^{m+1}Rm+1中过原点的直线的集合，下面在RPm\\mathbb{R}P^mRPm上引入微分结构，使之成为一个mmm维光滑流形。 (1) 证明RPm\\mathbb{R}P^mRPm是拓扑流形 (i) 拓扑关系的构建 首先在X=Rm+1\\0X = \\mathbb{R}^{m+1} \\backslash {0}X=Rm+1\\0 上定义等价关系∼\\thicksim∼如下： 对任意x=(x1,⋯ ,xm+1),y=(y1,⋯ ,ym+1),x∼yx = (x^1,\\cdots,x^{m+1}),y = (y^1,\\cdots,y^{m+1}),x\\sim yx=(x1,⋯,xm+1),y=(y1,⋯,ym+1),x∼y 当且仅当存在非零实数λ\\lambdaλ，使得y=λxy = \\lambda xy=λx，易见RPm\\mathbb{R}P^mRPm 可以等同XXX 关于等价关系∼\\sim∼ 的商空间，即 RPm=X/∼\\mathbb{R}P^m = X/\\sim RPm=X/∼ 用[x][x][x]表示点x=(x1,∼,xm+1)∈Xx = (x^1,\\sim,x^{m+1})\\in Xx=(x1,∼,xm+1)∈X 所在的等价类，则有 RPm={[x]∣x=(x1,⋯ ,xm+1)∈X}\\mathbb{R} P^{m}=\\left\\{[x] \\mid x=\\left(x^{1}, \\cdots, x^{m+1}\\right) \\in X\\right\\} RPm={[x]∣x=(x1,⋯,xm+1)∈X} 商映射记作π\\piπ ，RPm\\mathbb{R}P^mRPm上的拓扑为商拓扑，即U⊂RPmU \\subset \\mathbb{R}P^mU⊂RPm为开集当且仅当π−1(U)\\pi^{-1}(U)π−1(U)是XXX的开集。通常把xxx的坐标(x1,⋯ ,xm+2)(x^1,\\cdots,x^{m+2})(x1,⋯,xm+2)称为RPm\\mathbb{R}P^mRPm 中点[x][x][x]的齐次坐标，显然，一个点的齐次坐标不是唯一的，并且当xα≠0x^{\\alpha}\\ne 0xα​=0 s时，总有 [(x1,⋯ ,xm+1)]=[(x1/xα,⋯ ,xα−1/xα,1,xα+1/xα,⋯ ,xm+1/xα)]\\left[\\left(x^{1}, \\cdots, x^{m+1}\\right)\\right]=\\left[\\left(x^{1} / x^{\\alpha}, \\cdots, x^{\\alpha-1} / x^{\\alpha}, 1, x^{\\alpha+1} / x^{\\alpha}, \\cdots, x^{m+1} / x^{\\alpha}\\right)\\right] [(x1,⋯,xm+1)]=[(x1/xα,⋯,xα−1/xα,1,xα+1/xα,⋯,xm+1/xα)] (ii)开集、有限开覆盖选取，与Rm\\mathbb{R}^mRm 的同胚关系证明 如下定义RPm\\mathbb{R}P^mRPm 的m+1m+1m+1个开子集 Vα={[(x1,⋯ ,xm+1)]∈RPm∣xα≠0},α=1,⋯ ,m+1V_{\\alpha}=\\left\\{\\left[\\left(x^{1}, \\cdots, x^{m+1}\\right)\\right] \\in \\mathbb{R} P^{m} \\mid x^{\\alpha} \\neq 0\\right\\}, \\alpha=1, \\cdots, m+1 Vα​={[(x1,⋯,xm+1)]∈RPm∣xα​=0},α=1,⋯,m+1 并定义映射 φα:Vα→Rm,α=1,⋯ ,m+1\\varphi_{\\alpha}: V_{\\alpha} \\rightarrow \\mathbb{R}^{m}, \\alpha=1, \\cdots, m+1 φα​:Vα​→Rm,α=1,⋯,m+1 为 (ξ1,⋯ ,ξm)=φα([(x1,⋯ ,xm+1)])=(x1/xα,⋯ ,xα−1/xα,xα+1/xα,⋯ ,xm+1/xα)\\left(\\xi^{1}, \\cdots, \\xi^{m}\\right)=\\varphi_{\\alpha}\\left(\\left[\\left(x^{1}, \\cdots, x^{m+1}\\right)\\right]\\right)=\\left(x^{1} / x^{\\alpha}, \\cdots, x^{\\alpha-1} / x^{\\alpha}, x^{\\alpha+1} / x^{\\alpha}, \\cdots, x^{m+1} / x^{\\alpha}\\right) (ξ1,⋯,ξm)=φα​([(x1,⋯,xm+1)])=(x1/xα,⋯,xα−1/xα,xα+1/xα,⋯,xm+1/xα) 其中[(x1,⋯ ,xm+1)]∈Vα[(x^1,\\cdots,x^{m+1})]\\in V_{\\alpha}[(x1,⋯,xm+1)]∈Vα​ .易见φα\\varphi_{\\alpha}φα​是完全确定的，并且是从VαV_{\\alpha}Vα​到Rm\\mathbb{R}^mRm的同胚。 (2)光滑结构的证明 所以(Vα,φα)(V_{\\alpha},\\varphi_{\\alpha})(Vα​,φα​)是RPm\\mathbb{R}P^mRPm 的一个坐标卡，相应的局部坐标(η1,⋯ ,ηm)\\left(\\boldsymbol{\\eta}^{1}, \\cdots, \\boldsymbol{\\eta}^{m}\\right)(η1,⋯,ηm) 通常称为RPm\\mathbb{R}P^mRPm的非齐次坐标，当Vα∩Vβ≠∅V_{\\alpha} \\cap V_{\\beta} \\ne \\emptysetVα​∩Vβ​​=∅时(不妨设α&gt;β\\alpha &gt; \\betaα&gt;β) ,局部坐标变换 (η1,⋯ ,ηm)=φβ∘φα−1(ξ1,⋯ ,ξm),ξβ≠0\\left(\\eta^{1}, \\cdots, \\eta^{m}\\right)=\\varphi_{\\beta} \\circ \\varphi_{\\alpha}^{-1}\\left(\\xi^{1}, \\cdots, \\xi^{m}\\right), \\xi^{\\beta} \\neq 0 (η1,⋯,ηm)=φβ​∘φα−1​(ξ1,⋯,ξm),ξβ​=0 为 η1=ξ1/ξβ,⋯ ,ηβ−1=ξβ−1/ξβ,ηβ=ξβ+1/ξβ,⋯ηα−2=ξα−1/ξβ,ηα−1=1/ξβ,ηα=ξα/ξβ,⋯ ,ηm=ξm/ξβ\\begin{aligned} \\eta^{1} &amp;=\\xi^{1} / \\xi^{\\beta}, \\cdots, \\eta^{\\beta-1}=\\xi^{\\beta-1} / \\xi^{\\beta}, \\eta^{\\beta}=\\xi^{\\beta+1} / \\xi^{\\beta}, \\cdots \\\\ \\eta^{\\alpha-2} &amp;=\\xi^{\\alpha-1} / \\xi^{\\beta}, \\eta^{\\alpha-1}=1 / \\xi^{\\beta}, \\eta^{\\alpha}=\\xi^{\\alpha} / \\xi^{\\beta}, \\cdots, \\eta^{m}=\\xi^{m} / \\xi^{\\beta} \\end{aligned} η1ηα−2​=ξ1/ξβ,⋯,ηβ−1=ξβ−1/ξβ,ηβ=ξβ+1/ξβ,⋯=ξα−1/ξβ,ηα−1=1/ξβ,ηα=ξα/ξβ,⋯,ηm=ξm/ξβ​ 他们都是(ξ1,⋯ ,ξm)(\\xi^1,\\cdots,\\xi^m)(ξ1,⋯,ξm)的光滑函数，因而 φβ∘φα−1:φα(Vα∩Vβ)→φβ(Vα∩Vβ)\\varphi_{\\beta} \\circ \\varphi_{\\alpha}^{-1}: \\varphi_{\\alpha}\\left(V_{\\alpha} \\cap V_{\\beta}\\right) \\rightarrow \\varphi_{\\beta}\\left(V_{\\alpha} \\cap V_{\\beta}\\right) φβ​∘φα−1​:φα​(Vα​∩Vβ​)→φβ​(Vα​∩Vβ​) 是光滑映射，从而{(Vα,φα)∣α=1,⋯ ,m+1}\\{(V_{\\alpha},\\varphi_{\\alpha})|\\alpha = 1,\\cdots,m+1\\}{(Vα​,φα​)∣α=1,⋯,m+1}是RPm\\mathbb{R}P^mRPm上的一个光滑结构，使得RPm\\mathbb{R}P^mRPm为一个mmm维光滑流形，称之为mmm 维实射影空间。 浸入、嵌入和淹没的概念，并举例说明 浸入： MMM 和NNN 都是光滑流形，f:M→Nf:M \\to Nf:M→N 是光滑映射。如果fff 在点p∈Mp \\in Mp∈M 的秩等于MMM 的维数，则称映射fff 在ppp 点为浸入。如果fff 在MMM 的每一点都是浸入，则称fff 为浸入。 嵌入：设f:M→Nf:M \\to Nf:M→N 是单浸入，如果对于f(M)⊂Nf(M) \\subset Nf(M)⊂N 的子空间拓扑，f:M→f(M)f:M \\to f(M)f:M→f(M) 是同胚，则称fff 为嵌入，f(M)f(M)f(M) 为NNN 的嵌入子流形。 淹没：设M,NM,NM,N 分别为mmm 维和nnn 维光滑流形，m&gt;nm&gt;nm&gt;n 。如果光滑映射f:Mm→Nnf:M^m \\to N^nf:Mm→Nn 在点$p \\in M $ 的秩等于NNN 的维数，则称映射fff 在ppp 点为淹没。如果fff 在MMM 的每一点都是淹没，则称fff 为淹没。 参考例1.7，例1.8，例1.9，例1.10 (1). 对于正整数m,n,m&lt;nm,n,m&lt;nm,n,m&lt;n ，有包含映射f:Mm→Nn,f(x1,⋯ ,xm)=(x1,⋯ ,xm,0,⋯ ,0)f: M^m \\to N^n,f(x^1,\\cdots,x^m)=(x^1,\\cdots,x^m,0,\\cdots,0)f:Mm→Nn,f(x1,⋯,xm)=(x1,⋯,xm,0,⋯,0)，则fff是浸入，称为典型浸入。 (2). 设f：R→R2f：\\mathbb{R} \\to \\mathbb{R}^2f：R→R2定义为(t)=(2cos⁡(t−π2),sin⁡2(t−π2)) (t)=\\left(2 \\cos \\left(t-\\frac{\\pi}{2}\\right), \\sin 2\\left(t-\\frac{\\pi}{2}\\right)\\right) (t)=(2cos(t−2π​),sin2(t−2π​)) ，容易验证映射fff为浸入。 (3). 设U⊂RmU \\subset \\mathbb{R}^mU⊂Rm 是开子集，g:U→Rk(k&lt;m)g:U \\to \\mathbb{R}^k(k&lt;m)g:U→Rk(k&lt;m) 定义为： f(x1,⋯ ,xk,xk+1,⋯ ,xm)=(x1,⋯ ,xk)f\\left(x^{1}, \\cdots, x^{k}, x^{k+1}, \\cdots, x^{m}\\right)=\\left(x^{1}, \\cdots, x^{k}\\right) f(x1,⋯,xk,xk+1,⋯,xm)=(x1,⋯,xk) 则fff 是淹没，称为典型淹没 (4). 设f:Rm−0→Rf: \\mathbb{R}^m - {0} \\to \\mathbb{R}f:Rm−0→R定义为f(x1,⋯ ,xm)=∑i=1m(xi)2 f\\left(x^{1}, \\cdots, x^{m}\\right)=\\sum_{i=1}^{m}\\left(x^{i}\\right)^{2} f(x1,⋯,xm)=∑i=1m​(xi)2 ，映射fff 在Rm−0\\mathbb{R}^m - {0}Rm−0 的所有点处秩为1，所以映射fff 为淹没。 单位分解的概念，单位分解定理 设III 为自然数集，若光滑流形MMM 上的一族光滑函数{fi∣i∈I}\\{f_i|i \\in I\\}{fi​∣i∈I} 满足下列性质： 对于任一点p∈M,fi(p)≥0p \\in M,f_i(p) \\ge 0p∈M,fi​(p)≥0 对于任一点p∈M,∑ifi(p)=1p \\in M,\\sum_i f_i(p) = 1p∈M,∑i​fi​(p)=1 {supp(fi)}\\{supp(f_i)\\}{supp(fi​)} 为MMM 的局部有限的覆盖(支集，定义为使得f(p)≠0f(p) \\ne 0f(p)​=0的点集的闭包) 则称{fi∣i∈I}\\{f_i|i \\in I\\}{fi​∣i∈I} 为MMM 上的单位分解。 单位分解定理： 设MMM 为具有可数基的mmm 维光滑流形，{(Ui,φi;Vi)}\\{(U_i,\\varphi_i;V_i)\\}{(Ui​,φi​;Vi​)} 为MMM 的正则覆盖(局部有限覆盖，加细)，则存在单位分解{fi}\\{f_i\\}{fi​} ，使得在ViV_iVi​ 上fi&gt;0f_i &gt; 0fi​&gt;0，且supp(fi)⊂φi−1(B3/4m(0)ˉ)supp(f_i) \\subset \\varphi_i^{-1}(\\bar{B_{3/4}^m(0)})supp(fi​)⊂φi−1​(B3/4m​(0)ˉ​) 。 外积的定义及其性质： 设ξ\\xiξ 是外kkk 次向量(反对称的kkk 阶反变张量)，η\\etaη 是外lll 次向量，令 ξ∧η=(k+l)!k!l!Ak+l(ξ⊗η)\\xi \\wedge \\eta = \\frac{(k+l)!}{k!l!}A_{k+l}(\\xi \\otimes \\eta) ξ∧η=k!l!(k+l)!​Ak+l​(ξ⊗η) 其中Ak+lA_{k+l}Ak+l​ 是反对称化算子，则ξ∧η\\xi \\wedge \\etaξ∧η 是外k+lk+lk+l 次向量，称为外向量ξ\\xiξ 和η\\etaη 的外积。 性质： 外积是双线性的，且满足下列运算规律： （分配律）(aξ1+bξ2)∧η=aξ1∧η+bξ2∧η,ξ∧(aη1+bη2)=aξ∧η1+bξ∧η2\\left(a \\xi_{1}+b \\xi_{2}\\right) \\wedge \\eta=a \\xi_{1} \\wedge \\eta+b \\xi_{2} \\wedge \\eta, \\quad \\xi \\wedge\\left(a \\eta_{1}+b \\eta_{2}\\right)=a \\xi \\wedge \\eta_{1}+b \\xi \\wedge \\eta_{2}(aξ1​+bξ2​)∧η=aξ1​∧η+bξ2​∧η,ξ∧(aη1​+bη2​)=aξ∧η1​+bξ∧η2​ （反交换律）ξ∧η=(−1)klη∧ξ\\xi \\wedge \\eta=(-1)^{k l} \\eta \\wedge \\xiξ∧η=(−1)klη∧ξ （结合律）(ξ∧η)∧ζ=ξ∧(η∧ζ)(\\xi \\wedge \\eta) \\wedge \\zeta=\\xi \\wedge(\\eta \\wedge \\zeta)(ξ∧η)∧ζ=ξ∧(η∧ζ) 其中ξ,ξ1,ξ2∈Λk(V),η,η1,η2∈Λl(V),ζ∈Λh(V),a,b∈F\\xi, \\xi_{1}, \\xi_{2} \\in \\Lambda^{k}(V), \\eta, \\eta_{1}, \\eta_{2} \\in \\Lambda^{l}(V), \\zeta \\in \\Lambda^{h}(V), a, b \\in Fξ,ξ1​,ξ2​∈Λk(V),η,η1​,η2​∈Λl(V),ζ∈Λh(V),a,b∈F 推论 设ξ∈A1(V)=V\\xi \\in A^1(V) = Vξ∈A1(V)=V，则ξ∧ξ=0\\xi \\wedge \\xi = 0ξ∧ξ=0 设{e1,⋯ ,en}\\{e_1,\\cdots,e_n\\}{e1​,⋯,en​} 是VVV 的一组基，则： ei1∧⋯∧eir=r!Ar(ei1⊗⋯⊗eir)e_{i_{1}} \\wedge \\cdots \\wedge e_{i_{r}}=r ! A_{r}\\left(e_{i_{1}} \\otimes \\cdots \\otimes e_{i_{r}}\\right) ei1​​∧⋯∧eir​​=r!Ar​(ei1​​⊗⋯⊗eir​​) 其中1≤i1,⋯ ,ir≤m1 \\le i_1, \\cdots, i_r \\le m1≤i1​,⋯,ir​≤m 向量v1,⋯ ,vr∈Vv_1,\\cdots,v_r \\in Vv1​,⋯,vr​∈V 线性相关的充要条件是 v1∧⋯vr=0v_1 \\wedge \\cdots v_r = 0 v1​∧⋯vr​=0 Cartan引理的内容及其证明： 设v1,⋯ ,vr;w1,⋯ ,wrv_1,\\cdots,v_r;w_1,\\cdots,w_rv1​,⋯,vr​;w1​,⋯,wr​ 是VVV 中两组向量，r≤n=dimVr \\le n = dimVr≤n=dimV ,满足 ∑α=1rvα∧wa=0(1)\\sum_{\\alpha = 1}^{r} v_{\\alpha} \\wedge w_a = 0 \\tag{1} α=1∑r​vα​∧wa​=0(1) 如果v1,⋯ ,vrv_1,\\cdots,v_rv1​,⋯,vr​ 线性无关，则wαw_{\\alpha}wα​ 可表示成它们的线性组合 wα=∑β=1raαβvβ，1≤α≤rw_{\\alpha} = \\sum_{\\beta = 1}^r a_{\\alpha \\beta}v_{\\beta}， \\qquad 1 \\le \\alpha \\le r wα​=β=1∑r​aαβ​vβ​，1≤α≤r 且aαβ=aβαa_{\\alpha \\beta} = a_{\\beta \\alpha}aαβ​=aβα​ 证明： 因为v1,⋯ ,vr∈Vv_1,\\cdots,v_r \\in Vv1​,⋯,vr​∈V 线性无关，则可将他们扩充为VVV 的一组基{v1,⋯ ,vr−1,vr,vr+1,⋯ ,vn}\\{v_1, \\cdots, v_{r-1}, v_r, v_{r+1}, \\cdots, v_n\\}{v1​,⋯,vr−1​,vr​,vr+1​,⋯,vn​}. 则可设 wα=∑β=1raαβvβ+∑i=r+1naαiviw_{\\alpha}=\\sum_{\\beta=1}^{r} a_{\\alpha \\beta} v_{\\beta}+\\sum_{i=r+1}^{n} a_{\\alpha i} v_{i} wα​=β=1∑r​aαβ​vβ​+i=r+1∑n​aαi​vi​ 把上式带入(1)(1)(1) 得： 0=∑α,β=1raαβvα∧vβ+∑α=1r∑i=r+1naαivα∧vi=∑1≤α&lt;β≤r(aαβ−aβα)vα∧vβ+∑α=1r∑i=r+1naαivα∧vi\\begin{aligned} 0 &amp;=\\sum_{\\alpha, \\beta=1}^{r} a_{\\alpha \\beta} v_{\\alpha} \\wedge v_{\\beta}+\\sum_{\\alpha=1}^{r} \\sum_{i=r+1}^{n} a_{\\alpha i} v_{\\alpha} \\wedge v_{i} \\\\ &amp;=\\sum_{1 \\leq \\alpha&lt;\\beta \\leq r}\\left(a_{\\alpha \\beta}-a_{\\beta \\alpha}\\right) v_{\\alpha} \\wedge v_{\\beta}+\\sum_{\\alpha=1}^{r} \\sum_{i=r+1}^{n} a_{\\alpha i} v_{\\alpha} \\wedge v_{i} \\end{aligned} 0​=α,β=1∑r​aαβ​vα​∧vβ​+α=1∑r​i=r+1∑n​aαi​vα​∧vi​=1≤α&lt;β≤r∑​(aαβ​−aβα​)vα​∧vβ​+α=1∑r​i=r+1∑n​aαi​vα​∧vi​​ 因vi∧vj,1≤i&lt;j≤nv_i \\wedge v_j,1 \\le i &lt; j \\le nvi​∧vj​,1≤i&lt;j≤n 是Λ2(V)\\Lambda^{2}(V)Λ2(V) 的一组基，故： aαβ−aβα=0,aαi=0a_{\\alpha \\beta}-a_{\\beta \\alpha}=0, a_{\\alpha i}=0 aαβ​−aβα​=0,aαi​=0 即 wα=∑β=1raαβvβ,1≤α≤rw_{\\alpha}=\\sum_{\\beta=1}^{r} a_{\\alpha \\beta} v_{\\beta}, \\quad 1 \\leq \\alpha \\leq r wα​=β=1∑r​aαβ​vβ​,1≤α≤r 且aαβ=aβαa_{\\alpha \\beta} = a_{\\beta \\alpha}aαβ​=aβα​ 李括号（Poisson括号）的定义及其性质： 设MMM 为光滑流形，对任意X,Y∈Γ(TM)X,Y \\in \\Gamma(TM)X,Y∈Γ(TM)，定义[X,Y]:C∞(M)→R[X,Y]:C^{\\infty}(M) \\to \\mathbb{R}[X,Y]:C∞(M)→R 为 [X,Y](f)=X(Y(f))−Y(X(f))[X, Y](f)=X(Y(f))-Y(X(f)) [X,Y](f)=X(Y(f))−Y(X(f)) 称[X,Y][X,Y][X,Y] 为X,YX,YX,Y 的李括号或Poisson括号。 注： Γ(TM)\\Gamma(TM)Γ(TM):MMM上所有光滑切向量场X:M→TMX: M \\to TMX:M→TM的集合 TM={(p,v)∣p∈M,v∈TpM}TM= \\{(p,v)|p \\in M, v\\in T_pM\\}TM={(p,v)∣p∈M,v∈Tp​M}（TpMT_pMTp​M 为切空间） fff：X∈Γ(TM),f∈C∞(M),p∈MX \\in \\Gamma (TM),f \\in C^{\\infty}(M),p \\in MX∈Γ(TM),f∈C∞(M),p∈M 则(fX)(p)=f(p)X(p)(fX)(p)=f(p)X(p)(fX)(p)=f(p)X(p) 光滑向量场的李括号具有下面的性质： 设MMM 为光滑流形，则对任意X,Y∈Γ(TM),f,g∈C∞(M),λ,μ∈RX,Y \\in \\Gamma(TM),f,g \\in C^{\\infty}(M), \\lambda,\\mu \\in \\mathbb{R}X,Y∈Γ(TM),f,g∈C∞(M),λ,μ∈R ，有 [X,Y](λ⋅f+μ⋅g)=λ⋅[X,Y](f)+μ⋅[X,Y](g)[X, Y](\\lambda \\cdot f+\\mu \\cdot g)=\\lambda \\cdot[X, Y](f)+\\mu \\cdot[X, Y](g)[X,Y](λ⋅f+μ⋅g)=λ⋅[X,Y](f)+μ⋅[X,Y](g) [X,Y](f⋅g)=[X,Y](f)⋅g+f⋅[X,Y](g)[X, Y](f \\cdot g)=[X, Y](f) \\cdot g+f \\cdot[X, Y](g)[X,Y](f⋅g)=[X,Y](f)⋅g+f⋅[X,Y](g) 设MMM 是光滑流形，[,][,][,] 是李括号，则 [X,f⋅Y]=X(f)⋅Y+f⋅[X,Y][f⋅X,Y]=f⋅[X,Y]−Y(f)⋅X\\begin{array}{l} {[X, f \\cdot Y]=X(f) \\cdot Y+f \\cdot[X, Y]} \\\\ {[f \\cdot X, Y]=f \\cdot[X, Y]-Y(f) \\cdot X} \\end{array} [X,f⋅Y]=X(f)⋅Y+f⋅[X,Y][f⋅X,Y]=f⋅[X,Y]−Y(f)⋅X​ ​ 其中X,Y∈Γ(TM),f∈C∞(M)X,Y \\in \\Gamma(TM),f \\in C^{\\infty}(M)X,Y∈Γ(TM),f∈C∞(M) 李群的定义，并举例说明 设GGG 是一个群，并且是mmm 维光滑流形。如果GGG 的乘法运算φ:G×G→G,φ(g1,g2)=g1g2\\varphi: G \\times G \\to G, \\varphi(g_1,g_2) = g_1 g_2φ:G×G→G,φ(g1​,g2​)=g1​g2​ 以及求逆运算τ:G→G,τ(g)=g−1\\tau: G \\to G, \\tau(g) = g^{-1}τ:G→G,τ(g)=g−1 都是光滑映射，则称GGG 是一个mmm 维李群。 举例：例2.2，例2.3 RmR^mRm 关于向量加法成为一个mmm 维李群。 实矩阵构成的一般线性群GL(m,R)GL(m,\\mathbb{R})GL(m,R) 和GL(m,C)GL(m,\\mathbb{C})GL(m,C) 都是李群(GL(m,R)GL(m,\\mathbb{R})GL(m,R)表示mmm阶非退化实矩阵构成的集合)。 GL(m,R)GL(m,\\mathbb{R})GL(m,R)是mmm阶非退化实矩阵构成的集合，群运算是矩阵的乘法，因为GL(m,R)GL(m,\\mathbb{R})GL(m,R) 是Rm2\\mathbb{R}^{m^2}Rm2 的开子集，有自然诱导的光滑结构，容易验证矩阵的乘法运算和求逆运算都是光滑映射，所以GL(m,R)GL(m,\\mathbb{R})GL(m,R) 是m2m^2m2 维李群。类似GL(m,C)GL(m,\\mathbb{C})GL(m,C)是2m22m^22m2 维李群。 **设(G,∗)(G,*)(G,∗) 和 (H,⋅)(H,\\centerdot)(H,⋅)是两个李群，证明乘积流形 $G\\times H $ 有李群的结构 ** G,HG,HG,H是李群, →G,H\\to G,H→G,H 是光滑流形,G×HG \\times HG×H 是光滑流形。 定义G×H={(g,h)∣g∈G,h∈H}G \\times H=\\{(g,h)|g \\in G, h \\in H\\}G×H={(g,h)∣g∈G,h∈H} 在其上定义的乘法运算φ:(G×H)×(G×H)→(G×H):φ((g1,h1),(g2,h2))=(g1∗g2,h1⋅h2)\\varphi: (G\\times H) \\times (G \\times H) \\to (G \\times H):\\quad \\varphi((g_1,h_1),(g_2,h_2)) = (g_1 * g_2,h_1\\centerdot h_2)φ:(G×H)×(G×H)→(G×H):φ((g1​,h1​),(g2​,h2​))=(g1​∗g2​,h1​⋅h2​) 以及求逆运算τ:(G×H)→(G×H):τ((g,h))=(g−1,h−1)\\tau: (G \\times H) \\to (G \\times H): \\quad \\tau((g,h)) = (g^{-1},h^{-1})τ:(G×H)→(G×H):τ((g,h))=(g−1,h−1) 都是光滑映射 从而乘积流形 $G\\times H $ 有李群的结构 Poincare引理及其证明，以及它在古典向量分析中的应用 d2=0d^2 = 0d2=0，即对任意的外微分式www ，有d(dw)=0d(dw) = 0d(dw)=0 **证明：**因为ddd 是线性算子，所以只需取www 为单项式即可。由于外微分ddd 是局部算子，故只需在一个局部坐标系(U,φ;xi)(U,\\varphi;x_i)(U,φ;xi​) 中讨论，设 ω=fdx1∧⋯∧dxr,f∈C∞(M)\\omega=f d x^{1} \\wedge \\cdots \\wedge d x^{r}, f \\in C^{\\infty}(M) ω=fdx1∧⋯∧dxr,f∈C∞(M) 则 dω=df∧dx1∧⋯∧dxrd \\omega=d f \\wedge d x^{1} \\wedge \\cdots \\wedge d x^{r} dω=df∧dx1∧⋯∧dxr 再外微分一次，得 d(dω)=d(df)∧dx1∧⋯∧dxr−df∧d(dx1)∧⋯∧dxr+⋯=0d(d \\omega)=d(d f) \\wedge d x^{1} \\wedge \\cdots \\wedge d x^{r}-d f \\wedge d\\left(d x^{1}\\right) \\wedge \\cdots \\wedge d x^{r}+\\cdots=0 d(dω)=d(df)∧dx1∧⋯∧dxr−df∧d(dx1)∧⋯∧dxr+⋯=0 注：MMM上的外向量丛和外形式丛分别记作Λr(M)=∪p∈MΛr(TpM)\\Lambda^r(M)=\\cup_{p \\in M} \\Lambda^{r}\\left(T_{p} M\\right)Λr(M)=∪p∈M​Λr(Tp​M) 和 Λr(M∗)=⋃p∈MΛr(Tp∗M)\\Lambda^{r}\\left(M^{*}\\right)=\\bigcup_{p \\in M} \\Lambda^{r}\\left(T_{p}^{*} M\\right)Λr(M∗)=⋃p∈M​Λr(Tp∗​M) 用Ar(M)A^r(M)Ar(M)记rrr次外形式丛Λr(M∗)\\Lambda^r(M^*)Λr(M∗)的光滑截面构成的空间，即Ar(M)=Γ(Λr(M∗))A^{r}(M)=\\Gamma\\left(\\Lambda^{r}\\left(M^{*}\\right)\\right)Ar(M)=Γ(Λr(M∗)) 截面空间A(M)A(M)A(M)的元素称为MMM的外微分式，A(M)=∑r=0mAr(M)A(M)=\\sum_{r=0}^{m} A^{r}(M)A(M)=∑r=0m​Ar(M) 证明过程中用到的性质： 若w1w_1w1​是rrr次外微分式，则d(ω1∧ω2)=dω1∧ω2+(−1)rω1∧dω2d\\left(\\omega_{1} \\wedge \\omega_{2}\\right)=d \\omega_{1} \\wedge \\omega_{2}+(-1)^{r} \\omega_{1} \\wedge d \\omega_{2}d(ω1​∧ω2​)=dω1​∧ω2​+(−1)rω1​∧dω2​ 若f∈A0(M)f \\in A^0(M)f∈A0(M), 则d(df)=0d(df)=0d(df)=0 Poincare引理在古典向量分析中的应用： 设(x,y,z)(x,y,z)(x,y,z) 是R3\\mathbb{R}^3R3 上的光滑函数，则 df=∂f∂xdx+∂f∂ydy+∂f∂zdzd f=\\frac{\\partial f}{\\partial x} d x+\\frac{\\partial f}{\\partial y} d y+\\frac{\\partial f}{\\partial z} d z df=∂x∂f​dx+∂y∂f​dy+∂z∂f​dz ​ 其系数构成的向量场(∂f∂x,∂f∂y,∂f∂z)\\left(\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z}\\right)(∂x∂f​,∂y∂f​,∂z∂f​) 是fff 的梯度场gradfgrad fgradf. 设w=Adx+Bdy+Cdzw = A dx + Bdy + Cdzw=Adx+Bdy+Cdz ,其中A,B,CA,B,CA,B,C 是R3\\mathbb{R}^3R3 上的光滑函数，则 dω=dA∧dx+dB∧dy+dC∧dz=(∂A∂xdx+∂A∂ydy+∂A∂zdz)∧dx+(∂B∂xdx+∂B∂ydy+∂C∂zdz)∧dy+(∂C∂xdx+∂C∂ydy+∂C∂zdz)∧dz=(∂C∂y−∂B∂z)dy∧dz+(∂A∂z−∂C∂x)dz∧dx+(∂B∂x−∂A∂y)dx∧dy\\begin{aligned} d \\omega &amp;=d A \\wedge d x+d B \\wedge d y+d C \\wedge d z \\\\ &amp;= (\\frac{\\partial A}{\\partial x}dx + \\frac{\\partial A}{\\partial y}dy + \\frac{\\partial A}{\\partial z}dz) \\wedge dx + (\\frac{\\partial B}{\\partial x}dx + \\frac{\\partial B}{\\partial y}dy + \\frac{\\partial C}{\\partial z}dz) \\wedge dy + (\\frac{\\partial C}{\\partial x}dx + \\frac{\\partial C}{\\partial y}dy + \\frac{\\partial C}{\\partial z}dz) \\wedge dz\\\\ &amp;=\\left(\\frac{\\partial C}{\\partial y}-\\frac{\\partial B}{\\partial z}\\right) d y \\wedge d z+\\left(\\frac{\\partial A}{\\partial z}-\\frac{\\partial C}{\\partial x}\\right) d z \\wedge d x+\\left(\\frac{\\partial B}{\\partial x}-\\frac{\\partial A}{\\partial y}\\right) d x \\wedge d y \\end{aligned} dω​=dA∧dx+dB∧dy+dC∧dz=(∂x∂A​dx+∂y∂A​dy+∂z∂A​dz)∧dx+(∂x∂B​dx+∂y∂B​dy+∂z∂C​dz)∧dy+(∂x∂C​dx+∂y∂C​dy+∂z∂C​dz)∧dz=(∂y∂C​−∂z∂B​)dy∧dz+(∂z∂A​−∂x∂C​)dz∧dx+(∂x∂B​−∂y∂A​)dx∧dy​ ​ 若记向量场X=(A,B,C)X = (A,B,C)X=(A,B,C) ，则dwdwdw 的系数构成的向量场 (∂C∂y−∂B∂z,∂A∂z−∂C∂x,∂B∂x−∂A∂y)\\left(\\frac{\\partial C}{\\partial y}-\\frac{\\partial B}{\\partial z}, \\frac{\\partial A}{\\partial z}-\\frac{\\partial C}{\\partial x}, \\frac{\\partial B}{\\partial x}-\\frac{\\partial A}{\\partial y}\\right) (∂y∂C​−∂z∂B​,∂z∂A​−∂x∂C​,∂x∂B​−∂y∂A​) ​ 恰是向量场XXX 的旋度curlXcurl XcurlX 设ω=Ady∧dz+Bdz∧dx+Cdx∧dy\\omega=A d y \\wedge d z+B d z \\wedge d x+C d x \\wedge d yω=Ady∧dz+Bdz∧dx+Cdx∧dy ，则 dω=dA∧dy∧dz+dB∧dz∧dx+dC∧dx∧dy=∂A∂xdx∧dy∧dz+∂B∂ydy∧dz∧dx+∂C∂zdz∧dx∧dy=(∂A∂x+∂B∂y+∂C∂z)dx∧dy∧dz=div⁡dx∧dy∧dz\\begin{aligned} d \\omega &amp;= dA \\wedge dy \\wedge dz + dB \\wedge dz \\wedge dx + dC \\wedge dx \\wedge dy\\\\ &amp;= \\frac{\\partial A}{\\partial x} dx \\wedge dy \\wedge dz + \\frac{\\partial B}{\\partial y} dy \\wedge dz \\wedge dx + \\frac{\\partial C}{\\partial z} dz \\wedge dx \\wedge dy\\\\ &amp;=\\left(\\frac{\\partial A}{\\partial x}+\\frac{\\partial B}{\\partial y}+\\frac{\\partial C}{\\partial z}\\right) d x \\wedge d y \\wedge d z \\\\ &amp;=\\operatorname{div} d x \\wedge d y \\wedge d z \\end{aligned} dω​=dA∧dy∧dz+dB∧dz∧dx+dC∧dx∧dy=∂x∂A​dx∧dy∧dz+∂y∂B​dy∧dz∧dx+∂z∂C​dz∧dx∧dy=(∂x∂A​+∂y∂B​+∂z∂C​)dx∧dy∧dz=divdx∧dy∧dz​ ​ 其中X=(A,B,C),divXX=(A,B,C),divXX=(A,B,C),divX 表示向量场XXX 的散度。 由Poincare定理，立即得到古典场论的两个基本公式：curl(gradf)=0,div(curlX)=0curl(grad f) = 0, \\quad div(curl X)=0curl(gradf)=0,div(curlX)=0 流行定向的概念 设MMM 是一个微分流形，如果在MMM 上存在一族容许局部坐标系U={(Uα,φα)∣α∈I}\\mathscr{U}=\\left\\{\\left(U_{\\alpha}, \\varphi_{\\alpha}\\right) \\mid \\alpha \\in I\\right\\}U={(Uα​,φα​)∣α∈I} 满足下面两个条件： (1). ⋃α∈IUα=M\\bigcup_{\\alpha \\in I} U_{\\alpha}=M⋃α∈I​Uα​=M (2). 对任意两个局部坐标系Uα,φα;xiU_{\\alpha},\\varphi_{\\alpha};x^iUα​,φα​;xi 和Uβ,φβ;yiU_{\\beta},\\varphi_{\\beta};y^iUβ​,φβ​;yi, Uα⋂Uβ=∅U_{\\alpha} \\bigcap U_{\\beta} = \\emptysetUα​⋂Uβ​=∅ 时，在Uα⋂UβU_{\\alpha} \\bigcap U_{\\beta}Uα​⋂Uβ​ 上有 ∂(xα1,⋯ ,xαm)∂(yβ1,⋯ ,yβm)&gt;0\\frac{\\partial\\left(x_{\\alpha}^{1}, \\cdots, x_{\\alpha}^{m}\\right)}{\\partial\\left(y_{\\beta}^{1}, \\cdots, y_{\\beta}^{m}\\right)}&gt;0 ∂(yβ1​,⋯,yβm​)∂(xα1​,⋯,xαm​)​&gt;0 则称MMM 是可定向微分流形。满足(2)条件的两个局部坐标系 Uα,φα;xi U_{\\alpha},\\varphi_{\\alpha};x^i Uα​,φα​;xi和Uβ,φβ;yiU_{\\beta},\\varphi_{\\beta};y^iUβ​,φβ​;yi 称为定向相符的。 设 MMM 是可定向的 mmm 维微分流形，如果U={(Uα,φα)∣α∈I}\\mathscr{U}=\\left\\{\\left(U_{\\alpha}, \\varphi_{\\alpha}\\right) \\mid \\alpha \\in I\\right\\}U={(Uα​,φα​)∣α∈I} 是满足上面两个条件的一族局部坐标系，并且满足： (3). U\\mathscr{U}U是极大的，即对任意的容许局部坐标系U;xiU;x^iU;xi ，如果对于任意的α∈I\\alpha \\in Iα∈I, (U;xi)(U;x^i)(U;xi)和Uα;xαiU_{\\alpha};x^i_{\\alpha}Uα​;xαi​都是定向相符的，便有(U;xi)∈U(U;x^i) \\in \\mathscr{U}(U;xi)∈U 则称U\\mathscr{U}U是 MMM 的一个定向。具有指定定向的微分流形称为定向微分流形。 或通过外微分式给出等价的定义 mmm维光滑流形 MMM 称为可定向的，如果在 MMM 上存在一个连续的，处处不为零的mmm 次外微分式。如果在MMM上给定了这样一个外微分式，则称MMM是定向的。如果给出MMM 定向的两个外微分式彼此差一个处处为正的函数因子，则称他们规定了MMM的一个方向。 流形上外微分式的积分如何定义 设MMM 是mmm 维定向的光滑流形，φ\\varphiφ 是MMM 上有紧致支集的mmm 次微分式，由 ∫Mφ=∑α∫Mgα⋅φ\\int_{M} \\varphi=\\sum_{\\alpha} \\int_{M} g_{\\alpha} \\cdot \\varphi ∫M​φ=α∑​∫M​gα​⋅φ 所定义的数∫Mφ\\int_{M} \\varphi∫M​φ 称为外微分式φ\\varphiφ 在MMM 上的积分。 注：任取MMM 的一个定向相符的坐标卡构成的覆盖Σ={Wi}\\Sigma = \\{W_i\\}Σ={Wi​}， 设{gα}\\{g_{\\alpha}\\}{gα​} 是从属于Σ\\SigmaΣ 的单位分解，则φ=(∑αgα)⋅φ=∑α(gα⋅φ)\\varphi=(\\sum_{\\alpha}g_{\\alpha}) \\centerdot \\varphi = \\sum_{\\alpha}(g_{\\alpha} \\centerdot \\varphi)φ=(∑α​gα​)⋅φ=∑α​(gα​⋅φ) 用实例解释说明流形上的Stocks公式 设MMM 是mmm 维定向光滑流形，www 是MMM 上具有紧致支集的m−1m-1m−1 次外微分式，则 ∫∂Mω=∫Mdω\\int_{\\partial M} \\omega=\\int_{M} d \\omega ∫∂M​ω=∫M​dω 若∂M=∅\\partial M = \\emptyset∂M=∅, 则规定左边的积分是零。 参考例3.4 设Σ\\SigmaΣ 是R3\\mathbb{R}^3R3 中的一块定向曲面，其边界∂Σ\\partial \\Sigma∂Σ 为定向闭曲线，而且∂Σ\\partial \\Sigma∂Σ 的正向法向量符合右手法则。设P,Q,RP,Q,RP,Q,R 是包含在Σ\\SigmaΣ 在内的一个区域上的连续可微函数，则有Stocks公式： ∫∂ΣPdx+Qdy+Rdz=∬Σ(∂R∂y−∂Q∂z)dydz+(∂P∂z−∂R∂x)dzdx+(∂Q∂x−∂P∂y)dxdy\\int_{\\partial \\Sigma} P d x+Q d y+R d z=\\iint_{\\Sigma}\\left(\\frac{\\partial R}{\\partial y}-\\frac{\\partial Q}{\\partial z}\\right) d y d z+\\left(\\frac{\\partial P}{\\partial z}-\\frac{\\partial R}{\\partial x}\\right) d z d x+\\left(\\frac{\\partial Q}{\\partial x}-\\frac{\\partial P}{\\partial y}\\right) d x d y ∫∂Σ​Pdx+Qdy+Rdz=∬Σ​(∂y∂R​−∂z∂Q​)dydz+(∂z∂P​−∂x∂R​)dzdx+(∂x∂Q​−∂y∂P​)dxdy 若记w=Pdx+Qdy+Rdzw = Pdx+Qdy+Rdzw=Pdx+Qdy+Rdz，则上式可以写成 ∫∂Σω=∫Σdω\\int_{\\partial \\Sigma} \\omega=\\int_{\\Sigma} d \\omega\\\\ ∫∂Σ​ω=∫Σ​dω 叙述Brouwer映射度的定义和性质， 并利用Brouwer映射度证明6维单位球面S6S^6S6上的恒同映射和对径映射不同伦 定义 设p∈Mp \\in Mp∈M 是光滑映射f:Mn→Nnf: M^n \\to N ^nf:Mn→Nn 的一个正则点，MMM 是紧致光滑的定向流形，NNN 是连通光滑的定向流形，则切映射f∗p:TpM→Tf(p)Nf_{*p}:T_pM \\to T_{f(p)}Nf∗p​:Tp​M→Tf(p)​N 为定向向量空间之间的线性同构，根据同构保持定向或反转定向，我们定义f∗pf_{*p}f∗p​ 的符号，以及在ppp 处的度数degpfdeg_pfdegp​f 和正则点的类型如下： 同构f∗pf_{*p}f∗p​ f∗pf_{*p}f∗p​ 的符号 degpfdeg_pfdegp​f 类型 保持定向 +1 +1 正型 反转定向 -1 -1 负型 进而，对于fff 的正则值q∈Nq \\in Nq∈N，定义 deg⁡(f,q)=∑p∈f−1(q)deg⁡pf\\operatorname{deg}(f, q)=\\sum_{p \\in f^{-1}(q)} \\operatorname{deg}_{p} f deg(f,q)=p∈f−1(q)∑​degp​f 称之为fff 关于正则值qqq 的Brouwer度。 整数deg(f,q)deg(f,q)deg(f,q) 不依赖于正则值qqq 的选取，把整数deg(f,q)deg(f,q)deg(f,q) 称为映射fff 的Brouwer度或映射度，记为deg(f)deg(f)deg(f) 。 性质 设M,N,PM,N,PM,N,P 是具有相同维数的定向光滑流形，且MMM 和NNN 紧致，NNN 和PPP 连通,则 (1). 若f:M→Nf: M \\to Nf:M→N 和g:N→Pg: N \\to Pg:N→P 为光滑映射，则deg⁡(g∘f)=deg⁡(g)⋅deg⁡(f)\\operatorname{deg}(g \\circ f)=\\operatorname{deg}(g) \\cdot \\operatorname{deg}(f)deg(g∘f)=deg(g)⋅deg(f) ； (2). 若id:M→Mid: M \\to Mid:M→M 为恒同映射，则deg(id)=1deg(id)=1deg(id)=1，即恒同映射的映射度为1； (3). 若f:M→Nf: M \\to Nf:M→N 为微分同胚，则deg(f)=±1deg(f)= \\pm 1deg(f)=±1 ； (4). 若f,g:M→Nf,g: M \\to Nf,g:M→N 为C∞C^{\\infty}C∞ 映射，且fff 同伦于ggg， 则deg(f)=deg(g)deg(f)= deg(g)deg(f)=deg(g)，即映射度是同伦不变量。 证明 参考例3.5 例3.5考虑nnn 单位球面 Sn(n≥1) S^n(n \\ge 1) Sn(n≥1)上的恒同映射和对径映射.显然，SnS^nSn 上的恒同映射的Brouwer 度为1.我们定义SSS上的反射ri:Sn→Snr_i:S_n \\to S_nri​:Sn​→Sn​为 ri:(x1,⋯ ,xn+1)=(x1,⋯ ,xi−1,−xi,xi+1,⋯ ,an+1),i=1,⋯ ,n+1r_i:(x_1,\\cdots,x_{n+1})=(x_1,\\cdots ,x_{i-1},-x_i,x{i+1},\\cdots,a_{n+1}),i=1,\\cdots ,n+1 ri​:(x1​,⋯,xn+1​)=(x1​,⋯,xi−1​,−xi​,xi+1,⋯,an+1​),i=1,⋯,n+1 它是一个反转定向的微分同胚，故其映射度deg(ri)=−1deg(r_i)=-1deg(ri​)=−1. SnS_nSn​ 上的对径映射r:Sn→Snr: S^n \\to S^nr:Sn→Sn 定义为 r(x)=−xr(x)=-xr(x)=−x，它可以看成是n+1n+1n+1个反射的复合，即r=r1∘r2∘⋯∘rn+1r=r_{1} \\circ r_{2} \\circ \\cdots \\circ r_{n+1}r=r1​∘r2​∘⋯∘rn+1​,其映射度为 deg⁡(r)=deg⁡(r1)deg⁡(r2)⋯deg⁡(rn+1)=(−1)n+1\\operatorname{deg}(r)=\\operatorname{deg}\\left(r_{1}\\right) \\operatorname{deg}\\left(r_{2}\\right) \\cdots \\operatorname{deg}\\left(r_{n+1}\\right)=(-1)^{n+1} deg(r)=deg(r1​)deg(r2​)⋯deg(rn+1​)=(−1)n+1 当n为偶数时，deg(r)=−1deg(r)=-1deg(r)=−1，故SnS^nSn 上的对径映射和恒同映射不同伦. 黎曼度量的定义。证明：任意光滑流形上都存在黎曼度量。 设MMM 是mmm 维光滑流形，MMM 上的一个黎曼度量ggg 是MMM 上的一个光滑的二阶协变张量场，使得对每一点p∈M,g(p)p \\in M,g(p)p∈M,g(p) 是切空间Tp(M)T_p(M)Tp​(M) 上的一个对称，正定的二阶协变张量(M,g)(M,g)(M,g) 称为mmm 维黎曼流形。 注：g(p)∈Tp∗M⊗Tp∗M:Tp(M)×Tp(M)→Rg(p) \\in T_p^*M \\otimes T_p^*M:T_p(M) \\times T_p(M) \\to \\mathbb{R}g(p)∈Tp∗​M⊗Tp∗​M:Tp​(M)×Tp​(M)→R 证明：定理4.1 设MMM 是一个满足第二可数公理的mmm 维光滑流形，则在MMM 上必存在黎曼度量。 证明: 由于在流形的每一个局部坐标邻域上都可以给定一个黎曼度量。非常自然的想法就是利用单位分解定理，把这些局部定义的黎曼度量拼接成为流形M上的一个黎曼度量。 (1). 取定局部坐标邻域与单位分解，在每一个局部邻域上给定黎曼度量 由于M满足第二可数公理，可取MMM的一个局部有限的坐标覆盖{Uα;xαi∣α∈I}\\{U_{\\alpha};x^i_{\\alpha}|\\alpha \\in I\\}{Uα​;xαi​∣α∈I}，其中III是自然数集。由单位分解定理，存在MMM上的光滑函数族{fa}\\{f_a\\}{fa​}，使得对任意的a∈Ia \\in Ia∈I，有 supp⁡fα⊂Uα,0≤fα≤1,∑α∈Ifα=1\\operatorname{supp} f_{\\alpha} \\subset U_{\\alpha}, \\quad 0 \\leq f_{\\alpha} \\leq 1, \\sum_{\\alpha \\in I} f_{\\alpha}=1 suppfα​⊂Uα​,0≤fα​≤1,α∈I∑​fα​=1 对于每一个α∈I\\alpha \\in Iα∈I，在UαU_{\\alpha}Uα​ 上定义黎曼度量 g(α)=∑i=1mdxαi⊗dxαig^{(\\alpha)}=\\sum_{i=1}^{m} d x_{\\alpha}^{i} \\otimes d x_{\\alpha}^{i} g(α)=i=1∑m​dxαi​⊗dxαi​ (2). 将局部定义的黎曼度量拼接 利用g(α)g^{(\\alpha)}g(α), 在MMM 上如下定义二阶协变张量场gαg_{\\alpha}gα​，对任意p∈Mp \\in Mp∈M，令 gα(p)={fα(p)⋅g(α)(p),p∈Uα0,p∉Uαg_{\\alpha}(p)=\\left\\{\\begin{array}{c}f_{\\alpha}(p) \\cdot g^{(\\alpha)}(p), p \\in U_{\\alpha} \\\\ 0, p \\notin U_{\\alpha}\\end{array}\\right. gα​(p)={fα​(p)⋅g(α)(p),p∈Uα​0,p∈/​Uα​​ 由于fα⋅g(α)f_{\\alpha}\\centerdot g^{(\\alpha)}fα​⋅g(α) 在UαU_{\\alpha}Uα​ 上光滑，且Suppgα∈Suppfα∈UαSuppg_{\\alpha} \\in Suppf_{\\alpha} \\in U_{\\alpha}Suppgα​∈Suppfα​∈Uα​，易见gαg_{\\alpha}gα​ 是大范围定义在MMM上的光滑张量场 令 g=∑αgαg=\\sum_{\\alpha} g_{\\alpha} g=α∑​gα​ 根据覆盖{Uα∣α∈I}\\{U_{\\alpha}|\\alpha \\in I\\}{Uα​∣α∈I} 的局部有限性，上式右端在每一点p∈Mp \\in Mp∈M的某个邻域上是有限多项之和.所以ggg 是大范围定义在MMM 上的光滑，对称二阶协变张量场. (3). 证明正定 下面证明ggg 正定.对任意一点$ p \\in M$ ，由于 0≤fα≤1,∑α∈Ifα=10 \\leq f_{\\alpha} \\leq 1, \\sum_{\\alpha \\in I} f_{\\alpha}=1 0≤fα​≤1,α∈I∑​fα​=1 必有β∈I\\beta \\in Iβ∈I， 使得fβ(p)&gt;0f_{\\beta}(p) &gt; 0fβ​(p)&gt;0 。则对任意的v∈Tp(M)v \\in T_p(M)v∈Tp​(M)，有 (g(p))(v,v)=∑αfα(p)⋅gα(v,v)≥fβ(p)∑i=1m(dxβi(v))2≥0(g(p))(v, v)=\\sum_{\\alpha} f_{\\alpha}(p) \\cdot g^{\\alpha}(v, v) \\geq f_{\\beta}(p) \\sum_{i=1}^{m}\\left(d x_{\\beta}^{i}(v)\\right)^{2} \\geq 0 (g(p))(v,v)=α∑​fα​(p)⋅gα(v,v)≥fβ​(p)i=1∑m​(dxβi​(v))2≥0 当(g(p))(v,v)=0(g(p))(v,v)=0(g(p))(v,v)=0 时，因为fβ&gt;0f_{\\beta} &gt; 0fβ​&gt;0 ，所以 dxβi(v)=0,1≤i≤md x_{\\beta}^{i}(v)=0,1 \\leq i \\leq m dxβi​(v)=0,1≤i≤m 即v=0v=0v=0 ，因此ggg 是正定的，从而ggg 是MMM 上的一个黎曼度量。 向量丛上联络的定义 向量丛EEE上的联络是一个满足下列条件的映射: ∇:Γ(E)→Γ(T∗(M)⊗E)\\nabla: \\Gamma(E) \\rightarrow \\Gamma\\left(T^{*}(M) \\otimes E\\right) ∇:Γ(E)→Γ(T∗(M)⊗E) (1). 对任意的s1,s2∈Γ(E)s_1,s_2 \\in \\Gamma(E)s1​,s2​∈Γ(E)，有 ∇(s1+s2)=∇s1+∇s2\\nabla\\left(s_{1}+s_{2}\\right)=\\nabla s_{1}+\\nabla s_{2} ∇(s1​+s2​)=∇s1​+∇s2​ (2). 对任意的s∈Γ(E)s \\in \\Gamma(E)s∈Γ(E) 以及任意的f∈C∞(M)f \\in C^{\\infty}(M)f∈C∞(M)，有∇(fs)=df⊗s+f∇s\\nabla(f s)=d f \\otimes s+f \\nabla s∇(fs)=df⊗s+f∇s 注：Γ(E):\\Gamma(E):Γ(E): 光滑向量场，EEE的全体光滑截面的集合 EEE 是MMM 维光滑流形MMM 上的一个nnn 维向量丛 T∗(M)T^*(M)T∗(M) 为MMM 的切丛。 什么是Levi-Civita联络？设(M,g)(M,g)(M,g) 是一个黎曼流形，证明Levi-Civita联络 ∇\\nabla∇ 是MMM 的切从TMTMTM 上的联络。 设(M,g)(M,g)(M,g) 是黎曼流形，则通过下式定义的映射∇:Γ(TM)×Γ(TM)→Γ(TM)\\nabla: \\Gamma(T M) \\times \\Gamma(T M) \\rightarrow \\Gamma(T M)∇:Γ(TM)×Γ(TM)→Γ(TM) g(∇XY,Z)=12{X(g(Y,Z))+Y(g(Z,X))−Z(g(X,Y))+g(Z,[X,Y])+g(Y,[Z,X])−g(X,[Y,Z])}g\\left(\\nabla_{X} Y, Z\\right)=\\frac{1}{2}\\{X(g(Y, Z))+Y(g(Z, X))-Z(g(X, Y))+g(Z,[X, Y])+g(Y,[Z, X])-g(X,[Y, Z])\\} g(∇X​Y,Z)=21​{X(g(Y,Z))+Y(g(Z,X))−Z(g(X,Y))+g(Z,[X,Y])+g(Y,[Z,X])−g(X,[Y,Z])} 称为MMM 上的黎曼联络，或Levi-Civita联络 证明：参考定理4.7 对任意X,Y1,Y2,Z∈Γ(TM),λ,μ∈RX,Y_1,Y_2,Z \\in \\Gamma(TM),\\lambda,\\mu \\in \\mathbb{R}X,Y1​,Y2​,Z∈Γ(TM),λ,μ∈R，根据李括号的定义，并利用ggg 是一个张量场易得 g(∇X(λ⋅Y1+μ⋅Y2),Z)=λ⋅g(∇XY1,Z)+μ⋅g(∇XY2,Z)g(∇Y1+Y2X,Z)=g(∇Y1X,Z)+g(∇Y2X,Z)\\begin{array}{c} g\\left(\\nabla_{X}\\left(\\lambda \\cdot Y_{1}+\\mu \\cdot Y_{2}\\right), Z\\right)=\\lambda \\cdot g\\left(\\nabla_{X} Y_{1}, Z\\right)+\\mu \\cdot g\\left(\\nabla_{X} Y_{2}, Z\\right) \\\\ g\\left(\\nabla_{Y_{1}+Y_{2}} X, Z\\right)=g\\left(\\nabla_{Y_{1}} X, Z\\right)+g\\left(\\nabla_{Y_{2}} X, Z\\right) \\end{array} g(∇X​(λ⋅Y1​+μ⋅Y2​),Z)=λ⋅g(∇X​Y1​,Z)+μ⋅g(∇X​Y2​,Z)g(∇Y1​+Y2​​X,Z)=g(∇Y1​​X,Z)+g(∇Y2​​X,Z)​ 进一步，对任意的f∈C∞(M)f \\in C^{\\infty}(M)f∈C∞(M)，有 g(∇XfY,Z)=12{X(f⋅g(Y,Z))+f⋅Y(g(Z,X))−Z(f⋅g(X,Y))+g(Z,[X,f⋅Y])+f⋅g(Y,[Z,X])−g(X,[f⋅Y,Z])}=12{X(f)⋅g(Y,Z)+f⋅X(g(Y,Z))+f⋅Y(g(Z,X))−Z(f)⋅g(X,Y)−f⋅Z(g(X,Y))+g(Z,X(f)⋅Y+f⋅[X,Y])+f⋅g(Y,[Z,X])−g(X,−Z(f)⋅Y+f⋅[Y,Z])}=X(f)⋅g(Y,Z)+f⋅g(∇XY,Z)=g(X(f)⋅Y+f⋅∇XY,Z)\\begin{aligned} g\\left(\\nabla_{X} f Y, Z\\right)=&amp; \\frac{1}{2}\\{X(f \\cdot g(Y, Z))+f \\cdot Y(g(Z, X))-Z(f \\cdot g(X, Y))\\\\ &amp;+g(Z,[X, f \\cdot Y])+f \\cdot g(Y,[Z, X])-g(X,[f \\cdot Y, Z])\\} \\\\ =&amp; \\frac{1}{2}\\{X(f) \\cdot g(Y, Z)+f \\cdot X(g(Y, Z))+f \\cdot Y(g(Z, X))\\\\ &amp;-Z(f) \\cdot g(X, Y)-f \\cdot Z(g(X, Y))+g(Z, X(f) \\cdot Y+f \\cdot[X, Y]) \\\\ &amp;+f \\cdot g(Y,[Z, X])-g(X,-Z(f) \\cdot Y+f \\cdot[Y, Z])\\} \\\\ =&amp; X(f) \\cdot g(Y, Z)+f \\cdot g\\left(\\nabla_{X} Y, Z\\right) \\\\ =&amp; g\\left(X(f) \\cdot Y+f \\cdot \\nabla_{X} Y, Z\\right) \\end{aligned} g(∇X​fY,Z)====​21​{X(f⋅g(Y,Z))+f⋅Y(g(Z,X))−Z(f⋅g(X,Y))+g(Z,[X,f⋅Y])+f⋅g(Y,[Z,X])−g(X,[f⋅Y,Z])}21​{X(f)⋅g(Y,Z)+f⋅X(g(Y,Z))+f⋅Y(g(Z,X))−Z(f)⋅g(X,Y)−f⋅Z(g(X,Y))+g(Z,X(f)⋅Y+f⋅[X,Y])+f⋅g(Y,[Z,X])−g(X,−Z(f)⋅Y+f⋅[Y,Z])}X(f)⋅g(Y,Z)+f⋅g(∇X​Y,Z)g(X(f)⋅Y+f⋅∇X​Y,Z)​ 以及 g(∇f⋅XY,Z)=12{f⋅X(g(Y,Z))+Y(f⋅g(Z,X))−Z(f⋅g(X,Y))+g(Z,[f⋅X,Y])+g(Y,[Z,f⋅X])−f⋅g(X,[Y,Z])}=12{f⋅X(g(Y,Z))+Y(f)⋅g(Z,X)+f⋅Y(g(Z,X))−Z(f)⋅g(X,Y)−f⋅Z(g(X,Y))+g(Z,−Y(f)⋅X)+g(Z,f⋅[X,Y])+g(Y,Z(f)⋅X)+f⋅g(Y,[Z,X])−f⋅g(X,[Y,Z])}=f⋅g(∇XY,Z)\\begin{aligned} g\\left(\\nabla_{f \\cdot X} Y, Z\\right)=&amp; \\frac{1}{2}\\{f \\cdot X(g(Y, Z))+Y(f \\cdot g(Z, X))-Z(f \\cdot g(X, Y))+g(Z,[f \\cdot X, Y])\\\\ &amp;+g(Y,[Z, f \\cdot X])-f \\cdot g(X,[Y, Z])\\} \\\\ =&amp; \\frac{1}{2}\\{f \\cdot X(g(Y, Z))+Y(f) \\cdot g(Z, X)+f \\cdot Y(g(Z, X))\\\\ &amp;-Z(f) \\cdot g(X, Y)-f \\cdot Z(g(X, Y))+g(Z,-Y(f) \\cdot X) \\\\ &amp;+g(Z, f \\cdot[X, Y])+g(Y, Z(f) \\cdot X)+f \\cdot g(Y,[Z, X])-f \\cdot g(X,[Y, Z])\\} \\\\ =&amp; f \\cdot g\\left(\\nabla_{X} Y, Z\\right) \\end{aligned} g(∇f⋅X​Y,Z)===​21​{f⋅X(g(Y,Z))+Y(f⋅g(Z,X))−Z(f⋅g(X,Y))+g(Z,[f⋅X,Y])+g(Y,[Z,f⋅X])−f⋅g(X,[Y,Z])}21​{f⋅X(g(Y,Z))+Y(f)⋅g(Z,X)+f⋅Y(g(Z,X))−Z(f)⋅g(X,Y)−f⋅Z(g(X,Y))+g(Z,−Y(f)⋅X)+g(Z,f⋅[X,Y])+g(Y,Z(f)⋅X)+f⋅g(Y,[Z,X])−f⋅g(X,[Y,Z])}f⋅g(∇X​Y,Z)​ 证毕 曲率张量的定义以及性质 设 ((M,∇))( (M, \\nabla) )((M,∇)) 是 mmm 维仿射联络空间. 对任意的 $ X, Y, Z \\in \\Gamma(T M)$, 定义 R(X,Y):Γ(TM)→Γ(TM)R(X, Y): \\Gamma(T M) \\rightarrow \\Gamma(T M)R(X,Y):Γ(TM)→Γ(TM) 为 R(X,Y)Z=∇X,Y2Z−∇Y,X2Z=∇X∇YZ−∇Y∇XZ−∇[X,Y]ZR(X, Y) Z=\\nabla_{X, Y}^{2} Z-\\nabla_{Y, X}^{2} Z=\\nabla_{X} \\nabla_{Y} Z-\\nabla_{Y} \\nabla_{X} Z-\\nabla_{[X, Y]} Z R(X,Y)Z=∇X,Y2​Z−∇Y,X2​Z=∇X​∇Y​Z−∇Y​∇X​Z−∇[X,Y]​Z 称R(X,Y)R(X,Y)R(X,Y)为仿射联络空间(M,∇)(M,\\nabla)(M,∇) 关于光滑切向量场X,YX,YX,Y的曲率算子.RRR 是一个(1,3)(1,3)(1,3)型的光滑张 量场,称为仿射联络空间(M,∇)(M,\\nabla)(M,∇) 的曲率张量 设(M,∇)(M,\\nabla)(M,∇) 为仿射联络空间，则对任意的X,Y∈Γ(TM)X,Y \\in \\Gamma(TM)X,Y∈Γ(TM)，曲率算子R(X,Y)R(X,Y)R(X,Y) 具有下面的性质： $R(X, Y)=-R(Y, X) $ R(fX,Y)=R(X,fY)=fR(X,Y)R(f X, Y)=R(X, f Y)=f R(X, Y)R(fX,Y)=R(X,fY)=fR(X,Y) $ R(X, Y)(f Z)=f R(X, Y) Z $ 当 $ \\nabla $ 的抗率 T≡0T \\equiv 0T≡0 时 R(X,Y)Z+R(Z,X)Y+R(Y,Z)X=0R(X, Y) Z+R(Z, X) Y+R(Y, Z) X=0 R(X,Y)Z+R(Z,X)Y+R(Y,Z)X=0 其中 $ f \\in C^{\\infty}(M), Z \\in \\Gamma(T M) $ 黎曼曲率张量的定义以及性质 对于黎曼流形(M,g)(M,g)(M,g)，它有唯一确定的Levi-Civita联络∇\\nabla∇，它的曲率张量称为黎曼流形(M,g)(M,g)(M,g)的黎曼曲率张量. 设(M,g)(M,g)(M,g) 是黎曼流形，对任意X,Y,Z,W∈Γ(TM)X,Y,Z,W \\in \\Gamma(TM)X,Y,Z,W∈Γ(TM)，令 R(X,Y,Z,W)=g(R(Z,W)X,Y)\\mathcal{R}(X, Y, Z, W)=g(R(Z, W) X, Y) R(X,Y,Z,W)=g(R(Z,W)X,Y) 则得到一个四重线性映射 R(X,Y,Z,W)=g(R(Z,W)X,Y)\\mathcal{R}(X, Y, Z, W)=g(R(Z, W) X, Y) R(X,Y,Z,W)=g(R(Z,W)X,Y) 它是MMM 上的四阶协变张量场，称之为黎曼流形(M,g)(M,g)(M,g) 的黎曼曲率张量场 设(M,g)(M,g)(M,g) 是一个光滑的黎曼流形，则对任意X,Y,Z,W∈Γ(TM)X,Y,Z,W \\in \\Gamma(TM)X,Y,Z,W∈Γ(TM)，黎曼曲率张量场 R(X,Y,Z,W)=g(R(Z,W)X,Y)\\mathcal{R}(X, Y, Z, W)=g(R(Z, W) X, Y) R(X,Y,Z,W)=g(R(Z,W)X,Y) 具有下面的性质： 反对称性 R(X,Y,Z,W)=−R(Y,X,Z,W)\\mathcal{R}(X,Y,Z,W) = -\\mathcal{R}(Y,X,Z,W) R(X,Y,Z,W)=−R(Y,X,Z,W) R(X,Y,Z,W)=−R(X,Y,W,Z)\\mathcal{R}(X,Y,Z,W) = -\\mathcal{R}(X,Y,W,Z) R(X,Y,Z,W)=−R(X,Y,W,Z) 第一Bianchi恒等式 R(X,Y,Z,W)+R(Z,Y,W,X)+R(W,Y,X,Z)=0\\mathcal{R}(X,Y,Z,W) + \\mathcal{R}(Z,Y,W,X) + \\mathcal{R}(W,Y,X,Z) = 0 R(X,Y,Z,W)+R(Z,Y,W,X)+R(W,Y,X,Z)=0 对称性 R(X,Y,Z,W)=R(Z,W,X,Y)\\mathcal{R}(X,Y,Z,W) = \\mathcal{R}(Z,W,X,Y) R(X,Y,Z,W)=R(Z,W,X,Y) **在三维光滑流形M=R3M = \\mathbb{R}^3M=R3 上，令α=dx1−x1dx2∈Ω1(M),β=x2dx1∧dx3−dx2∧dx3∈Ω2(M)\\alpha = dx^1 - x^1 dx^2 \\in \\Omega^1(M), \\beta = x^2dx^1 \\wedge dx^3 - dx^2 \\wedge dx^3 \\in \\Omega^2(M)α=dx1−x1dx2∈Ω1(M),β=x2dx1∧dx3−dx2∧dx3∈Ω2(M) ，计算 dα,dβd \\alpha, d \\betadα,dβ 以及 α∧β\\alpha \\wedge \\betaα∧β ** dα=−dx1∧dx2dβ=dx2∧dx1∧dx3d \\alpha = -dx^1 \\wedge dx^2 \\qquad d \\beta = dx^2 \\wedge dx^1 \\wedge dx^3 dα=−dx1∧dx2dβ=dx2∧dx1∧dx3 α∧β=−dx1∧dx2∧dx3−x1dx2∧x2dx1∧dx3=(x1x2−1)dx1∧dx2∧dx3\\begin{aligned} \\alpha \\wedge \\beta &amp;= -dx^1 \\wedge dx^2 \\wedge dx^3 - x^1 dx^2 \\wedge x^2 dx^1 \\wedge dx^3 \\\\ &amp;= (x^1 x^2 -1)dx^1 \\wedge dx^2 \\wedge dx^3 \\end{aligned} α∧β​=−dx1∧dx2∧dx3−x1dx2∧x2dx1∧dx3=(x1x2−1)dx1∧dx2∧dx3​ 在R3R^3R3 上定义三个光滑向量场如下： X=y∂∂x−x∂∂y,Y=z∂∂y−y∂∂z,Z=∂∂x+∂∂y+2∂∂zX=y \\frac{\\partial}{\\partial x} - x \\frac{\\partial}{\\partial y}, \\quad Y=z \\frac{\\partial}{\\partial y}-y \\frac{\\partial}{\\partial z},\\quad Z=\\frac{\\partial}{\\partial x} +\\frac{\\partial}{\\partial y} + 2\\frac{\\partial}{\\partial z} X=y∂x∂​−x∂y∂​,Y=z∂y∂​−y∂z∂​,Z=∂x∂​+∂y∂​+2∂z∂​ 求[X,Y][X,Y][X,Y]和[Y,Z][Y,Z][Y,Z] [X,Y]=X(Y−Y(X=(y∂∂x−x∂∂y)(z∂∂y−y∂∂z)−(z∂∂y−y∂∂z)(y∂∂x−x∂∂y)=yz∂2∂x∂y−y2∂2∂x∂z−xz∂2∂y2+x∂∂z+xy∂2∂y∂z−(z∂∂x+zy∂2∂y∂x−zx∂2∂y2−y2∂2∂z∂x+yx∂2∂z∂y)=x∂∂z−z∂∂x\\begin{aligned} \\left[X,Y\\right] &amp;= X(Y - Y(X \\\\ &amp;= (y \\frac{\\partial}{\\partial x} - x \\frac{\\partial}{\\partial y})(z \\frac{\\partial }{\\partial y}-y \\frac{\\partial }{\\partial z}) - (z \\frac{\\partial}{\\partial y}-y \\frac{\\partial}{\\partial z})(y \\frac{\\partial}{\\partial x} - x \\frac{\\partial}{\\partial y}) \\\\ &amp;= yz\\frac{\\partial ^2}{\\partial x \\partial y} - y^2 \\frac{\\partial ^2}{\\partial x \\partial z} - xz\\frac{\\partial ^2}{\\partial y^2} + x \\frac{\\partial }{\\partial z} + xy\\frac{\\partial ^2}{\\partial y \\partial z}\\\\ &amp;- (z \\frac{\\partial }{\\partial x} + zy\\frac{\\partial ^2}{\\partial y \\partial x} - zx \\frac{\\partial ^2}{\\partial y^2} - y^2\\frac{\\partial ^2}{\\partial z \\partial x} + yx\\frac{\\partial ^2}{\\partial z \\partial y}) \\\\ &amp;= x \\frac{\\partial }{\\partial z} - z \\frac{\\partial }{\\partial x} \\end{aligned} [X,Y]​=X(Y−Y(X=(y∂x∂​−x∂y∂​)(z∂y∂​−y∂z∂​)−(z∂y∂​−y∂z∂​)(y∂x∂​−x∂y∂​)=yz∂x∂y∂2​−y2∂x∂z∂2​−xz∂y2∂2​+x∂z∂​+xy∂y∂z∂2​−(z∂x∂​+zy∂y∂x∂2​−zx∂y2∂2​−y2∂z∂x∂2​+yx∂z∂y∂2​)=x∂z∂​−z∂x∂​​ [Y,Z]=(z∂∂y−y∂∂z)(∂∂x+∂∂y+2∂∂z)−(∂∂x+∂∂y+2∂∂z)(z∂∂y−y∂∂z)=z∂2∂y∂x+z∂2∂y2+z∂2∂y∂z−y∂2∂z∂x−y∂2∂z∂y−y∂2∂z2−(z∂∂x∂y−y∂2∂x∂z+z∂2∂y2−∂∂z−y∂2∂y∂z+∂∂y+z∂2∂z∂y−y∂2∂z2)=∂∂z−∂∂y\\begin{aligned} \\left[Y,Z\\right] &amp;= (z \\frac{\\partial}{\\partial y}-y \\frac{\\partial}{\\partial z})(\\frac{\\partial}{\\partial x} +\\frac{\\partial}{\\partial y} + 2\\frac{\\partial}{\\partial z}) -(\\frac{\\partial}{\\partial x} +\\frac{\\partial}{\\partial y} + 2\\frac{\\partial}{\\partial z})(z \\frac{\\partial}{\\partial y}-y \\frac{\\partial}{\\partial z}) \\\\ &amp;= z\\frac{\\partial ^2}{\\partial y \\partial x} + z \\frac{\\partial ^2}{\\partial y^2} + z \\frac{\\partial ^2}{\\partial y \\partial z} - y \\frac{\\partial ^ 2}{\\partial z \\partial x} - y\\frac{\\partial ^2}{\\partial z \\partial y} - y \\frac{\\partial ^ 2}{\\partial z^2}\\\\ &amp;- (z\\frac{\\partial}{\\partial x \\partial y} - y \\frac{\\partial ^2}{\\partial x \\partial z} + z \\frac{\\partial ^2}{\\partial y^2} - \\frac{\\partial}{\\partial z} - y \\frac{\\partial ^ 2}{\\partial y \\partial z} + \\frac{\\partial}{\\partial y} + z \\frac{\\partial ^2}{\\partial z \\partial y} - y \\frac{\\partial ^ 2}{\\partial z^2})\\\\ &amp;= \\frac{\\partial}{\\partial z} - \\frac{\\partial}{\\partial y} \\end{aligned} [Y,Z]​=(z∂y∂​−y∂z∂​)(∂x∂​+∂y∂​+2∂z∂​)−(∂x∂​+∂y∂​+2∂z∂​)(z∂y∂​−y∂z∂​)=z∂y∂x∂2​+z∂y2∂2​+z∂y∂z∂2​−y∂z∂x∂2​−y∂z∂y∂2​−y∂z2∂2​−(z∂x∂y∂​−y∂x∂z∂2​+z∂y2∂2​−∂z∂​−y∂y∂z∂2​+∂y∂​+z∂z∂y∂2​−y∂z2∂2​)=∂z∂​−∂y∂​​","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"现代微分几何","slug":"现代微分几何","permalink":"/tags/现代微分几何/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"实验室快速上手教程","slug":"实验室快速上手","date":"2020-09-12T07:06:10.341Z","updated":"2020-09-13T10:01:07.383Z","comments":true,"path":"2020/09/12/实验室快速上手/","link":"","permalink":"/2020/09/12/实验室快速上手/","excerpt":"","text":"基础篇 Ubuntu系统的基本使用 终端基本命令 快捷键ctrl + alt + T打开终端 终端基本使用方法： $ cd path # 切换到目录 $ ls # 列出当前目录下的文件 $ pwd # 查看当前所在目录 $ cp file path # 文件复制到另一个目录 $ rm file # 删除文件 $ rm -rf path # 删除文件夹 $ touch file # 新建文件 $ mkdir dir_name # 新建文件夹 $ cat file # 查看文件内容(内容为文本的文件) $ gedit file # 利用gedit文本编辑器编辑文本 $ vim file # 利用vim编辑文本 $ nvidia-smi # 查看当前显卡状态 $ top # 查看当前内存、cpu等使用状态 $ mv filename newfilename # 文件或文件夹的重命名，也可以用来移动文件或文件夹 $ bash file.sh # 执行sh文件 $ tar -zxvf file # 解压文件 $ sudo dpkg -i file # 安装.deb文件(类似windows中的exe文件) $ chmod 777 file # 开放文件权限 $ chmod 777 -R file # 开放文件夹权限 补充： .. 代表上级文件夹 按Tab 键可自动补全 sudo代表使用管理员权限，当出现permission denied或权限不足提示时，首先尝试在命令前加sudo 需要安装的基本应用 Nvidia显卡驱动 CUDA CUDNN Pycharm Anaconda（或miniconda） 安装过程自行搜索，或者参考我的另一篇博客传送门 实验和代码 实验环境 首先安装好上面的基本应用 以pixel2pixel 为例： # 创建conda环境，环境名为pix2pix，python版本为3.6 $ conda create -n pix2pix python=3.6 # 激活conda环境 $ conda activate pix2pix # 安装所需的python第三方包，pytorch等 $ conda install pytorch $ conda install torchvision $ conda install visdom $ pip install dominate 然后按照实验的README下载数据集，运行代码等 一些常见问题： 兼容问题 例如pytorch不同版本和tensorflow不同版本之间的函数接口可能不同(pytorch还好，tensorflow这个问题比较严重)；python、cuda、cudnn、pytorch、tensorflow等版本互相不兼容等问题 解决：安装对应的版本，以pytorch为例： # 寻找pytorch所有版本(我在结果里删掉了一部分便于显示) $ conda search pytorch Loading channels: done # Name Version Build Channel pytorch 0.4.1 py37ha74772b_0 pkgs/main pytorch 1.0.1 cuda100py27he554f03_0 pkgs/main pytorch 1.0.1 cuda80py27ha8650f8 pkgs/main pytorch 1.0.1 cuda80py36ha8650f8_0 pkgs/main pytorch 1.1.0 cuda92py36h65efead_0 pkgs/main pytorch 1.1.0 cuda92py37h65efead_0 pkgs/main pytorch 1.2.0 cpu_py27h00be3c6_0 pkgs/main pytorch 1.2.0 cuda92py36hd3e106c_0 pkgs/main pytorch 1.2.0 cuda92py37hd3e106c_0 pkgs/main pytorch 1.3.1 cpu_py37h62f834f_0 pkgs/main # 安装对应的版本： $ conda install pytorch==1.3.1 或 $ conda install pytorch=1.3.1=cpu_py37h62f834f_0 注意到conda search pytorch 的build列中可能会出现cpu…/py…/.cuda…cudnn…等，其含义： cpu：pytorch是在cpu环境下编译的，安装这种类型的包一般无法使用GPU py: python版本，例如py37指实在python3.7环境下编译的(python2和python3之间可能会起冲突，一般python2.几内部和python3.几内部影响不大) cuda: cuda版本,安装后会自动下载cudatookit，可以代替电脑中的cuda使用。例如cuda92代表在cuda9.2环境下编译 cudnn： cudnn版本，安装后自动下载cudnn，可以代替电脑中的cudnn使用。 因此多数情况下的cudnn error、cuda问题等直接通过conda解决更好解决。 cuda问题 cuda爆显存：CUDA out of memory 一般情况下是由于batch-size较大导致的，尝试减小batch-size 如果是因为模型太大，参数量太多，改代码减少参数量或者换去服务器里多调用几块显卡 $ watch nvidia-smi 去观察显存使用情况，如果显存逐渐升高然后爆显存，大多是因为在执行测试或evaluation时没有阻止反向传播，修改测试部分的代码： with torch.no_grad(): model.test() cuda,cudnn版本问题：首先尝试用conda install 去安装不同版本的cudatookit或cudnn，如果失败建议使用docker搭建环境。 cuda和cudatookit的区别 大多数情况下使用cudatookit就足够了，必须使用电脑中的cuda实际是需要使用gcc,g++,nvcc等，例如PointNet++的tensorflow代码中需要使用nvcc编译一部分代码。 有些古老版本的代码会直接和显卡冲突 没找到解决方案，感觉无解…… 实验室还有几块1080Ti的显卡，借着用一下 看代码、修改代码 初学建议使用Pycharm中的debug逐行看代码，观察代码的运行过程。 可以参考这篇文章——&gt; 传送门 在pycharm中运行和debug代码需要提前配置好python环境： File————&gt; Settings————&gt; Project Interpreter————&gt; 小齿轮————&gt; Add————&gt;Conda environment————&gt; Existing environment————&gt; 更改Interpreter的位置 注: ununtu中默认的conda环境位置为：/home/username/anaconda3/envs/envname/bin/python 服务器的使用 详细使用教程见另一篇博客 传送门 进阶篇 科学上网 上外网下载数据集，可以找机场节点(一般是用ssr代理)，对应的客户端为： windows: shadosocksR ubuntu: electron-ssr mac: ShadowsocksX-NG-R 有些机场也有v2ray代理的节点，对应客户端为： Windows:·v2rayN Mac:v2rayU Linux:v2rayL 我自搭的v2ray节点分享出来(速度一般)： vmess://ewogICJ2IjogIjIiLAogICJwcyI6ICJ3dWxhYmluZ19jbG91ZC56YXNldmVuemFlaWdodC50b3AiLAogICJhZGQiOiAiY2xvdWQuemFzZXZlbnphZWlnaHQudG9wIiwKICAicG9ydCI6ICI1NTU1IiwKICAiaWQiOiAiMjVjNTc3NWItYTdkMi00ZmY5LWJlNjgtMjdjZWE2MjA4NGFiIiwKICAiYWlkIjogIjIiLAogICJuZXQiOiAid3MiLAogICJ0eXBlIjogIm5vbmUiLAogICJob3N0IjogImNsb3VkLnphc2V2ZW56YWVpZ2h0LnRvcCIsCiAgInBhdGgiOiAiLzkwMTBiNzllLyIsCiAgInRscyI6ICJ0bHMiCn0K 复制后，在v2ray客户端中导入 注： ssr的作者被请去喝茶了，现在ssr已经不再更新，并且ssr容易被监测到，推荐使用v2ray。 利用Git进行版本控制 基本命令参考另一篇博客 传送门 利用tensorboardX进行结果可视化： 参考： ref1. ​ ref2. 利用Docker搭建环境，防止冲突 当环境问题和系统的cuda版本、cudnn版本，以及一些内核文件冲突时，推荐使用Docker。 Dockerhub 参考 利用Neptune调参、模型可视化等 ref Neptune","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"实验室","slug":"实验室","permalink":"/tags/实验室/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"neptune","slug":"Neptune","date":"2020-09-12T06:42:00.000Z","updated":"2020-09-12T06:51:30.153Z","comments":true,"path":"2020/09/12/Neptune/","link":"","permalink":"/2020/09/12/Neptune/","excerpt":"","text":"Getting started Neptune 比较和调试ML实验和模型 监测实验结果 保存模型、参数 监测GPU利用状态 Install Neptune client library $ pip install neptune-client # or $ conda install -c conda-forge neptune-client Copy and export your API token 在~/.bashrc 中添加 export NEPTUNE_API_TOKEN=\"your API token\" 执行 $ source ~\\.bashrc 测试 新建python文件，执行 import neptune # The init() function called this way assumes that # NEPTUNE_API_TOKEN environment variable is defined. neptune.init('ybb-ybb/sandbox') neptune.create_experiment(name='minimal_example') # log some metrics for i in range(100): neptune.log_metric('loss', 0.95**i) neptune.log_metric('AUC', 0.96) $ bash main.py 使用 create an experiment 定义参数运行新实验： # Define parameters PARAMS = {'decay_factor' : 0.5, 'n_iterations' : 117} # Create experiment with defined parameters neptune.create_experiment (name='example_with_parameters', params=PARAMS) 记录图像： # Log image data import numpy as np array = np.random.rand(10, 10, 3)*255 array = np.repeat(array, 30, 0) array = np.repeat(array, 30, 1) neptune.log_image('mosaics', array) 记录文本 # Log image data import numpy as np array = np.random.rand(10, 10, 3)*255 array = np.repeat(array, 30, 0) array = np.repeat(array, 30, 1) neptune.log_image('mosaics', array) 保存模型 # log some file # replace this file with your own file from local machine neptune.log_artifact('model_weights.pkl') # log file to some specific directory (see second parameter below) # replace this file with your own file from local machine neptune.log_artifact('model_checkpoints/checkpoint_3.pkl', 'training/model_checkpoints/checkpoint_3.pkl') 上传代码 # Upload source code # replace these two source files with your own files. neptune.create_experiment(upload_source_files=['main.py', 'model.py']) 标签 # add tag when experiment is created neptune.create_experiment(tags=['training']) # add single tag neptune.append_tag('transformer') # add few tags at once neptune.append_tags('BERT', 'ELMO', 'ideas-exploration')","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"实验室","slug":"实验室","permalink":"/tags/实验室/"},{"name":"neptune","slug":"neptune","permalink":"/tags/neptune/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"python序列方法","slug":"python序列方法","date":"2020-08-17T13:49:00.000Z","updated":"2020-08-17T13:51:04.318Z","comments":true,"path":"2020/08/17/python序列方法/","link":"","permalink":"/2020/08/17/python序列方法/","excerpt":"","text":"注：有些方法在 python2 中不存在 列表方法 通过列表推导式创建列表 &gt;&gt;&gt; x=[i**2 for i in range(3)] &gt;&gt;&gt; x [0, 1, 4] append : 将一个对象附加到列表末尾 clear ：就地清空列表内容 copy ： 复制列表 count ： 计算指定元素在列表中出现了多少次 extend ： 使用列表扩展另一个列表 index ： 查找指定值第一次出现的索引 insert ： 讲一个对象插入列表 pop ： 从列表删除一个元素(默认最后一个元素)，并返回这一元素 remove ： 删除第一个为指定值的元素 reverse ： 按相反的顺序排列列表中的元素 sort ： 对列表就地排序，接受两个可选参数key和values。 &gt;&gt;&gt; lst = [1, 2, 3] &gt;&gt;&gt; lst.append(4) &gt;&gt;&gt; lst [1, 2, 3, 4] &gt;&gt;&gt; lst.clear() &gt;&gt;&gt; lst [] &gt;&gt;&gt; a = [1, 2, 3] &gt;&gt;&gt; b=a.copy() &gt;&gt;&gt; b [1, 2, 3] &gt;&gt;&gt; a.count(1) 1 &gt;&gt;&gt; a.extend(b) &gt;&gt;&gt; a [1, 2, 3, 1, 2, 3] &gt;&gt;&gt; a.index(2) 1 &gt;&gt;&gt; a.insert(1,4) &gt;&gt;&gt; a [1, 4, 2, 3, 1, 2, 3] &gt;&gt;&gt; a.pop() 3 &gt;&gt;&gt; a [1, 4, 2, 3, 1, 2] &gt;&gt;&gt; a.pop(0) 1 &gt;&gt;&gt; a [4, 2, 3, 1, 2] &gt;&gt;&gt; a.remove(1) &gt;&gt;&gt; a [4, 2, 3, 2] &gt;&gt;&gt; a.reverse() &gt;&gt;&gt; a [2, 3, 2, 4] &gt;&gt;&gt; a.sort() &gt;&gt;&gt; a [2, 2, 3, 4] &gt;&gt;&gt; a.sort(key=lambda x : x % 3,reverse=True) &gt;&gt;&gt; a [2, 2, 4, 3] 字符串方法 center ： 通过在字符串两边添加填充字符使字符串居中 find ：在字符串中查找子串，找到则返回子串第一个字符的索引，否则返回 -1(可指定起点值和终点值) join ： 合并序列的元素，与 split 相反 lower ： 返回字符串的小写版本 replace ： 将指定子串都替换为另一个字符串，并返回替换后的结果 split ： 与 join 相反，将字符串拆分为序列 strip ： 将字符串开头和末尾的指定字符删除 isspace ： 是否是空格 isdight ： 是否是数字 isupper : 是否是大写字母 islower ： 是否是小写字母 &gt;&gt;&gt; x=\"Hello World!\" &gt;&gt;&gt; x.center(15) ' Hello World! ' &gt;&gt;&gt; x.center(15,'*') '**Hello World!*' &gt;&gt;&gt; x.find('llo') 2 &gt;&gt;&gt; x.find('llo',3) -1 &gt;&gt;&gt; seq = ['1','2','3'] &gt;&gt;&gt; '+'.join(seq) '1+2+3' &gt;&gt;&gt; x.lower() 'hello world!' &gt;&gt;&gt; x.replace('hello','Hello') 'Hello World!' &gt;&gt;&gt; x.split() ['Hello', 'World!'] &gt;&gt;&gt; x = x.center(15,'*') &gt;&gt;&gt; x '**Hello World!*' &gt;&gt;&gt; x.strip('*') 'Hello World!' &gt;&gt;&gt; x '**Hello World!*' 字典 创建字典：通过键——值对序列或者字典推导式创建 &gt;&gt;&gt; items = [('name','Gumby'),('age',42)] &gt;&gt;&gt; d=dict(items) &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; d=dict(name='Gumby',age=42) &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; x={i:i ** 2 for i in range(3)} &gt;&gt;&gt; x {0: 0, 1: 1, 2: 4} **clear ** ：删除所有字典项 copy ： 返回一个新字典，包含的键值对与原字典相同 fromkeys ：创建一个新字典，包含指定的键，且每个键对应的值都是None，可指定对应的默认值 get ：访问不存在的建时返回None，可指定返回值 items ： 返回一个包含所有字典项的列表，其中每个元素都是（key,value）的形式 pop ： 获取与指定键相关联的值，并将该键值对从字典中删除 popitem ： 随机弹出一个字典项 setdefault ： 类似get ，当字典中不包含指定的键时，在字典中添加指定的键值对 update ： 使用一个字典中的项来更新另一个字典 keys ： 返回一个字典视图，其中包含字典中的键 values ： 返回一个字典视图，其中包含字典中的值 &gt;&gt;&gt; d=dict(name='Gumby',age=42) &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; d.clear() &gt;&gt;&gt; d {} &gt;&gt;&gt; d=dict(name='Gumby',age=42) &gt;&gt;&gt; x=d.copy() &gt;&gt;&gt; x {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; {}.fromkeys(['name','age']) {'name': None, 'age': None} &gt;&gt;&gt; {}.fromkeys(['name','age'],False) {'name': False, 'age': False} &gt;&gt;&gt; x.get('score') &gt;&gt;&gt; x.items() dict_items([('name', 'Gumby'), ('age', 42)]) IndentationError: expected an indented block &gt;&gt;&gt; for key,value in x.items(): ... print(value) Gumby 42 &gt;&gt;&gt; x {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; x.pop('name') 'Gumby' &gt;&gt;&gt; x.popitem() ('age', 42) &gt;&gt;&gt; x {} &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42} &gt;&gt;&gt; d.setdefault('name','N/A') 'Gumby' &gt;&gt;&gt; d.setdefault('score','N/A') 'N/A' &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42, 'score': 'N/A'} &gt;&gt;&gt; x={'score':88} &gt;&gt;&gt; d.update(x) &gt;&gt;&gt; d {'name': 'Gumby', 'age': 42, 'score': 88} &gt;&gt;&gt; x.keys() dict_keys(['name', 'age']) &gt;&gt;&gt; x.values() dict_values(['Gumby', 42])","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"python","slug":"python","permalink":"/tags/python/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"十大排序算法","slug":"排序算法","date":"2020-06-27T01:44:00.000Z","updated":"2020-06-27T02:10:11.063Z","comments":true,"path":"2020/06/27/排序算法/","link":"","permalink":"/2020/06/27/排序算法/","excerpt":"","text":"算法 算法部分的介绍在十大经典排序算法动画与解析，看我就够了！ 关于时间复杂度： 平方阶 (O(n2))(O(n^2))(O(n2)) 排序 各类简单排序：插入排序、选择排序和冒泡排序。 线性对数阶$ (O(nlog2n))$ 排序：快速排序、堆排序和归并排序； O(n+§))O(n+§))O(n+§)) 排序，§§§ 是介于 0 和 1 之间的常数。 希尔排序 线性阶 (O(n)) 排序 基数排序，此外还有桶、箱排序 关于稳定性： 稳定的排序算法：冒泡排序、插入排序、归并排序和基数排序。 不是稳定的排序算法：选择排序、快速排序、希尔排序、堆排序。 python实现 冒泡排序 def bubblesort(arr): n=len(arr) for i in range(n): for j in range(n-i-1): if arr[j] &gt; arr[j+1]: arr[j],arr[j+1]=arr[j+1],arr[j] return arr if __name__ == '__main__': arr = [5,4,2,3,8] bubblesort(arr) print(arr) 选择排序 def selectionsort(arr): n = len(arr) for i in range(n): min =i for j in range(i, n): if arr[j] &lt; arr[i]: min =j arr[min], arr[i] = arr[i], arr[min] return arr if __name__ == '__main__': arr=[5,4,2,3,8] selectionsort(arr) print(arr) 插入排序 def insertionSort(arr): for i in range(1, len(arr)): key = arr[i] j = i - 1 while j &gt;= 0 and key &lt; arr[j]: arr[j + 1] = arr[j] j -= 1 arr[j + 1] = key if __name__ == '__main__': arr = [5,4,2,3,8] insertionSort(arr) print(arr) 希尔排序 def shellsort(arr): n = len(arr) gap = n while gap &gt; 0: gap = gap // 2 for i in range(gap, n): key = arr[i] j = i - gap while j &gt;= 0 and key &lt; arr[j]: arr[j + gap] = arr[j] j -= gap arr[j + gap] = key return arr if __name__ == '__main__': arr = [5, 4, 2, 3, 8] shellsort(arr) print(arr) 归并排序 def sorttwoarray(arr_left, arr_right): m, n, i, j = len(arr_left), len(arr_right), 0, 0 arr = [] while i &lt; m and j &lt; n: if arr_left[i] &lt; arr_right[j]: arr.append(arr_left[i]) i += 1 else: arr.append(arr_right[j]) j += 1 arr.extend(arr_left[i:m]) arr.extend(arr_right[j:n]) return arr def mergesort(arr): n = len(arr) arr_left = arr[:(n + 1) // 2] arr_right = arr[(n + 1) // 2:] if len(arr_left) == 1: return sorttwoarray(arr_left, arr_right) else: return sorttwoarray(mergesort(arr_left), mergesort(arr_right)) if __name__ == '__main__': arr = [6, 4, 3, 7, 5, 1, 2] array = mergesort(arr) print(array) 快速排序 # -*- coding: UTF-8 -*- # 《算法导论》中的快速排序 def quick_sort(array, l, r): if l &lt; r: q = partition(array, l, r) quick_sort(array, l, q - 1) quick_sort(array, q + 1, r) def partition(array, l, r): x = array[r] i = l - 1 for j in range(l, r): if array[j] &lt;= x: i += 1 array[i], array[j] = array[j], array[i] array[i + 1], array[r] = array[r], array[i + 1] return i + 1 if __name__ == '__main__': arr = [6, 4, 3, 7, 5, 1, 2] quick_sort(arr,0,6) print(arr) 堆排序 # -*- coding: UTF-8 -*- def heapify(arr, n, i): largest = i l = 2 * i + 1 # left = 2*i + 1 r = 2 * i + 2 # right = 2*i + 2 if l &lt; n and arr[i] &lt; arr[l]: largest = l if r &lt; n and arr[largest] &lt; arr[r]: largest = r if largest != i: arr[i], arr[largest] = arr[largest], arr[i] # 交换 heapify(arr, n, largest) def heapSort(arr): n = len(arr) # Build a maxheap. for i in range(n, -1, -1): heapify(arr, n, i) # 一个个交换元素 for i in range(n - 1, 0, -1): arr[i], arr[0] = arr[0], arr[i] # 交换 heapify(arr, i, 0) if __name__ == '__main__': arr = [5, 2, 7, 3, 6, 1, 4] heapSort(arr) print (arr), 计数排序 def countingsort(arr): n = len(arr) min_arr = min(arr) max_arr = max(arr) length = max_arr - min_arr + 1 newarr = [0] * length sort_arr = [] for i in arr: newarr[i - min_arr] += 1 for i in range(length): sort_arr += [i + min_arr] * newarr[i] return sort_arr if __name__ == '__main__': arr = [5, 3, 4, 7, 2, 4, 3, 4, 7] sort_arr = countingsort(arr) print(sort_arr) 桶排序 def bucketsort(arr, num_bucket): min_arr = min(arr) max_arr = max(arr) buckets = [[] for i in range(num_bucket)] size = (max_arr - min_arr + 1) / num_bucket sorted_arr = [] for i in arr: index = (i - min_arr) // size buckets[index].append(i) for i in buckets: sorted_arr += (sorted(i)) return sorted_arr if __name__ == '__main__': arr = [7, 12, 56, 23, 19, 33, 35, 42, 42, 2, 8, 22, 39, 26, 17] sort_arr = bucketsort(arr, 5) print(sort_arr) 基数排序 def radixsort(arr): d = 1 max_arr = max(arr) while max_arr / 10 != 0: d += 1 max_arr /= 10 for i in range(d): s = [[] for k in range(10)] for j in arr: s[int(j / (10 ** i)) % 10].append(j) sorted_arr = [a for b in s for a in b] return sorted_arr if __name__ == '__main__': arr = [321, 1, 10, 30, 277, 753, 127] sorted_arr = radixsort(arr) print (sorted_arr)","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"python","slug":"python","permalink":"/tags/python/"},{"name":"排序","slug":"排序","permalink":"/tags/排序/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"终端使用socks5代理","slug":"终端socks5","date":"2020-06-26T10:32:00.000Z","updated":"2020-07-13T05:52:42.000Z","comments":true,"path":"2020/06/26/终端socks5/","link":"","permalink":"/2020/06/26/终端socks5/","excerpt":"","text":"proxychains安装 # git仓库中编译安装 $ git clone https://github.com/rofl0r/proxychains-ng.git $ cd proxychains-ng $ ./configure $ make &amp;&amp; make install $ cp ./src/proxychains.conf /etc/proxychains.conf $ cd .. &amp;&amp; rm -rf proxychains-ng # 或直接安装 $ brew install proxychains-ng 编辑proxychains配置 $ vim /etc/proxychains.conf 将sock4 127.0.0.1 9095 改为socks5 12.0.0.1 1080 (配置同ssr或v2ray客户端一致) 使用方法 在需要代理的命令前加上 proxychains4 ，如 $ proxychains4 wget http://xxx.com/xxx.zip","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"科学上网","slug":"科学上网","permalink":"/tags/科学上网/"},{"name":"代理","slug":"代理","permalink":"/tags/代理/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"screen","slug":"screen","date":"2020-05-28T10:49:00.000Z","updated":"2020-06-26T06:24:41.865Z","comments":true,"path":"2020/05/28/screen/","link":"","permalink":"/2020/05/28/screen/","excerpt":"","text":"安装 $ sudo apt-get install screen 使用 # 创建一个名为screen-name的会话 $ screen -S screen-name # 离开会话: ctrl+a+d # 恢复创建的会话 $ screen -r screen-name # 或，如果只有一个会话 $ screen -r # 查看已经创建的会话 $ screen -ls # 退出会话 $ exit 其它命令 Ctrl + a，d #暂离当前会话 Ctrl + a，c #在当前screen会话中创建一个子会话 Ctrl + a，w #子会话列表 Ctrl + a，p #上一个子会话 Ctrl + a，n #下一个子会话 Ctrl + a，0-9 #在第0窗口至第9子会话间切换 鼠标回滚 screen模式下，无法在终端中使用鼠标滚轴进行翻页，解决： ctrl + a +[ 进入回滚模式 ctrl + c 切换回之前模式","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"screen","slug":"screen","permalink":"/tags/screen/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"Numpy","slug":"numpy基础用法总结","date":"2020-04-24T03:38:00.000Z","updated":"2020-09-12T07:58:26.474Z","comments":true,"path":"2020/04/24/numpy基础用法总结/","link":"","permalink":"/2020/04/24/numpy基础用法总结/","excerpt":"","text":"基础篇 创建数组： # 通过list创建 &gt;&gt;&gt;np.array([[1, 2], [3, 4]]) array([[1, 2], [3, 4]]) # 通过arange创建 &gt;&gt;&gt;np.arange(0,1,0.1) array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]) # arange+广播 &gt;&gt;&gt;np.arange(1,60,10).reshape(-1,1)+np.arange(0,6) array([[ 1, 2, 3, 4, 5, 6], [11, 12, 13, 14, 15, 16], [21, 22, 23, 24, 25, 26], [31, 32, 33, 34, 35, 36], [41, 42, 43, 44, 45, 46], [51, 52, 53, 54, 55, 56]]) # linspace通过等差数列创建数组 &gt;&gt;&gt;np.linspace(0,1,10) array([0. , 0.11111111, 0.22222222, 0.33333333, 0.44444444, 0.55555556, 0.66666667, 0.77777778, 0.88888889, 1. ]) # 特殊形式数组 &gt;&gt;&gt;np.zeros((2,3),np.int) array([[0, 0, 0], [0, 0, 0]]) &gt;&gt;&gt;np.ones((2,3),np.int) array([[1, 1, 1], [1, 1, 1]]) # 长度为10，元素值为0-1的随机数数组 &gt;&gt;&gt;np.random.rand(2,3) array([[0.96064533, 0.55490284, 0.13219661], [0.3036712 , 0.95073354, 0.39364538]]) # 通过frombuffer,fromstring,fromfile和fromfunction等函数创建数组 &gt;&gt;&gt;np.fromfunction(lambda x,y:(x+1)*(y+1),(2,3)) array([[1., 2., 3.], [2., 4., 6.]]) # a和b之间的随机整数 &gt;&gt;&gt;np.random.randint(low=0,high=20,size=5) array([ 7, 19, 12, 18, 12]) 索引和切片 &gt;&gt;&gt;a=np.arange(5) &gt;&gt;&gt;a[2] 2 &gt;&gt;&gt;a[:2] array([0, 1]) &gt;&gt;&gt;a[:-1] array([0, 1, 2, 3]) # 加入步长 &gt;&gt;&gt;a[0:4:2] array([0, 2]) &gt;&gt;&gt;a[::-1] array([4, 3, 2, 1, 0]) # 布尔索引 &gt;&gt;&gt;mask=np.array([True,True,False,False,True]) &gt;&gt;&gt;a[mask] array([0, 1, 4]) &gt;&gt;&gt;a[a&gt;2] array([3, 4]) # 索引轴缺失 &gt;&gt;&gt;a=np.arange(6).reshape(2,3) &gt;&gt;&gt;a[-1] array([3, 4, 5]) &gt;&gt;&gt;a[-1,:] array([3, 4, 5]) # 使用...补全索引轴 &gt;&gt;&gt;a=np.arange(24).reshape(2,3,4) &gt;&gt;&gt;a array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) &gt;&gt;&gt;a[0,...,1] array([1, 5, 9]) 转置及reshape reshape: # None可将一维行向量转置为列向量 &gt;&gt;&gt;a=np.random.rand(6) &gt;&gt;&gt;a array([0.25779506, 0.22348449, 0.19464385, 0.26307378, 0.76859958, 0.80357972]) &gt;&gt;&gt;a[:,None] array([[0.25779506], [0.22348449], [0.19464385], [0.26307378], [0.76859958], [0.80357972]]) # 等价于reshape &gt;&gt;&gt;a.reshape(-1,1) array([[0.25779506], [0.22348449], [0.19464385], [0.26307378], [0.76859958], [0.80357972]]) &gt;&gt;&gt;a.reshape(2,3) array([[0.25779506, 0.22348449, 0.19464385], [0.26307378, 0.76859958, 0.80357972]]) # flatten()返回一维数组 &gt;&gt;&gt;a=np.arange(6).reshape(2,3) &gt;&gt;&gt;a.flatten() array([0, 1, 2, 3, 4, 5]) # 等价于ravel或reshape(-1) &gt;&gt;&gt;np.ravel(a) array([0, 1, 2, 3, 4, 5]) transpose: &gt;&gt;&gt;a=np.arange(24).reshape(2,3,4) &gt;&gt;&gt;a array([[[ 0, 1, 2, 3], [ 4, 5, 6, 7], [ 8, 9, 10, 11]], [[12, 13, 14, 15], [16, 17, 18, 19], [20, 21, 22, 23]]]) &gt;&gt;&gt;a,shape (2, 3, 4) &gt;&gt;&gt;a.transpose(2,0,1) array([[[ 0, 4, 8], [12, 16, 20]], [[ 1, 5, 9], [13, 17, 21]], [[ 2, 6, 10], [14, 18, 22]], [[ 3, 7, 11], [15, 19, 23]]]) &gt;&gt;&gt;a.transpose(2,0,1).shape (4, 2, 3) Ufun numpy数学函数： 注：不提供axis时，按整个数组计算 函数 说明 np.sin(x) sin(x) np.cos(x) cos(x) np.tan(x tan(x) np.arcsin(x) arcsin(x) np.arccos(x) arccos(x) np.arctan(x) arctan(x) np.arctan2(x,y) arctan(x/y) np.deg2rad(x) 角度转弧度 np.rad2deg(x) 弧度转角度 np.prod(x,axis=None) 乘积 np.sum(x,axis=None) 求和 np.exp(x) exp(x) np.log(x) ln(x) np.sqrt(x) 开根 np.square(x) 平方 np.absolute(x) 绝对值 np.fabs(x) 绝对值 np.sign(x) 符号 np.maximum(x,y) 逐元素取最大值 np.minimum(x,y) 逐元素取最小值 np.mean(x,axis=None) 均值 np.std(x,axis=None) 标准差 np.var(x,axis=None) 方差 np.average(x,weight) (加权)平均 np.argmax(x,axis=None) 最大值索引 np.argmin(x,axis=None) 最小值索引 np.sort(x,axis=None) 从小到大排序 np.argsort(x,axis=None) 从小到大排序的索引 利用frompyfunc自定义Ufun： np.frompyfunc(func,n_in,n_out) &gt;&gt;&gt;def pow2(x): ... return x**2 &gt;&gt;&gt;fun_pow2=np.frompyfunc(pow2,1,1) &gt;&gt;&gt;a=np.arange(5) &gt;&gt;&gt;fun_pow2(a) array([0, 1, 4, 9, 16], dtype=object) 广播操作 广播是针对形状不同的数组的运算采取的操作。 当我们使用ufunc函数对两个数组进行计算时，ufunc函数会对这两个数组的对应元素进行计算，因此它要求这两个数组有相同的大小(shape相同)。如果两个数组的shape不同的话（行列规模不等），会进行如下的广播(broadcasting)处理： 1）. 让所有输入数组都向其中shape最长的数组看齐，shape中不足的部分都通过在前面加1补齐。因此输出数组的shape是输入数组shape的各个轴上的最大值（往最大轴长上靠）。 2）. 如果输入数组的某个轴和输出数组的对应轴的长度相同或者其长度为1时，这个数组能够用来计算，否则出错。 3）. 当输入数组的某个轴的长度为1时，沿着此轴运算时都用此轴上的第一组值。 &gt;&gt;&gt;np.arange(2)[:,None]+np.arange(3) array([[0, 1, 2], [1, 2, 3]]) 四则运算 +，-，*，/ ， 为逐元素四则运算** 矩阵乘法，注意要符合矩阵乘法规则: # 2*3矩阵 &gt;&gt;&gt;a=np.array([[1,2,3],[4,5,6]]) # 3*2矩阵 &gt;&gt;&gt;b=np.array([[3,4],[5,6],[7,8]]) &gt;&gt;&gt;a.dot(b) array([[34, 40], [79, 94]]) **内积：**对于两个一维数组，计算的是这两个数组对应下标元素的乘积和；对于多维数组a和b，它计算的结果数组中的每个元素都是数组a和b的最后一维的内积，因此数组a和b的最后一维的长度必须相同。 计算公式为：inner(a, b)[i,j,k,m] = sum(a[i,j,:]*b[k,m,:]) &gt;&gt;&gt;a=np.arange(12).reshape(2,3,2) &gt;&gt;&gt;b=np.arange(12,24).reshape(2,3,2) &gt;&gt;&gt;np.inner(a,b) array([[[[ 13, 15, 17], [ 19, 21, 23]], [[ 63, 73, 83], [ 93, 103, 113]], [[113, 131, 149], [167, 185, 203]]], [[[163, 189, 215], [241, 267, 293]], [[213, 247, 281], [315, 349, 383]], [[263, 305, 347], [389, 431, 473]]]]) **外积：**只按照一维数组进行计算，如果传入为多维数组，先展开再计算 &gt;&gt;&gt;np.outer([1,2,3],[4,5,6,7]) array([[ 4, 5, 6, 7], [ 8, 10, 12, 14], [12, 15, 18, 21]]) 其它一些 np.ndenumerate返回索引及数组值的迭代对象 &gt;&gt;&gt;for index, x in np.ndenumerate(c): ... print(index, x) ((0, 0), 1) ((0, 1), 2) ((1, 0), 3) ((1, 1), 4) &gt;&gt;&gt;np.ndenumerate(c) &lt;numpy.lib.index_tricks.ndenumerate at 0x7f21cc0dbb90&gt; &gt;&gt;&gt;np.ndenumerate(c).next() ((0, 0), 1) np.random.choice从一维数组或int对象随机选择元素 np.random.choice(a,size=None,replace=True,p=None) a:一维数据或int对象；replace=True：可重复选择；p：选取的概率 &gt;&gt;&gt;np.random.choice(5,3,p=[0.1,0,0.3,0.6,0]) Out[4]: array([3, 3, 2], dtype=int64) np.nonezeros返回非0元素的索引 &gt;&gt;&gt;np.nonzero([[0,1,2],[0,0,2]]) (array([0, 0, 1], dtype=int64), array([1, 2, 2], dtype=int64)) np.intersect1d求两个数组的交集： &gt;&gt;&gt; np.intersect1d([1, 3, 4, 3], [3, 1, 2, 1]) array([1, 3]) # 利用reduce取多个交 &gt;&gt;&gt; from functools import reduce &gt;&gt;&gt; reduce(np.intersect1d, ([1, 3, 4, 3], [3, 1, 2, 1], [6, 3, 4, 2])) array([3]) np.where找到矩阵中满足条件的元素的索引 &gt;&gt;&gt; x = np.arange(9.).reshape(3, 3) &gt;&gt;&gt; np.where( x &gt; 5 ) (array([2, 2, 2]), array([0, 1, 2])) &gt;&gt;&gt; x[np.where( x &gt; 3.0 )] # 返回大于3的值. array([ 4., 5., 6., 7., 8.]) &gt;&gt;&gt; np.where( x == 3.0 ) # 返回等于3的值的索引. (array([1], dtype=int64), array([0], dtype=int64)) **np.indices:**获取数组shape属性的所有索引，其shpe为(dim,shape) &gt;&gt;&gt;np.indices((2,3)).shape (2, 2, 3) &gt;&gt;&gt;np.indices((2,3))[0] array([[0, 0, 0], [1, 1, 1]]) &gt;&gt;&gt;np.indices((2,3))[1] array([[0, 1, 2], [0, 1, 2]]) # 用于索引 &gt;&gt;&gt;a=np.arange(6).reshape(2,3) &gt;&gt;&gt;b=np.indices((2,3))[0] &gt;&gt;&gt;a[b] array([[[0, 1, 2], [0, 1, 2], [0, 1, 2]], [[3, 4, 5], [3, 4, 5], [3, 4, 5]]]) &gt;&gt;&gt;c=np.indices((2,3))[1] &gt;&gt;&gt;a[:,c] array([[[0, 1, 2], [0, 1, 2]], [[3, 4, 5], [3, 4, 5]]]) # 配合布尔索引进行mask操作 &gt;&gt;&gt;a[b&gt;0] array([3, 4, 5]) &gt;&gt;&gt;b&gt;0 array([[False, False, False], [ True, True, True]]) **np.repeat:**对数组进行扩展 np.repeat(a,repeats,axis=None) &gt;&gt;&gt;a=np.array([[10,20],[30,40]]) &gt;&gt;&gt;np.repeat(a,[3,2],axis=0) array([[10, 20], [10, 20], [10, 20], [30, 40], [30, 40]]) **np.tile:**对整个数组进行复制拼接 np.tile(a,reps) &gt;&gt;&gt; a=np.array([10,20]) &gt;&gt;&gt;np.tile(a, (3,2)) array([[10, 20, 10, 20], [10, 20, 10, 20], [10, 20, 10, 20]]) **np.pad:**数组填充(padding)操作 np.pad(array,pad_width,mode,**kwags) &gt;&gt;&gt;A = np.arange(95,99).reshape(2,2) &gt;&gt;&gt;np.pad(A,((3,2),(2,3)),'constant',constant_values = (0,0)) array([[ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 95, 96, 0, 0, 0], [ 0, 0, 97, 98, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0], [ 0, 0, 0, 0, 0, 0, 0]]) **np.flip:**沿着指定轴翻转 &gt;&gt;&gt;A = np.arange(4).reshape((2,2)) &gt;&gt;&gt;np.flip(A,0) array([[2, 3], [0, 1]]) **np.unravel_index:**返回indices的下标 np.unravel_index(indices,dims,order=‘C’) &gt;&gt;&gt;np.unravel_index([22, 41, 37], (7,6)) (array([3, 6, 6]), array([4, 5, 1])) &gt;&gt;&gt;a=np.array([[1,2,3],[4,3,2]]) &gt;&gt;&gt;np.argmax(a) 3 &gt;&gt;&gt;np.unravel_index(np.argmax(a),a.shape) (1, 0) **np.unique:**去除数组中重复数字，并进行排序后输出 &gt;&gt;&gt;a=np.array([[1,2,3],[4,3,2]]) &gt;&gt;&gt;np.unique(a) array([1, 2, 3, 4])","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"python","slug":"python","permalink":"/tags/python/"},{"name":"numpy","slug":"numpy","permalink":"/tags/numpy/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"矩阵求导","slug":"矩阵求导","date":"2020-04-15T23:27:00.000Z","updated":"2020-04-17T03:29:07.000Z","comments":true,"path":"2020/04/16/矩阵求导/","link":"","permalink":"/2020/04/16/矩阵求导/","excerpt":"","text":"符号与符号布局的规定 符号规定： LLL ：标量 x​x​x​ ：n​n​n​ 维向量 yyy ：mmm 维向量 XXX ：m∗nm*nm∗n 维矩阵 分母布局： 标量LLL 对向量xxx 求导得到的是nnn 维向量，其中(∂L∂x)i=∂L∂xi(\\frac{\\partial L}{\\partial x})_i=\\frac{\\partial L}{\\partial x_i}(∂x∂L​)i​=∂xi​∂L​ 标量LLL 对矩阵XXX 求导是大小为m∗nm*nm∗n 的矩阵，其中(∂L∂X)ij=∂L∂xij(\\frac{\\partial L}{\\partial X})_{ij}=\\frac{\\partial L}{\\partial x_{ij}}(∂X∂L​)ij​=∂xij​∂L​ 向量y​y​y​ 对向量xxx 求导是大小为m∗nm*nm∗n 的矩阵，其中(∂y∂x)ij=∂yj∂xi​(\\frac{\\partial y}{\\partial x})_{ij}=\\frac{\\partial y_j}{\\partial x_i}​(∂x∂y​)ij​=∂xi​∂yj​​​ 分子布局： 标量LLL 对向量xxx 求导得到的是nnn 维向量，其中(∂L∂x)i=∂L∂xi(\\frac{\\partial L}{\\partial x})_i=\\frac{\\partial L}{\\partial x_i}(∂x∂L​)i​=∂xi​∂L​ 标量LLL 对矩阵XXX 求导是大小为n∗mn*mn∗m 的矩阵，其中(∂L∂X)ij=∂L∂xji(\\frac{\\partial L}{\\partial X})_{ij}=\\frac{\\partial L}{\\partial x_{ji}}(∂X∂L​)ij​=∂xji​∂L​ 向量yyy 对向量xxx 求导是大小为n∗mn*mn∗m 的矩阵，其中(∂y∂x)ij=∂yi∂xj(\\frac{\\partial y}{\\partial x})_{ij}=\\frac{\\partial y_i}{\\partial x_j}(∂x∂y​)ij​=∂xj​∂yi​​ 注：数学界有两派人使用着自己的符号约定，从而将矩阵微积分划分成了两个派别。这两个约定都是被大家所接受的。这两个布局之间相差一个转置，大多数的转置异常问题根本上来说是由于没有统一求导布局所导致的 。 几个重要的向量对向量求导结论 利用定义验证： ∂x∂x=I\\frac{\\partial x}{\\partial x}=I∂x∂x​=I 设向量z=f(x)z=f(x)z=f(x) ，则∂Az∂x=∂f∂xAT\\frac{\\partial Az}{\\partial x}=\\frac{\\partial f}{\\partial x}A^T∂x∂Az​=∂x∂f​AT ，特别地：∂Ax∂x=AT\\frac{\\partial Ax}{\\partial x}=A^T∂x∂Ax​=AT 设向量z=g(x)z=g(x)z=g(x) ，则∂zTA∂x=∂g∂xA\\frac{\\partial z^TA}{\\partial x}=\\frac{\\partial g}{\\partial x}A∂x∂zTA​=∂x∂g​A ，特别地：∂xTA∂x=A\\frac{\\partial x^TA}{\\partial x}=A∂x∂xTA​=A 设fff 为按元素运算的函数，则∂f(x)∂x=diag(f′(x))\\frac{\\partial f(x)}{\\partial x}=diag(f&#x27;(x))∂x∂f(x)​=diag(f′(x)) 标量求导的迹方法 多元函数微积分中，有df=∑i=1n∂f∂xidxi=∂f∂xTdxd f=\\sum_{i=1}^{n} \\frac{\\partial f}{\\partial x_{i}} d x_{i}=\\frac{\\partial f}{\\partial x}^{T} d xdf=∑i=1n​∂xi​∂f​dxi​=∂x∂f​Tdx ，在矩阵导数中： dL=∑i=1m∑j=1n∂L∂XijdXij=tr⁡((∂L∂X)TdX)d L=\\sum_{i=1}^{m} \\sum_{j=1}^{n} \\frac{\\partial L}{\\partial \\mathbf{X}_{ij}} d \\mathbf{X}_{ij}=\\operatorname{tr}\\left(\\left(\\frac{\\partial L}{\\partial \\mathbf{X}}\\right)^{T} d \\mathbf{X}\\right) dL=i=1∑m​j=1∑n​∂Xij​∂L​dXij​=tr((∂X∂L​)TdX) 迹的常用性质： tr(XT)=tr(X)tr(X^T)=tr(X)tr(XT)=tr(X) tr(X+Y)=tr(X)+tr(Y)tr(X+Y)=tr(X)+tr(Y)tr(X+Y)=tr(X)+tr(Y) tr(XY)=tr(YX)tr(XY)=tr(YX)tr(XY)=tr(YX) tr⁡(ATB)=∑i,jAijBij\\operatorname{tr}\\left(A^{T} B\\right)=\\sum_{i, j} A_{i j} B_{i j}tr(ATB)=∑i,j​Aij​Bij​ tr(AT(B⊙C))=tr((A⊙B)TC)=∑i,jAijBijCijtr\\left(A^{T}(B \\odot C)\\right)=tr\\left((A \\odot B)^{T} C\\right)=\\sum_{i, j} A_{i j} B_{i j} C_{i j}tr(AT(B⊙C))=tr((A⊙B)TC)=∑i,j​Aij​Bij​Cij​ 其中⊙\\odot⊙ 为Hadamard乘积 常用全微分公式及法则 常用公式 d(X+Y)=dX+dYd(X+Y)=dX+dYd(X+Y)=dX+dY d(tr(X))=tr(dX)d(tr(X))=tr(dX)d(tr(X))=tr(dX) d(XY)=(dX)Y+XdYd(XY)=(dX)Y+XdYd(XY)=(dX)Y+XdY d(X⊙Y)=(dX)⊙Y+X⊙dYd(X \\odot Y)=(dX) \\odot Y +X \\odot dYd(X⊙Y)=(dX)⊙Y+X⊙dY dσ(X)=σ′(X)⊙dXd \\sigma(X)=\\sigma&#x27;(X)\\odot dXdσ(X)=σ′(X)⊙dX （$\\sigma $ 为逐元素运算） dX−1=−X−1(dX)X−1dX^{-1}=-X^{-1}(dX)X^{-1}dX−1=−X−1(dX)X−1 d∣X∣=∣X∣tr(X−1dX)d|X|=|X|tr(X^{-1}dX)d∣X∣=∣X∣tr(X−1dX) dln∣X∣=tr(X−1dX)dln|X|=tr(X^{-1}dX)dln∣X∣=tr(X−1dX) dXT=(dX)TdX^T=(dX)^TdXT=(dX)T 乘法法则 若x∈Rp,y=f(x)∈Rq,z=g(x)∈Rq\\mathbf{x} \\in R^{p}, \\mathbf{y}=f(\\mathbf{x}) \\in R^{q}, \\mathbf{z}=g(\\mathbf{x}) \\in R^{q}x∈Rp,y=f(x)∈Rq,z=g(x)∈Rq,则$ \\frac{\\partial \\mathbf{y}^{T} \\mathbf{z}}{\\partial \\mathbf{x}}=\\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} \\mathbf{z}+\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}} \\mathbf{y} \\in R^{p}$ 若 x∈Rp,y=f(x)∈R,z=g(x)∈Rq\\mathbf{x} \\in R^{p}, y=f(\\mathbf{x}) \\in R, \\mathbf{z}=g(\\mathbf{x}) \\in R^{q}x∈Rp,y=f(x)∈R,z=g(x)∈Rq,则 ∂yz∂x=∂y∂xzT+∂z∂xy∈Rp×q\\frac{\\partial y \\mathbf{z}}{\\partial \\mathbf{x}}=\\frac{\\partial y}{\\partial \\mathbf{x}} \\mathbf{z}^{T}+\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{x}} y \\in R^{p \\times q}∂x∂yz​=∂x∂y​zT+∂x∂z​y∈Rp×q 链式法则 向量对向量求导(包含向量对标量求导、标量对向量求导)： 设多个向量之间存在依赖关系：a⇒b⇒…⇒x⇒y⇒z\\mathbf{a} \\Rightarrow \\mathbf{b} \\Rightarrow \\ldots \\Rightarrow \\mathbf{x} \\Rightarrow \\mathbf{y} \\Rightarrow \\mathbf{z}a⇒b⇒…⇒x⇒y⇒z 计算方法：∂z∂a=∂b∂a∂c∂b…∂y∂x∂z∂y\\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{a}}=\\frac{\\partial \\mathbf{b}}{\\partial \\mathbf{a}} \\frac{\\partial \\mathbf{c}}{\\partial \\mathbf{b}} \\ldots \\frac{\\partial \\mathbf{y}}{\\partial \\mathbf{x}} \\frac{\\partial \\mathbf{z}}{\\partial \\mathbf{y}}∂a∂z​=∂a∂b​∂b∂c​…∂x∂y​∂y∂z​ 标量对矩阵求导： 若矩阵X∈Rp∗qX\\in R^{p*q}X∈Rp∗q ，矩阵y=g(X)∈Rs∗ty=g(X)\\in R^{s*t}y=g(X)∈Rs∗t ，标量z=f(Y)∈Rz=f(Y) \\in Rz=f(Y)∈R，则∂z∂Xij=tr⁡((∂z∂Y)T∂Y∂Xij)\\frac{\\partial z}{\\partial \\mathbf{X}_{ij}}=\\operatorname{tr}\\left(\\left(\\frac{\\partial z}{\\partial \\mathbf{Y}}\\right)^{T} \\frac{\\partial \\mathbf{Y}}{\\partial \\mathbf{X}_{ij}}\\right)∂Xij​∂z​=tr((∂Y∂z​)T∂Xij​∂Y​) 由上式，若链式关系中存在有矩阵对矩阵求导，则难以直接写出标量对矩阵的导数，下面则给出常用的线性关系下的&quot;链式&quot;求导 ： 若存在关系：X⇒Y=AX+B⇒L=f(Y)\\mathbf{X} \\Rightarrow \\mathbf{Y}=\\mathbf{A} \\mathbf{X}+\\mathbf{B} \\Rightarrow L=f(\\mathbf{Y})X⇒Y=AX+B⇒L=f(Y) ，则∂L∂X=AT∂L∂Y\\frac{\\partial L}{\\partial \\mathbf{X}}=A^{T} \\frac{\\partial L}{\\partial \\mathbf{Y}}∂X∂L​=AT∂Y∂L​ 若存在关系： X⇒Y=XA+B⇒L=f(Y)\\mathbf{X} \\Rightarrow \\mathbf{Y}=\\mathbf{X} \\mathbf{A}+\\mathbf{B} \\Rightarrow L=f(\\mathbf{Y})X⇒Y=XA+B⇒L=f(Y)，则∂L∂X=∂L∂YAT\\frac{\\partial L}{\\partial \\mathbf{X}}= \\frac{\\partial L}{\\partial \\mathbf{Y}}A^T∂X∂L​=∂Y∂L​AT 链式法则不再成立，往往通过迹方法来求标量对矩阵的导数 常见技巧 一维下标求和考虑写成向量内积的形式 二位下标求和考虑写成trtrtr的形式 向量模长的平方考虑内积运算∑ixi2=xTx\\sum_{i} x_{i}^{2}=\\mathbf{x}^{T} \\mathbf{x}∑i​xi2​=xTx 矩阵的Frobenius范数考虑写成trtrtr 的形式∥X∥F2=tr(XXT)\\|\\mathbf{X}\\|_{F}^{2}=t r\\left(\\mathbf{X} \\mathbf{X}^{T}\\right)∥X∥F2​=tr(XXT) 推荐阅读： 知乎，矩阵求导术(上) 知乎，矩阵求导术(下)","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"矩阵求导","slug":"矩阵求导","permalink":"/tags/矩阵求导/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"内网穿透proxyer","slug":"proxyer做内网穿透","date":"2020-04-10T01:15:00.000Z","updated":"2020-04-10T01:48:36.000Z","comments":true,"path":"2020/04/10/proxyer做内网穿透/","link":"","permalink":"/2020/04/10/proxyer做内网穿透/","excerpt":"","text":"Github地址：https://github.com/khvysofq/proxyer 服务端 安装docker： $ curl -sSL https://get.docker.com/ | sh $ systemctl start docker $ systemctl enable docker 安装docker compose $ curl -L \"https://get.daocloud.io/docker/compose/releases/download/1.24.1/docker-compose-$(uname -s)-$(uname -m)\" -o /usr/local/bin/docker-compose $ chmod +x /usr/local/bin/docker-compose 安装proxyer： $ wget https://raw.githubusercontent.com/khvysofq/proxyer/master/docker-compose.yml # 后面1.1.1.1改成服务器ip地址 $ export PROXYER_PUBLIC_HOST=1.1.1.1 $ docker-compose up -d 安装完成后，通过ip:6789访问服务端WEB管理面板了，进去后需要设置一个客户端认证密码。 客户端 从web管理面板下载对应系统客户端 windows系统直接运行，linux解压后运行./proxyer，按照提示浏览器进入127.0.0.1:9876 如图，内网地址填127.0.0.1:22，序列号自定义 安装ssh，已安装可跳过： $ sudo apt-get install ssh 以图片为例，远程ssh连接时，连接使用： $ ssh -p 43537 yu@66.152.179.100 设置为开机自启 (支持Ubuntu16.04，18.04好像不支持这种方式了) 编辑/etc/rc.local文件，在exit 0前添加proxyer文件的位置 如：~/proxyer","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"内网穿透","slug":"内网穿透","permalink":"/tags/内网穿透/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"Git！","slug":"Git","date":"2020-03-30T10:49:00.000Z","updated":"2020-03-30T13:08:35.000Z","comments":true,"path":"2020/03/30/Git/","link":"","permalink":"/2020/03/30/Git/","excerpt":"","text":"工作原理/流程 Workspace：工作区 Index / Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 配置 在Github注册后，做一下本地的Git仓库配置： $ git config --global user.name \"ybb-ybb\" $ git config --global user.email \"21901037@mail.dlut.edu.cn\" 如果对某个仓库使用不同的用户名和邮箱，去掉--global参数即可 本地仓库 提交 # 将当前目录变成git可管理的仓库 $ git init # 将readme.md添加到缓存区 $ git add readme.md # 将所有文件添加到缓存区 $ git add . # 将缓存区文件提交到仓库 $ git commit -m \"提交信息\" # 查看是否还有文件未提交 $ git status # 查看文件修改内容 $ git diff readme.md # 查看历史记录 $ git log # 查看历史记录的简单信息 $ git log –pretty=oneline 版本回退 # 回到上一个版本 $ git reset --hard HEAD^ # 同理，回到上上个版本等，以此类推 $ git reset --hard HEAD^^ # 或 $ git reset --hard HEAD~2 # 查看版本号变化 $ git reflog # 版本号回退 $ git reset --hard {版本号} # 丢弃工作区的修改（回到暂存区的状态） $ git checkout -- filename 远程仓库 配置 本地Git仓库和Github仓库之间是通过ssh加密的，因此需要先进行一些配置： 第一步：创建SSH Key。在主目录下，看看有没有.ssh目录，如果有，再看看这个目录下有没有id_rsa和id_rsa.pub这两个文件，如果有的话，直接跳过此如下命令，如果没有的话： ssh-keygen -t rsa –C “youremail@example.com” id_rsa是私钥，id_rsa.pub是公钥 第二步：登录github,打开” settings”中的SSH Keys页面，然后点击“Add SSH Key”,填上任意title，在Key文本框里黏贴id_rsa.pub文件的内容 ，Add key 推送到远程仓库 # 先创建一个github仓库，复制http或ssh地址,然后关联 $ git remote add origin {http adress} # 推送，第一次推送时添加-u参数,把master分支推送到远程 $ git push -u origin master 分支 # 创建分支 $ git branch backup # 切换分支 $ git checkout backup # 或者：创建+切换分支 $ git checkout -b backup # 查看当前分支 $ git branch # 在master分支上，将分支backup合并到master上 $ git merge backup # 删除分支 $ git branch -d backup","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"Git","slug":"Git","permalink":"/tags/Git/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"离线下载+在线播放网盘","slug":"离线下载+在线播放网盘","date":"2020-03-15T04:13:00.000Z","updated":"2020-03-15T04:39:06.210Z","comments":true,"path":"2020/03/15/离线下载+在线播放网盘/","link":"","permalink":"/2020/03/15/离线下载+在线播放网盘/","excerpt":"","text":"主要过程是用Aria2进行下载，然后上传到OneDrive云盘并用OneIndex关联云盘实现网页访问。 获取OneDrive 申请OneDrive5T账号 两个申请OneDrive云盘5T的方法： 1、申请微软的Office 365开发者计划，地址：免费获得一年的21TB OneDrive和Microsoft Office 365企业 2、使用热心大佬提供的临时邮箱申请一个，方法如下： 1)、进入注册地址https://products.office.com/en-us/student?tab=students 2)、输入如有乐享提供的临时邮箱，地址：https://51.ruyo.net/8263.html 3)、填入密码，和从临时邮箱获取的验证码 授权 授权认证： 点击右侧URL登录并授权，授权地址→ 国际版 世纪互联 授权后会获取一个localhost开头打不开的链接，这里只需要记住code，也就是链接中code=和&amp;中间的参数。 安装Aria2 以下操作都是在服务器端执行 $ cd /root $ wget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubiBackup/doubi/master/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; bash aria2.sh #备用地址 $ wget -N --no-check-certificate https://www.moerats.com/usr/shell/Aria2/aria2.sh &amp;&amp; chmod +x aria2.sh &amp;&amp; bash aria2.sh 安装后可以使用bash aria2.sh命令修改Aria2的默认下载目录、端口号、密码等 安装OneDriveUploader $ wget https://raw.githubusercontent.com/MoeClub/OneList/master/OneDriveUploader/amd64/linux/OneDriveUploader -P /usr/local/bin/ # 授权 $ chmod +x /usr/local/bin/OneDriveUploader # 初始化配置 #将moerats替换成授权步骤中获取的code参数 $ code=\"moerats\" $ OneDriveUploader -a \"${code}\" 如果提示 Init config file: /root/auth.json 类似信息，则初始化成功。 手动上传示例： # -c指定初始化文件位置，-s指定上传文件，-r指定网盘目录，不指定默认为根目录 # 将当前目录下的Download文件夹上传到OneDrive网盘Test目录中 $ OneDriveUploader -c /root/auth.json -s \"Download\" -r \"Test\" 配置Aria2的自动上传 # 新建文件 $ touch rcloneupload.sh # 修改文件内容 $ vim rcloneupload.sh 将文件内容修改为下面内容，注意替换Aria2的下载目录 #!/bin/bash GID=\"$1\"; FileNum=\"$2\"; File=\"$3\"; MaxSize=\"15728640\"; Thread=\"3\"; #默认3线程，自行修改，服务器配置不好的话，不建议太多 Block=\"20\"; #默认分块20m，自行修改 RemoteDIR=\"\"; #上传到Onedrive的路径，默认为根目录，如果要上传到MOERATS目录，\"\"里面请填成MOERATS LocalDIR=\"/www/download/\"; #Aria2下载目录，记得最后面加上/ Uploader=\"/usr/local/bin/OneDriveUploader\"; #上传的程序完整路径，默认为本文安装的目录 Config=\"/root/auth.json\"; #初始化生成的配置auth.json绝对路径，参考第3步骤生成的路径 if [[ -z $(echo \"$FileNum\" |grep -o '[0-9]*' |head -n1) ]]; then FileNum='0'; fi if [[ \"$FileNum\" -le '0' ]]; then exit 0; fi if [[ \"$#\" != '3' ]]; then exit 0; fi function LoadFile(){ if [[ ! -e \"${Uploader}\" ]]; then return; fi IFS_BAK=$IFS IFS=$'\\n' tmpFile=\"$(echo \"${File/#$LocalDIR}\" |cut -f1 -d'/')\" FileLoad=\"${LocalDIR}${tmpFile}\" if [[ ! -e \"${FileLoad}\" ]]; then return; fi ItemSize=$(du -s \"${FileLoad}\" |cut -f1 |grep -o '[0-9]*' |head -n1) if [[ -z \"$ItemSize\" ]]; then return; fi if [[ \"$ItemSize\" -ge \"$MaxSize\" ]]; then echo -ne \"\\033[33m${FileLoad} \\033[0mtoo large to spik.\\n\"; return; fi ${Uploader} -c \"${Config}\" -t \"${Thread}\" -b \"${Block}\" -s \"${FileLoad}\" -r \"${RemoteDIR}\" if [[ $? == '0' ]]; then rm -rf \"${FileLoad}\"; fi IFS=$IFS_BAK } LoadFile; 授权 $ chmod +x rcloneupload.sh bash aria2.sh修改配置文件，加上一行： on-download-complete=/root/rcloneupload.sh 重启Aria2生效 测试一下 试一下 bash /root/rcloneupload.sh 正常为无反应，如果报错： 1、安装dos2unix $ apt-get install dos2unix -y 2、转换格式 $ dos2unix /root/rcloneupload.sh Aria2离线下载的使用 谷歌浏览器插件 aria2 for chrome 进去之后AriaNg设置——&gt;添加新RPC设置，配置如下： 然后添加任务即可进行离线下载，并自动上传到OneDrive OneIndex对接网盘 OneIndex可以对接Onedrive网盘，将网盘里的内容直接显示成目录，视频可以在线播放。也可以搭建自己的在线图床/视频播放系统。 使用docker安装Oneindex $ docker run -d -p 8181:80 --restart=always baiyuetribe/oneindex 然后访问ip:8181按照提示操作即可 效果图： 如果要进入系统管理页面，访问ip:8181/?/login 可选，域名访问 如果有自己的域名，可以通过反向代理进行http访问 宝塔反代：先进入宝塔面板，点击左侧网站，添加站点，完成后进入网站设置，点击反向代理，目标URL填入http://127.0.0.1:8181，再启用反向代理即可。 宝塔界面可一键安装： $ wget -O install.sh http://download.bt.cn/install/install-ubuntu.sh &amp;&amp; sudo bash install.sh","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"OneDrive","slug":"OneDrive","permalink":"/tags/OneDrive/"},{"name":"离线下载","slug":"离线下载","permalink":"/tags/离线下载/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"tensorboardX","slug":"tensorboardX","date":"2020-03-09T13:31:11.839Z","updated":"2020-03-15T04:35:24.214Z","comments":true,"path":"2020/03/09/tensorboardX/","link":"","permalink":"/2020/03/09/tensorboardX/","excerpt":"","text":"创建 TensorBoardX的GitHub地址：传送门 首先创建一个 SummaryWriter 的示例 ： from tensorboardX import SummaryWriter # Creates writer1 object. # The log will be saved in 'runs/exp' writer1 = SummaryWriter('runs/exp') # Creates writer2 object with auto generated file name # The log directory will be something like 'runs/Aug20-17-20-33' writer2 = SummaryWriter() # Creates writer3 object with auto generated file name, the comment will be appended to the filename. # The log directory will be something like 'runs/Aug20-17-20-33-resnet' writer3 = SummaryWriter(comment='resnet') 以上展示了三种初始化 SummaryWriter 的方法： 提供一个路径，将使用该路径来保存日志 无参数，默认将使用 runs/日期时间 路径来保存日志 提供一个 comment 参数，将使用 runs/日期时间-comment 路径来保存日志 在浏览器中查看这些可视化数据： tensorboard --logdir=&lt;your_log_dir&gt; 用各种add方法记录数据 数字(scalar) add_scalar(tag, scalar_value, global_step=None, walltime=None) 参数: tag (string): 数据名称，不同名称的数据使用不同曲线展示 scalar_value (float): 数字常量值 global_step (int, optional): 训练的 step walltime (float, optional): 记录发生的时间，默认为 time.time() 需要注意，这里的 scalar_value 一定是 float 类型，如果是 PyTorch scalar tensor，则需要调用 .item() 方法获取其数值。我们一般会使用 add_scalar 方法来记录训练过程的 loss、accuracy、learning rate 等数值的变化，直观地监控训练过程。 示例： from tensorboardX import SummaryWriter writer = SummaryWriter('runs/scalar_example') for i in range(10): writer.add_scalar('quadratic', i**2, global_step=i) writer.add_scalar('exponential', 2**i, global_step=i) 图片(image) 需要pillow库的支持 用add_image记录单个图像数据，用add_images记录多个图像数据 add_image(tag, img_tensor, global_step=None, walltime=None, dataformats='CHW') CHW为channel*hight*width 示例： from tensorboardX import SummaryWriter import cv2 as cv writer = SummaryWriter('runs/image_example') for i in range(1, 6): writer.add_image('countdown', cv.cvtColor(cv.imread('{}.jpg'.format(i)), cv.COLOR_BGR2RGB), global_step=i, dataformats='HWC') 直方图(histogram) add_histogram(tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None) 示例： from tensorboardX import SummaryWriter import numpy as np writer = SummaryWriter('runs/embedding_example') writer.add_histogram('normal_centered', np.random.normal(0, 1, 1000), global_step=1) writer.add_histogram('normal_centered', np.random.normal(0, 2, 1000), global_step=50) writer.add_histogram('normal_centered', np.random.normal(0, 3, 1000), global_step=100) &quot;DISTRIBUTIONS&quot;和&quot;HISTOGRAMS&quot;两栏都是用来观察数据分布的。其中在&quot;HISTOGRAMS&quot;中，同一数据不同 step 时候的直方图可以上下错位排布 (OFFSET) 也可重叠排布 (OVERLAY)。 运行图(graph) add_graph(model, input_to_model=None, verbose=False, **kwargs) 可以可视化神经网络的结构，参考Github官方样例 嵌入张量(embedding) 使用 add_embedding 方法可以在二维或三维空间可视化 embedding 向量。 add_embedding(mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None) 参数： mat (torch.Tensor or numpy.array): 一个MxN矩阵，每行代表特征空间的一个数据点 metadata (list or torch.Tensor or numpy.array, optional): 一个一维列表N，mat 中每行数据的 label，大小应和 mat 行数相同 label_img (torch.Tensor, optional): 一个形如 NxCxHxW 的张量，对应 mat 每一行数据显示出的图像，N 应和 mat 行数相同 global_step (int, optional): 训练的 step tag (string, optional): 数据名称，不同名称的数据将分别展示 示例： from tensorboardX import SummaryWriter import torchvision writer = SummaryWriter('runs/embedding_example') mnist = torchvision.datasets.MNIST('mnist', download=True) writer.add_embedding( mnist.train_data.reshape((-1, 28 * 28))[:100,:], #直接将mnist前100个数据展开成一维向量作为embedding metadata=mnist.train_labels[:100], #每个embedding的label label_img = mnist.train_data[:100,:,:].reshape((-1, 1, 28, 28)).float() / 255, #每个图像 global_step=0 )","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"neural ode","slug":"neural-ode","permalink":"/tags/neural-ode/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"Hexo-Theme-Sakura","slug":"Hexo-Theme-Sakura","date":"2020-03-09T12:16:01.000Z","updated":"2020-03-15T04:21:33.074Z","comments":true,"path":"2020/03/09/Hexo-Theme-Sakura/","link":"","permalink":"/2020/03/09/Hexo-Theme-Sakura/","excerpt":"","text":"hexo-theme-sakura主题 English document 基于WordPress主题Sakura修改成Hexo的主题。 demo预览 正在开发中… 交流群 若你是使用者，加群QQ: 801511924 若你是创作者，加群QQ: 194472590 主题特性 首页大屏视频 首页随机封面 图片懒加载 valine评论 fancy-box相册 pjax支持，音乐不间断 aplayer音乐播放器 多级导航菜单（按现在大部分hexo主题来说，这也算是个特性了） 赞赏作者 如果喜欢hexo-theme-sakura主题，可以考虑资助一下哦~非常感激！ paypal | Alipay 支付宝 | WeChat Pay 微信支付 未完善的使用教程 那啥？老实说我目前也不是很有条理233333333~ 1、主题下载安装 hexo-theme-sakura建议下载压缩包格式，因为除了主题内容还有些source的配置对新手来说比较太麻烦，直接下载解压就省去这些麻烦咯。 下载好后解压到博客根目录（不是主题目录哦，重复的选择替换）。接着在命令行（cmd、bash）运行npm i安装依赖。 2、主题配置 博客根目录下的_config配置 站点 # Site title: 你的站点名 subtitle: description: 站点简介 keywords: author: 作者名 language: zh-cn timezone: 部署 deploy: type: git repo: github: 你的github仓库地址 # coding: 你的coding仓库地址 branch: master 备份 （使用hexo b发布备份到远程仓库） backup: type: git message: backup my blog of https://honjun.github.io/ repository: # 你的github仓库地址,备份分支名 （建议新建backup分支） github: https://github.com/honjun/honjun.github.io.git,backup # coding: https://git.coding.net/hojun/hojun.git,backup 主题目录下的_config配置 其中标明【改】的是需要修改部门，标明【选】是可改可不改，标明【非】是不用改的部分 # site name # 站点名 【改】 prefixName: さくら荘その siteName: hojun # favicon and site master avatar # 站点的favicon和头像 输入图片路径（下面的配置是都是cdn的相对路径，没有cdn请填写完整路径，建议使用jsdeliver搭建一个cdn啦，先去下载我的cdn替换下图片就行了，简单方便~）【改】 favicon: /images/favicon.ico avatar: /img/custom/avatar.jpg # 站点url 【改】 url: https://sakura.hojun.cn # 站点介绍（或者说是个人签名）【改】 description: Live your life with passion! With some drive! # 站点cdn，没有就为空 【改】 若是cdn为空，一些图片地址就要填完整地址了，比如之前avatar就要填https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/custom/avatar.jpg cdn: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6 # 开启pjax 【选】 pjax: 1 # 站点首页的公告信息 【改】 notice: hexo-Sakura主题已经开源，目前正在开发中... # 懒加载的加载中图片 【选】 lazyloadImg: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/loader/orange.progress-bar-stripe-loader.svg # 站点菜单配置 【选】 menus: 首页: { path: /, fa: fa-fort-awesome faa-shake } 归档: { path: /archives, fa: fa-archive faa-shake, submenus: { 技术: {path: /categories/技术/, fa: fa-code }, 生活: {path: /categories/生活/, fa: fa-file-text-o }, 资源: {path: /categories/资源/, fa: fa-cloud-download }, 随想: {path: /categories/随想/, fa: fa-commenting-o }, 转载: {path: /categories/转载/, fa: fa-book } } } 清单: { path: javascript:;, fa: fa-list-ul faa-vertical, submenus: { 书单: {path: /tags/悦读/, fa: fa-th-list faa-bounce }, 番组: {path: /bangumi/, fa: fa-film faa-vertical }, 歌单: {path: /music/, fa: fa-headphones }, 图集: {path: /tags/图集/, fa: fa-photo } } } 留言板: { path: /comment/, fa: fa-pencil-square-o faa-tada } 友人帐: { path: /links/, fa: fa-link faa-shake } 赞赏: { path: /donate/, fa: fa-heart faa-pulse } 关于: { path: /, fa: fa-leaf faa-wrench , submenus: { 我？: {path: /about/, fa: fa-meetup}, 主题: {path: /theme-sakura/, fa: iconfont icon-sakura }, Lab: {path: /lab/, fa: fa-cogs }, } } 客户端: { path: /client/, fa: fa-android faa-vertical } RSS: { path: /atom.xml, fa: fa-rss faa-pulse } # Home page sort type: -1: newer first，1: older first. 【非】 homePageSortType: -1 # Home page article shown number) 【非】 homeArticleShown: 10 # 背景图片 【选】 bgn: 8 # startdash面板 url, title, desc img 【改】 startdash: - {url: /theme-sakura/, title: Sakura, desc: 本站 hexo 主题, img: /img/startdash/sakura.md.png} - {url: http://space.bilibili.com/271849279, title: Bilibili, desc: 博主的b站视频, img: /img/startdash/bilibili.jpg} - {url: /, title: hojun的万事屋, desc: 技术服务, img: /img/startdash/wangshiwu.jpg} # your site build time or founded date # 你的站点建立日期 【改】 siteBuildingTime: 07/17/2018 # 社交按钮(social) url, img PC端配置 【改】 social: github: {url: http://github.com/honjun, img: /img/social/github.png} sina: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/sina.png} wangyiyun: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/wangyiyun.png} zhihu: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/zhihu.png} email: {url: http://weibo.com/mashirozx?is_all=1, img: /img/social/email.svg} wechat: {url: /#, qrcode: /img/custom/wechat.jpg, img: /img/social/wechat.png} # 社交按钮(msocial) url, img 移动端配置 【改】 msocial: github: {url: http://github.com/honjun, fa: fa-github, color: 333} weibo: {url: http://weibo.com/mashirozx?is_all=1, fa: fa-weibo, color: dd4b39} qq: {url: https://wpa.qq.com/msgrd?v=3&amp;uin=954655431&amp;site=qq&amp;menu=yes, fa: fa-qq, color: 25c6fe} # 赞赏二维码（其中wechatSQ是赞赏单页面的赞赏码图片）【改】 donate: alipay: /img/custom/donate/AliPayQR.jpg wechat: /img/custom/donate/WeChanQR.jpg wechatSQ: /img/custom/donate/WeChanSQ.jpg # 首页视频地址为https://cdn.jsdelivr.net/gh/honjun/hojun@1.2/Unbroken.mp4，配置如下 【改】 movies: url: https://cdn.jsdelivr.net/gh/honjun/hojun@1.2 # 多个视频用逗号隔开，随机获取。支持的格式目前已知MP4,Flv。其他的可以试下，不保证有用 name: Unbroken.mp4 # 左下角aplayer播放器配置 主要改id和server这两项，修改详见[aplayer文档] 【改】 aplayer: id: 2660651585 server: netease type: playlist fixed: true mini: false autoplay: false loop: all order: random preload: auto volume: 0.7 mutex: true # Valine评论配置【改】 valine: true v_appId: GyC3NzMvd0hT9Yyd2hYIC0MN-gzGzoHsz v_appKey: mgOpfzbkHYqU92CV4IDlAUHQ 分类页和标签页配置 分类页 标签页 配置项在\\themes\\Sakura\\languages\\zh-cn.yml里。新增一个分类或标签最好加下哦，当然嫌麻烦可以直接使用一张默认图片（可以改主题或者直接把404图片替换下，征求下意见要不要给这个在配置文件中加个开关，可以issue或群里提出来），现在是没设置的话会使用那种倒立小狗404哦。 #category # 按分类名创建 技术: #中文标题 zh: 野生技术协会 # 英文标题 en: Geek – Only for Love # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/coding.jpg 生活: zh: 生活 en: live img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/writing.jpg #tag # 标签名即是标题 悦读: # 封面图片 img: https://cdn.jsdelivr.net/gh/honjun/cdn@1.6/img/banner/reading.jpg 单页面封面配置 如留言板页面页面，位于source下的comment下，打开index.md如下： --- title: comment date: 2018-12-20 23:13:48 keywords: 留言板 description: comments: true # 在这里配置单页面头部图片，自定义替换哦~ photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/comment.jpg --- 单页面配置 番组计划页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） --- layout: bangumi title: bangumi comments: false date: 2019-02-10 21:32:48 keywords: description: bangumis: # 番组图片 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg # 番组名 title: 朝花夕誓——于离别之朝束起约定之花 # 追番状态 （追番ing/已追完） status: 已追完 # 追番进度 progress: 100 # 番剧日文名称 jp: さよならの朝に約束の花をかざろう # 放送时间 time: 放送时间: 2018-02-24 SUN. # 番剧介绍 desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 - img: https://lain.bgm.tv/pic/cover/l/0e/1e/218971_2y351.jpg title: 朝花夕誓——于离别之朝束起约定之花 status: 已追完 progress: 50 jp: さよならの朝に約束の花をかざろう time: 放送时间: 2018-02-24 SUN. desc: 住在远离尘嚣的土地，一边将每天的事情编织成名为希比欧的布，一边静静生活的伊欧夫人民。在15岁左右外表就停止成长，拥有数百年寿命的他们，被称为“离别的一族”，并被视为活着的传说。没有双亲的伊欧夫少女玛奇亚，过着被伙伴包围的平稳日子，却总感觉“孤身一人”。他们的这种日常，一瞬间就崩溃消失。追求伊欧夫的长寿之血，梅萨蒂军乘坐着名为雷纳特的古代兽发动了进攻。在绝望与混乱之中，伊欧夫的第一美女蕾莉亚被梅萨蒂带走，而玛奇亚暗恋的少年克里姆也失踪了。玛奇亚虽然总算逃脱了，却失去了伙伴和归去之地……。 --- 友链页 （请直接在下载后的文件中改，下面的添加了注释可能会有些影响） --- layout: links title: links # 创建日期，可以改下 date: 2018-12-19 23:11:06 # 图片上的标题，自定义修改 keywords: 友人帐 description: # true/false 开启/关闭评论 comments: true # 页面头部图片，自定义修改 photos: https://cdn.jsdelivr.net/gh/honjun/cdn@1.4/img/banner/links.jpg # 友链配置 links: # 类型分组 - group: 个人项目 # 类型简介 desc: 充分说明这家伙是条咸鱼 &lt; (￣︶￣)&gt; items: # 友链链接 - url: https://shino.cc/fgvf # 友链头像 img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg # 友链站点名 name: Google # 友链介绍 下面雷同 desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 # 类型分组... - group: 小伙伴们 desc: 欢迎交换友链 ꉂ(ˊᗜˋ) items: - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 - url: https://shino.cc/fgvf img: https://cloud.moezx.cc/Picture/svg/landscape/fields.svg name: Google desc: Google 镜像 --- 写文章配置 主题集成了个人插件hexo-tag-bili和hexo-tag-fancybox_img。其中hexo-tag-bili用来在文章或单页面中插入B站外链视频，使用语法如下： 详细使用教程详见hexo-tag-bili。 hexo-tag-fancybox_img用来在文章或单页面中图片，使用语法如下： 详细使用教程详见hexo-tag-fancybox_img 还有啥，一时想不起来… To be continued…","categories":[{"name":"其它","slug":"其它","permalink":"/categories/其它/"}],"tags":[{"name":"web","slug":"web","permalink":"/tags/web/"},{"name":"悦读","slug":"悦读","permalink":"/tags/悦读/"}],"keywords":[{"name":"其它","slug":"其它","permalink":"/categories/其它/"}]},{"title":"neural ode","slug":"Neural ODE","date":"2020-03-04T03:38:00.000Z","updated":"2020-07-02T08:52:50.662Z","comments":true,"path":"2020/03/04/Neural ODE/","link":"","permalink":"/2020/03/04/Neural ODE/","excerpt":"","text":"原文：Neural ordinary differential equations NIPS2018最佳论文 简介 简单复习一下ResNet： 通过残差块解决反向传播过程中的梯度消失问题 ResNet、RNN、Normalizing flow 等模型都是这种形式： ht+1=ht+f(ht,θt)h_{t+1}=h_t+f(h_t,\\theta_t) ht+1​=ht​+f(ht​,θt​) 如果采用更多的层数和更小的步长，可以优化为一个常微分方程： dh(t)dt=f(h(t),t,θ)\\frac{d \\mathbf{h}(t)}{d t}=f(\\mathbf{h}(t), t, \\theta) dtdh(t)​=f(h(t),t,θ) 这就是ODE Net的核心idea了……下面进行具体的分析 给定常微分方程，数学理论上可以对其进行解析法求解，但通常我们只关心数值解：在已知h(t0)h(t_0)h(t0​) 的情况下，求出h(t1)h(t_1)h(t1​) 。这在神经网络里对应的是正向传播。用ResNet对比一下： ResNet的正向传播： ht+1=ht+f(ht,θt)h_{t+1}=h_t+f(h_t,\\theta_t) ht+1​=ht​+f(ht​,θt​) ODE网络的正向传播： dh(t)dt=f(h(t),t,θ)∫t0t1dh(t)=∫t0t1f(h(t),t,θ)dth(t1)=h(t0)+∫t0t1f(h(t),t,θ)dt\\begin{array}{c} \\frac{d h(t)}{d t}=f(h(t), t, \\theta) \\\\ \\int_{t_{0}}^{t_{1}} d h(t)=\\int_{t_{0}}^{t_{1}} f(h(t), t, \\theta) d t \\\\ h\\left(t_{1}\\right)=h\\left(t_{0}\\right)+\\int_{t_{0}}^{t_{1}} f(h(t), t, \\theta) d t \\end{array} dtdh(t)​=f(h(t),t,θ)∫t0​t1​​dh(t)=∫t0​t1​​f(h(t),t,θ)dth(t1​)=h(t0​)+∫t0​t1​​f(h(t),t,θ)dt​ 求解这个常微分方程数值解的方法有很多，最原始的是欧拉法：固定Δt\\Delta tΔt ,通过逐步迭代来求解： h(t+Δt)=h(t)+Δt∗f(h(t),t,θ)h(t+\\Delta t)=h(t)+\\Delta t * f(h(t),t,\\theta) h(t+Δt)=h(t)+Δt∗f(h(t),t,θ) 我们看到，如果令Δt=1\\Delta t=1Δt=1 ,离散化的欧拉法就退化成残差模块的表达式，也就是说ResNet可以看成是ODENet的特殊情况。 但欧拉法只是解常微分方程最基础的解法，它每走一步都会产生误差，并且误差会层层累积起来。近百年来，在数学和物理学领域已经有更成熟的ODE Solve方法，它们不仅能保证收敛到真实解，而且能够控制误差，本文在不涉及ODE Solve内部结构的前提下(将ODE Solve作为一个黑盒来使用)，研究如何用ODE Solve帮助机器学习。 这篇文章使用了一种适应性的ODE solver，它不像ResNet那样固定步长，而是根据给定的误差容忍度自动调整步长，黑色的评估位置可以视作神经元，他的位置也会根据误差容忍度自动调整： 使用ODENet的几个好处（和原文不完全一致，详细可看原文）： 一般的神经网络利用链式法则，将梯度从最外层的函数逐层向内传播，并更新每一层的参数θ\\thetaθ ,这就需要在前向传播中需要保留所有层的激活值，并在沿计算路径反传梯度时利用这些激活值。这对内存的占用非常大，层数越多，占用的内存也越大，这限制了深度模型的训练过程。 本文给出的用ODENet反向传播的方法不存储任何中间过程，因而不管层数如何加深，只需要常数级的内存成本。 自适应的计算。传统的欧拉法会有误差逐层累积的缺陷，而ODENet可以在训练过程中实时的监测误差水平，并可以调整精度来控制模型的成本。例如：在训练时我们可以使用较高的精度使训练的模型尽可能准确，而在测试时可以使用较低的精度，减少测试成本。 应用在流模型上会极大简化变分公式的计算，在下文中详细讲解 在时间上的连续性，好理解不展开 对于ODEnet在流模型上的应用，可以看一下论文FFJORD。 反向传播 在训练连续神经网络的过程中，正向传播可以使用ODE slove。但对ODE solve求导来进行反向传播求解梯度是很困难的，本篇文章使用Pontryagin的伴随方法(adjoint method) 来求解梯度，该方法不仅在计算和内存上有更大优势，同时还能够精确地控制数值误差。 具体而言，对于： L(z(t1))=L(∫t0t1f(z(t),t,θ)dt)=L( ODESolve(z (t0),f,t0,t1,θ))(1)\\left.L\\left(\\mathbf{z}\\left(t_{1}\\right)\\right)=L\\left(\\int_{t_{0}}^{t_{1}} f(\\mathbf{z}(t), t, \\theta) d t\\right)=L\\left(\\text { ODESolve(z }\\left(t_{0}\\right), f, t_{0}, t_{1}, \\theta\\right)\\right)\\tag{1} L(z(t1​))=L(∫t0​t1​​f(z(t),t,θ)dt)=L( ODESolve(z (t0​),f,t0​,t1​,θ))(1) 为优化LLL ,我们需要计算他对于参数z(t0),t0,t1z(t_0),t_0,t_1z(t0​),t0​,t1​ 和θ\\thetaθ 的梯度。 第一步是确定loss的梯度如何取决于隐藏状态z(t)z(t)z(t) 的变化，这在文章中被称作伴随a(t)a(t)a(t) (adjointa(t)adjoint \\quad a(t)adjointa(t) ) a(t)=−∂L/∂z(t)a(t) = - \\partial L / \\partial \\mathbf{z}(t) a(t)=−∂L/∂z(t) 这个a(t)a(t)a(t) 实际等价于反向传播算法中的梯度，可以由另一个ODE给定(证明补充在后面)： da(t)dt=−a(t)⊤∂f(z(t),t,θ)∂z(2)\\frac{d a(t)}{d t}=-a(t)^{\\top} \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\mathbf{z}}\\tag{2} dtda(t)​=−a(t)⊤∂z∂f(z(t),t,θ)​(2) 在传统的基于链式法则的反向传播过程中，我们将后一层对前一层进行求导以传递梯度(∂L/∂z(t0)=∂L/∂z(t1)∗∂z(t1)/∂z(t0)\\partial L/\\partial z(t_0)=\\partial L/\\partial z(t_1) * \\partial z(t_1) / \\partial z(t_0)∂L/∂z(t0​)=∂L/∂z(t1​)∗∂z(t1​)/∂z(t0​))，而在ODENet中，可以再次调用ODESolve计算∂L/∂z(t0)\\partial L/\\partial z(t_0)∂L/∂z(t0​)。 对于计算相对于参数θ\\thetaθ 的梯度，公式类似： dLdθ=∫t1t0a(t)⊤∂f(z(t),t,θ)∂θdt(3)\\frac{d L}{d \\theta}=\\int_{t_{1}}^{t_{0}} a(t)^{\\top} \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\theta} d t\\tag{3} dθdL​=∫t1​t0​​a(t)⊤∂θ∂f(z(t),t,θ)​dt(3) 这三个积分(带标号的三个)可以在同一个ODE solver过程中进行计算： 简单解释如何理解上面这个算法： 以前向传播为例，ODESolve(h(t0),f,t0,t1,θ)ODESolve(h(t_0),f,t_0,t_1,\\theta)ODESolve(h(t0​),f,t0​,t1​,θ) 表示求解常微分方程dh(t)dt=f(h(t),t,θ)\\frac{d \\mathbf{h}(t)}{d t}=f(\\mathbf{h}(t), t, \\theta)dtdh(t)​=f(h(t),t,θ) 的数值解h(t1)h(t_1)h(t1​) 。 将积分串联在一起以使用一次ODESolver解出所有量。 如果Loss不仅仅取决于最终状态，那么在用ODENet进行反向传播时，需要在这些状态中进行一系列的单独求解，每次都要调整算法中的 adjoint a(t)a(t)a(t) 。 用ODE网络替代ResNet 对图像进行两次下采样，然后分别应用六个残差块和一个ODENet进行对比： RK-Net是用Runge-Kutta积分器，直接进行反向误差的传播 LLL 表示ResNet的隐藏层数，L~\\tilde{L}L~ 表示调用ODESolve的次数。 误差控制，前向传播和反向传播的求值次数，网络深度表现在下图： a：求值次数和精度成反比 b：求值次数与时间成正比 c：求值次数与反向传播时间成正比，并且反向传播的时间大概是正向传播的一半 d：网络深度，由于ODENet是一个连续网络，没有隐藏层，因此将评估点的数量作为深度，可以看到在训练过程中网络深度逐渐增加 连续的归一化流模型 流模型的解读在前一篇博客中 流模型使用一个可逆函数fff 进行两个分布之间的映射，变换前后的两个分布满足变量代换定理： z1=f(z0)⟹log⁡p(z1)=log⁡p(z0)−log⁡∣det⁡∂f∂z0∣\\mathrm{z}_{1}=f\\left(\\mathrm{z}_{0}\\right) \\Longrightarrow \\log p\\left(\\mathrm{z}_{1}\\right)=\\log p\\left(\\mathrm{z}_{0}\\right)-\\log \\left|\\operatorname{det} \\frac{\\partial f}{\\partial \\mathrm{z}_{0}}\\right| z1​=f(z0​)⟹logp(z1​)=logp(z0​)−log∣∣∣∣​det∂z0​∂f​∣∣∣∣​ 平面归一化流(NICE之后的一篇流模型的文章，这篇论文没看……)使用的变换： z(t+1)=z(t)+uh(w⊤z(t)+b),log⁡p(z(t+1))=log⁡p(z(t))−log⁡∣1+u⊤∂h∂z∣\\mathbf{z}(t+1)=\\mathbf{z}(t)+u h\\left(w^{\\top} \\mathbf{z}(t)+b\\right), \\quad \\log p(\\mathbf{z}(t+1))=\\log p(\\mathbf{z}(t))-\\log \\left|1+u^{\\top} \\frac{\\partial h}{\\partial \\mathbf{z}}\\right| z(t+1)=z(t)+uh(w⊤z(t)+b),logp(z(t+1))=logp(z(t))−log∣∣∣∣​1+u⊤∂z∂h​∣∣∣∣​ 在流模型中，为使∂f/∂z\\partial f/\\partial z∂f/∂z 的雅可比行列式易于计算，通常是通过精心构建函数fff 来实现。并且fff 还需要是可逆的。而在这篇文章里发现，将离散的流模型换成连续流模型，可以极大的简化计算：不需要去计算∂f/∂z\\partial f/ \\partial z∂f/∂z 的行列式，只需要计算迹，并且不需要构建fff 可逆：fff 可以是任意函数，它是天然可逆的(常微分方程决定的函数只要满足唯一性，就一定是双射的)，因此fff 理论上可以是任何网络。 核心定理（梯度变元定理）： 证明过程见附录 于是我们将平面归一化流模型连续化： dz(t)dt=uh(w⊤z(t)+b),∂log⁡p(z(t))∂t=−u⊤∂h∂z(t)\\frac{d \\mathbf{z}(t)}{d t}=u h\\left(w^{\\top} \\mathbf{z}(t)+b\\right), \\quad \\frac{\\partial \\log p(\\mathbf{z}(t))}{\\partial t}=-u^{\\top} \\frac{\\partial h}{\\partial \\mathbf{z}(t)} dtdz(t)​=uh(w⊤z(t)+b),∂t∂logp(z(t))​=−u⊤∂z(t)∂h​ 不同于求行列式的值，求迹还是一个连续函数，因此如果常微分方程dz/dtdz/dtdz/dt 是由一组函数的和给出的，那么对数概率密度也可以直接用迹的和表示： dz(t)dt=∑n=1Mfn(z(t)),dlog⁡p(z(t))dt=∑n=1Mtr⁡(∂fn∂z)\\frac{d \\mathbf{z}(t)}{d t}=\\sum_{n=1}^{M} f_{n}(\\mathbf{z}(t)), \\quad \\frac{d \\log p(\\mathbf{z}(t))}{d t}=\\sum_{n=1}^{M} \\operatorname{tr}\\left(\\frac{\\partial f_{n}}{\\partial \\mathbf{z}}\\right) dtdz(t)​=n=1∑M​fn​(z(t)),dtdlogp(z(t))​=n=1∑M​tr(∂z∂fn​​) 因此对于有M个隐藏状态的连续流模型来说，计算成本仅仅是O(M)\\mathcal{O}\\left(M\\right)O(M),而平面归一化流的计算成本是O(M3)\\mathcal{O}\\left(M^{3}\\right)O(M3) 。 NF和CNF的比较： 通过ODE对时间序列建模 zt0∼p(zt0)z_{t_{0}} \\sim p\\left(z_{t_{0}}\\right) zt0​​∼p(zt0​​) zt1,zt2,…,ztN=ODESolve(zt0,f,θf,t0,…,tN)z_{t_{1}}, z_{t_{2}}, \\ldots, z_{t_{N}} =ODESolve(z_{t_0},f,\\theta_f,t_0,\\ldots,t_N) zt1​​,zt2​​,…,ztN​​=ODESolve(zt0​​,f,θf​,t0​,…,tN​) eachxti∼p(x∣zti,θX)each \\quad x_{t_i} \\sim p(x|z_{t_i},\\theta_X) eachxti​​∼p(x∣zti​​,θX​) 具体而言，在给定初始状态 z0z_0z0​ 和观测时间 t0,…tNt_0,\\ldots t_Nt0​,…tN​ 的情况下，该模型计算潜在状态 zt1…ztNz_{t_1} \\ldots z_{t_N}zt1​​…ztN​​ 和输出 xt1…xtNx_{t_1} \\ldots x_{t_N}xt1​​…xtN​​。在实验部分，初始状态z0z_0z0​由RNN编码产生，潜在状态zt1…ztNz_{t_1} \\ldots z_{t_N}zt1​​…ztN​​ 由ODESolve产生，其中的fff 用神经网络训练，然后利用VAE的方式从潜在状态中生成数据。 实验：从采样点进行螺旋线重建 均方差比较： 附录 伴随法的证明 对于z(t)z(t)z(t) 给定常微分方程： dz(t)d(t)=f(z(t),t,θ)\\frac{dz(t)}{d(t)}=f(z(t),t,\\theta) d(t)dz(t)​=f(z(t),t,θ) L(z(t1))=L(∫t0t1f(z(t),t,θ)dt)=L( ODESolve(z (t0),f,t0,t1,θ))\\left.L\\left(\\mathbf{z}\\left(t_{1}\\right)\\right)=L\\left(\\int_{t_{0}}^{t_{1}} f(\\mathbf{z}(t), t, \\theta) d t\\right)=L\\left(\\text { ODESolve(z }\\left(t_{0}\\right), f, t_{0}, t_{1}, \\theta\\right)\\right) L(z(t1​))=L(∫t0​t1​​f(z(t),t,θ)dt)=L( ODESolve(z (t0​),f,t0​,t1​,θ)) 定义便随状态： a(t)=−∂L/∂z(t)a(t) = - \\partial L / \\partial \\mathbf{z}(t) a(t)=−∂L/∂z(t) 则： da(t)dt=−a(t)⊤∂f(z(t),t,θ)∂z(2)\\frac{d a(t)}{d t}=-a(t)^{\\top} \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\mathbf{z}}\\tag{2} dtda(t)​=−a(t)⊤∂z∂f(z(t),t,θ)​(2) 证明： z(t+ε)=∫tt+εf(z(t),t,θ)dt+z(t)=Tε(z(t),t)\\mathbf{z}(t+\\varepsilon)=\\int_{t}^{t+\\varepsilon} f(\\mathbf{z}(t), t, \\theta) d t+\\mathbf{z}(t)=T_{\\varepsilon}(\\mathbf{z}(t), t) z(t+ε)=∫tt+ε​f(z(t),t,θ)dt+z(t)=Tε​(z(t),t) 然后应用链式法则，有： dL∂z(t)=dLdz(t+ε)dz(t+ε)dz(t) or a(t)=a(t+ε)∂Tε(z(t),t)∂z(t)\\frac{d L}{\\partial \\mathbf{z}(t)}=\\frac{d L}{d \\mathbf{z}(t+\\varepsilon)} \\frac{d \\mathbf{z}(t+\\varepsilon)}{d \\mathbf{z}(t)} \\quad \\text { or } \\quad \\mathbf{a}(t)=\\mathbf{a}(t+\\varepsilon) \\frac{\\partial T_{\\varepsilon}(\\mathbf{z}(t), t)}{\\partial \\mathbf{z}(t)} ∂z(t)dL​=dz(t+ε)dL​dz(t)dz(t+ε)​ or a(t)=a(t+ε)∂z(t)∂Tε​(z(t),t)​ 利用导数定义，并进行泰勒展开进行化简计算： da(t)dt=lim⁡ε→0+a(t+ε)−a(t)ε=lim⁡ε→0+a(t+ε)−a(t+ε)∂∂z(t)Tε(z(t))ε=lim⁡ε→0+a(t+ε)−a(t+ε)∂∂z(t)(z(t)+εf(z(t),t,θ)+O(ε2))ε=lim⁡ε→0+a(t+ε)−a(t+ε)(I+ε∂f(z(t),t,θ)θz(t)+O(ε2))ε=lim⁡ε→0+−εa(t+ε)∂f(z(t),t,θ)∂z(t)+O(ε2)ε=lim⁡ε→0+−a(t+ε)∂f(z(t),t,θ)∂z(t)+O(ε)=−a(t)∂f(z(t),t,θ)∂z(t)\\begin{aligned} \\frac{d \\mathbf{a}(t)}{d t} &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\mathbf{a}(t+\\varepsilon)-\\mathbf{a}(t)}{\\varepsilon} \\\\ &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\mathbf{a}(t+\\varepsilon)-\\mathbf{a}(t+\\varepsilon) \\frac{\\partial}{\\partial \\mathbf{z}(t)} T_{\\varepsilon}(\\mathbf{z}(t))}{\\varepsilon} \\\\ &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\mathbf{a}(t+\\varepsilon)-\\mathbf{a}(t+\\varepsilon) \\frac{\\partial}{\\partial \\mathbf{z}(t)}\\left(\\mathbf{z}(t)+\\varepsilon f(\\mathbf{z}(t), t, \\theta)+\\mathcal{O}\\left(\\varepsilon^{2}\\right)\\right)}{\\varepsilon} \\\\ &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\mathbf{a}(t+\\varepsilon)-\\mathbf{a}(t+\\varepsilon)\\left(I+\\varepsilon \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\theta \\mathbf{z}(t)}+\\mathcal{O}\\left(\\varepsilon^{2}\\right)\\right)}{\\varepsilon} \\\\ &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{-\\varepsilon \\mathbf{a}(t+\\varepsilon) \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\mathbf{z}(t)}+\\mathcal{O}\\left(\\varepsilon^{2}\\right)}{\\varepsilon} \\\\ &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}}-\\mathbf{a}(t+\\varepsilon) \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\mathbf{z}(t)}+\\mathcal{O}(\\varepsilon) \\\\ &amp;=-\\mathbf{a}(t) \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\mathbf{z}(t)} \\end{aligned} dtda(t)​​=ε→0+lim​εa(t+ε)−a(t)​=ε→0+lim​εa(t+ε)−a(t+ε)∂z(t)∂​Tε​(z(t))​=ε→0+lim​εa(t+ε)−a(t+ε)∂z(t)∂​(z(t)+εf(z(t),t,θ)+O(ε2))​=ε→0+lim​εa(t+ε)−a(t+ε)(I+εθz(t)∂f(z(t),t,θ)​+O(ε2))​=ε→0+lim​ε−εa(t+ε)∂z(t)∂f(z(t),t,θ)​+O(ε2)​=ε→0+lim​−a(t+ε)∂z(t)∂f(z(t),t,θ)​+O(ε)=−a(t)∂z(t)∂f(z(t),t,θ)​​ 对于θ\\thetaθ 和ttt 定义增强状态： ddt[zθt](t)=faug⁡([z,θ,t]):=[f([z,θ,t])01],aaug:=[aaθat],aθ(t):=dLdθ(t),at(t):=dLdt(t)\\frac{d}{d t}\\left[\\begin{array}{l} \\mathrm{z} \\\\ \\theta \\\\ t \\end{array}\\right](t)=f_{\\operatorname{aug}}([\\mathrm{z}, \\theta, t]):=\\left[\\begin{array}{c} f([\\mathrm{z}, \\theta, t]) \\\\ 0 \\\\ 1 \\end{array}\\right], \\mathbf{a}_{a u g}:=\\left[\\begin{array}{l} \\mathrm{a} \\\\ \\mathrm{a}_{\\theta} \\\\ \\mathrm{a}_{t} \\end{array}\\right], \\mathrm{a}_{\\theta}(t):=\\frac{d L}{d \\theta(t)}, \\mathrm{a}_{t}(t):=\\frac{d L}{d t(t)} dtd​⎣⎡​zθt​⎦⎤​(t)=faug​([z,θ,t]):=⎣⎡​f([z,θ,t])01​⎦⎤​,aaug​:=⎣⎡​aaθ​at​​⎦⎤​,aθ​(t):=dθ(t)dL​,at​(t):=dt(t)dL​ 其中θ\\thetaθ 和ttt 无关，即dθ(t)/dt=0,dt(t)/dt=1d\\theta(t) /dt=0,dt(t)/dt=1dθ(t)/dt=0,dt(t)/dt=1 计算雅可比行列式： ∂faug∂[z,θ,t]=[∂f∂z∂f∂θ∂f∂t000000]\\frac{\\partial f_{a u g}}{\\partial[\\mathbf{z}, \\theta, t]}=\\left[\\begin{array}{ccc} \\frac{\\partial f}{\\partial z} &amp; \\frac{\\partial f}{\\partial \\theta} &amp; \\frac{\\partial f}{\\partial t} \\\\ 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 \\end{array}\\right] ∂[z,θ,t]∂faug​​=⎣⎡​∂z∂f​00​∂θ∂f​00​∂t∂f​00​⎦⎤​ 直接将faugf_{aug}faug​ 和aauga_{aug}aaug​ 代入上一小节的伴随法公式： daaug(t)dt=−[a(t)aθ(t)at(t)]∂faug∂[z,θ,t](t)=−[a∂f∂za∂f∂θa∂f∂t](t)\\frac{d \\mathbf{a}_{a u g}(t)}{d t}=-\\left[\\begin{array}{lllll} \\mathbf{a}(t) &amp; \\mathbf{a}_{\\theta}(t) &amp; \\mathbf{a}_{t}(t) \\end{array}\\right] \\frac{\\partial f_{\\text {aug}}}{\\partial[\\mathbf{z}, \\theta, t]}(t)=-\\left[\\begin{array}{lll} \\mathbf{a} \\frac{\\partial f}{\\partial \\mathbf{z}} &amp; \\mathbf{a} \\frac{\\partial f}{\\partial \\theta} &amp; \\mathbf{a} \\frac{\\partial f}{\\partial t} \\end{array}\\right](t) dtdaaug​(t)​=−[a(t)​aθ​(t)​at​(t)​]∂[z,θ,t]∂faug​​(t)=−[a∂z∂f​​a∂θ∂f​​a∂t∂f​​](t) 于是得到了最终的结论： dLdθ=∫tNt0a(t)∂f(z(t),t,θ)∂θdt\\frac{d L}{d \\theta}=\\int_{t_{N}}^{t_{0}} \\mathbf{a}(t) \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial \\theta} d t dθdL​=∫tN​t0​​a(t)∂θ∂f(z(t),t,θ)​dt dLdtN=−a(tN)∂f(z(tN),tN,θ)∂tNdLdt0=∫tNt0a(t)∂f(z(t),t,θ)∂tdt\\frac{d L}{d t_{N}}=-\\mathbf{a}\\left(t_{N}\\right) \\frac{\\partial f\\left(\\mathbf{z}\\left(t_{N}\\right), t_{N}, \\theta\\right)}{\\partial t_{N}} \\quad \\frac{d L}{d t_{0}}=\\int_{t_{N}}^{t_{0}} \\mathbf{a}(t) \\frac{\\partial f(\\mathbf{z}(t), t, \\theta)}{\\partial t} d t dtN​dL​=−a(tN​)∂tN​∂f(z(tN​),tN​,θ)​dt0​dL​=∫tN​t0​​a(t)∂t∂f(z(t),t,θ)​dt 梯度变元定理的证明 给定常微分方程： dz(t)d(t)=f(z(t),t)\\frac{dz(t)}{d(t)}=f(z(t),t) d(t)dz(t)​=f(z(t),t) fff 要求对zzz Lipschitz连续，对ttt 连续。则对数概率密度满足： ∂log⁡p(z(t))∂t=−tr⁡(dfdz(t))\\frac{\\partial \\log p(\\mathbf{z}(t))}{\\partial t}=-\\operatorname{tr}\\left(\\frac{d f}{d \\mathbf{z}}(t)\\right) ∂t∂logp(z(t))​=−tr(dzdf​(t)) 证明： 首先类似上面伴随法证明的过程，将z(t+ε)z(t+\\varepsilon)z(t+ε) 表示为Tε(z(t))T_{\\varepsilon}(\\mathbf{z}(t))Tε​(z(t)) fff 要求对zzz Lipschitz连续，对ttt 连续。这是为了使方程满足Picard存在定理，使得解存在且唯一。 首先是要推导出 ∂log⁡p(z(t))∂t=−tr⁡(lim⁡ε→0+∂∂ϵ∂∂zTε(z(t)))\\frac{\\partial \\log p(z(t))}{\\partial t}=-\\operatorname{tr}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\epsilon} \\frac{\\partial}{\\partial z} T_{\\varepsilon}(z(t))\\right) ∂t∂logp(z(t))​=−tr(ε→0+lim​∂ϵ∂​∂z∂​Tε​(z(t))) 过程： ∂log⁡p(z(t))∂t=lim⁡ε→0+log⁡p(z(t))−log⁡∣det⁡∂∂zTε(z(t))∣−log⁡p(z(t))ε=−lim⁡ε→0+log⁡∣det⁡∂∂zTε(z(t))∣ε=−lim⁡ε→0+∂∂εlog⁡∣det⁡∂∂zTε(z(t))∣∂∂εε=−lim⁡ε→0+∂∂ε∣det⁡∂∂zTε(z(t))∣∣det⁡∂∂zTε(z(t))∣(∂log⁡(z)∂z∣z=1=1)=−(lim⁡ε→0+∂∂ε∣det⁡∂∂zTε(z(t))∣)⏟bounded (lim⁡ε→0+1∣det⁡∂∂zTε(z(t))∣)=−lim⁡ε→0+∂∂ε∣det⁡∂∂zTε(z(t))∣\\begin{aligned} \\frac{\\partial \\log p(\\mathbf{z}(t))}{\\partial t} &amp;=\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\log p(\\mathbf{z}(t))-\\log \\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|-\\log p(\\mathbf{z}(t))}{\\varepsilon} \\\\ &amp;=-\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\log \\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|}{\\varepsilon}\\\\ &amp;=-\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\frac{\\partial}{\\partial \\varepsilon} \\log \\left|\\operatorname{det} \\frac{\\partial}{\\partial z} T_{\\varepsilon}(\\mathbf{z}(t))\\right|}{\\frac{\\partial}{\\partial \\varepsilon} \\varepsilon}\\\\ &amp;=-\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\frac{\\partial}{\\partial \\varepsilon}\\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|}{\\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|} \\qquad \\qquad \\quad \\left(\\left.\\frac{\\partial \\log (\\mathbf{z})}{\\partial \\mathbf{z}}\\right|_{\\mathbf{z}=1}=1\\right)\\\\ &amp;=-\\underbrace{\\left(\\lim _{\\varepsilon \\rightarrow 0+} \\frac{\\partial}{\\partial \\varepsilon}\\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|\\right)}_{\\text {bounded }}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{1}{\\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right|}\\right)\\\\ &amp;=-\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\varepsilon}\\left|\\operatorname{det} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right| \\end{aligned} ∂t∂logp(z(t))​​=ε→0+lim​εlogp(z(t))−log∣∣​det∂z∂​Tε​(z(t))∣∣​−logp(z(t))​=−ε→0+lim​εlog∣∣​det∂z∂​Tε​(z(t))∣∣​​=−ε→0+lim​∂ε∂​ε∂ε∂​log∣∣​det∂z∂​Tε​(z(t))∣∣​​=−ε→0+lim​∣∣​det∂z∂​Tε​(z(t))∣∣​∂ε∂​∣∣​det∂z∂​Tε​(z(t))∣∣​​(∂z∂log(z)​∣∣∣∣​z=1​=1)=−bounded (ε→0+lim​∂ε∂​∣∣∣∣​det∂z∂​Tε​(z(t))∣∣∣∣​)​​(ε→0+lim​∣∣​det∂z∂​Tε​(z(t))∣∣​1​)=−ε→0+lim​∂ε∂​∣∣∣∣​det∂z∂​Tε​(z(t))∣∣∣∣​​ 第一步用到的是流模型中的公式(本质是概率密度上的雅可比公式)，后面仅用到洛必达法则、链式法则等简单技巧。 然后应用雅可比公式： ∂log⁡p(z(t))∂t=−lim⁡ε→0+tr⁡(adj⁡(∂∂zTε(z(t)))∂∂ε∂∂zTε(z(t)))=−tr⁡((lim⁡ε→0+adj⁡(∂∂zTε(z(t))))⏟=I(lim⁡ε→0+∂∂ε∂∂zTε(z(t))))=−tr⁡(lim⁡ε→0+∂∂ε∂∂zTε(z(t)))\\begin{aligned} \\frac{\\partial \\log p(\\mathbf{z}(t))}{\\partial t} &amp;=-\\lim _{\\varepsilon \\rightarrow 0^{+}} \\operatorname{tr}\\left(\\operatorname{adj}\\left(\\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right) \\frac{\\partial}{\\partial \\varepsilon} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right) \\\\ &amp;=-\\operatorname{tr}\\left(\\underbrace{\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\operatorname{adj}\\left(\\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right)\\right)}_{=I}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\varepsilon} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right)\\right) \\\\ &amp;=-\\operatorname{tr}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\varepsilon} \\frac{\\partial}{\\partial \\mathbf{z}} T_{\\varepsilon}(\\mathbf{z}(t))\\right) \\end{aligned} ∂t∂logp(z(t))​​=−ε→0+lim​tr(adj(∂z∂​Tε​(z(t)))∂ε∂​∂z∂​Tε​(z(t)))=−tr⎝⎜⎜⎛​=I(ε→0+lim​adj(∂z∂​Tε​(z(t))))​​(ε→0+lim​∂ε∂​∂z∂​Tε​(z(t)))⎠⎟⎟⎞​=−tr(ε→0+lim​∂ε∂​∂z∂​Tε​(z(t)))​ 雅可比公式是： ddtdet(A(t))=tr(adj(A(t))ddtA(t))\\frac{d}{dt}det(A(t))=tr(adj(A(t))\\frac{d}{dt}A(t)) dtd​det(A(t))=tr(adj(A(t))dtd​A(t)) 最后进行泰勒展开即可： ∂log⁡p(z(t))∂t=−tr⁡(lim⁡ε→0+∂∂ε∂∂z(z+εf(z(t),t)+O(ε2)+O(ε3)+…))=−tr⁡(lim⁡ε→0+∂∂ε(I+∂∂zεf(z(t),t)+O(ε2)+O(ε3)+…))=−tr⁡(lim⁡ε→0+(∂∂zf(z(t),t)+O(ε)+O(ε2)+…))=−tr⁡(∂∂zf(z(t),t))\\begin{aligned} \\frac{\\partial \\log p(\\mathbf{z}(t))}{\\partial t} &amp;=-\\operatorname{tr}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\varepsilon} \\frac{\\partial}{\\partial \\mathbf{z}}\\left(\\mathbf{z}+\\varepsilon f(\\mathbf{z}(t), t)+\\mathcal{O}\\left(\\varepsilon^{2}\\right)+\\mathcal{O}\\left(\\varepsilon^{3}\\right)+\\ldots\\right)\\right) \\\\ &amp;=-\\operatorname{tr}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}} \\frac{\\partial}{\\partial \\varepsilon}\\left(I+\\frac{\\partial}{\\partial \\mathbf{z}} \\varepsilon f(\\mathbf{z}(t), t)+\\mathcal{O}\\left(\\varepsilon^{2}\\right)+\\mathcal{O}\\left(\\varepsilon^{3}\\right)+\\ldots\\right)\\right) \\\\ &amp;=-\\operatorname{tr}\\left(\\lim _{\\varepsilon \\rightarrow 0^{+}}\\left(\\frac{\\partial}{\\partial \\mathbf{z}} f(\\mathbf{z}(t), t)+\\mathcal{O}(\\varepsilon)+\\mathcal{O}\\left(\\varepsilon^{2}\\right)+\\ldots\\right)\\right) \\\\ &amp;=-\\operatorname{tr}\\left(\\frac{\\partial}{\\partial \\mathbf{z}} f(\\mathbf{z}(t), t)\\right) \\end{aligned} ∂t∂logp(z(t))​​=−tr(ε→0+lim​∂ε∂​∂z∂​(z+εf(z(t),t)+O(ε2)+O(ε3)+…))=−tr(ε→0+lim​∂ε∂​(I+∂z∂​εf(z(t),t)+O(ε2)+O(ε3)+…))=−tr(ε→0+lim​(∂z∂​f(z(t),t)+O(ε)+O(ε2)+…))=−tr(∂z∂​f(z(t),t))​","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"neural ode","slug":"neural-ode","permalink":"/tags/neural-ode/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"gan,vae和flow","slug":"GAN VAE and Flow","date":"2020-02-15T13:19:00.000Z","updated":"2020-07-01T11:08:38.809Z","comments":true,"path":"2020/02/15/GAN VAE and Flow/","link":"","permalink":"/2020/02/15/GAN VAE and Flow/","excerpt":"","text":"前言 GAN，VAE和FLOW的目标是一致的——希望构建一个从隐变量ZZZ生成目标数据XXX的模型，其中先验分布P(z)P(z)P(z)通常被设置为高斯分布。我们希望找到一个变换函数f(x)f(x)f(x)，他能建立一个从zzz到xxx的映射：f:z→xf:z\\to xf:z→x，然后在P(Z)P(Z)P(Z)中随机采样一个点z′z&#x27;z′，通过映射fff，就可以找到一个新的样本点x′x&#x27;x′。 举个栗子： 如何将均匀分布U[0,1]U[0,1]U[0,1]映射成正态分布N(0,1)N(0,1)N(0,1)？ 将X∼U[0,1]X \\sim U[0,1]X∼U[0,1]经过函数Y=f(x)Y = f(x)Y=f(x)映射之后，就有Y∼N(0,1)Y\\sim N(0,1)Y∼N(0,1)了那么[x,x+dx][x,x+dx][x,x+dx]和[y,y+dy][y,y+dy][y,y+dy]两个区间上的概率应该相等，即： ρ(x)dx=12πexp⁡(−y22)dy\\rho(x) d x=\\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{y^{2}}{2}\\right) d y ρ(x)dx=2π​1​exp(−2y2​)dy 对其进行积分，有： ∫0xρ(t)dt=∫−∞y12πexp⁡(−t22)dt=Φ(y)\\int_{0}^{x} \\rho(t) d t=\\int_{-\\infty}^{y} \\frac{1}{\\sqrt{2 \\pi}} \\exp \\left(-\\frac{t^{2}}{2}\\right) d t=\\Phi(y) ∫0x​ρ(t)dt=∫−∞y​2π​1​exp(−2t2​)dt=Φ(y) y=Φ−1(∫0xρ(t)dt)=f(x)y=\\Phi^{-1}\\left(\\int_{0}^{x} \\rho(t) d t\\right)=f(x) y=Φ−1(∫0x​ρ(t)dt)=f(x) 可以看到Y=f(X)Y = f(X)Y=f(X)的解是存在的，但很复杂，无法用初等函数进行显示的表示，因此在大多数情况下，我们都是通过神经网络来拟合这个函数。 假设我们现在已经有一个映射fff，我们如何衡量映射fff构造出来的数据集f(z1),f(z2),...,f(zn)f(z_1),f(z_2),...,f(z_n)f(z1​),f(z2​),...,f(zn​)，是否和目标数据XXX分布相同？(注：KL和JS距离根据两个概率分布的表达式计算分布的相似度，而我们现在只有从构造的分布采样的数据和真实分布采样的数据，而离散化的KL和JS距离因为图像维度问题，计算量非常大)。在这里GAN采用了一个暴力的办法：训练一个判别器作为两者相似性的度量，而VAE(变分自编码器)和FLOW(流模型)在最大化最大似然。 VAE(变分自编码器) VAE的基本思路 对于连续随机变量，概率分布PPP和QQQ，KL散度(又称相对熵)的定义为： DKL(P∥Q)=∫−∞∞p(x)ln⁡p(x)q(x)dx=Ex∼P(x)[logP(x)−logQ(x)]D_{\\mathrm{KL}}(P \\| Q)=\\int_{-\\infty}^{\\infty} p(x) \\ln \\frac{p(x)}{q(x)} \\mathrm{d} x=E_{x \\sim P(x)}[logP(x)-logQ(x)] DKL​(P∥Q)=∫−∞∞​p(x)lnq(x)p(x)​dx=Ex∼P(x)​[logP(x)−logQ(x)] 给定一个概率分布DDD,已知其概率密度函数(连续分布)或概率质量函数(离散分布)为fDf_DfD​，以及一个分布参数θ\\thetaθ，我们可以从这个分布中抽出一个具有nnn个值的采样X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​，利用fDf_DfD​计算出其似然函数： L(θ∣x1,…,xn)=fθ(x1,…,xn)\\mathbf{L}\\left(\\theta | x_{1}, \\ldots, x_{n}\\right)=f_{\\theta}\\left(x_{1}, \\ldots, x_{n}\\right) L(θ∣x1​,…,xn​)=fθ​(x1​,…,xn​) 若DDD是离散分布，fθf_{\\theta}fθ​即是在参数为θ\\thetaθ时观测到这一采样的概率。若其是连续分布，fθf_{\\theta}fθ​则为X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​联合分布的概率密度函数在观测值处的取值。一旦我们获得X1,X2,...,XnX_1,X_2,...,X_nX1​,X2​,...,Xn​，我们就能求得一个关于θ\\thetaθ的估计。最大似然估计会寻找关于的最可能的值（即，在所有可能的取值中，寻找一个值使这个采样的“可能性”最大化）。从数学上来说，我们可以在的所有可能取值中寻找一个值使得似然函数取到最大值。这个使可能性最大的值即称为的最大似然估计。由定义，最大似然估计是样本的函数。 注：下面忽略积分号和求和的差异 VAE做最大似然估计，也就是要最大化概率： P(X)=∑iP(X∣zi;θ)P(zi)P(X)=\\sum_{i} P\\left(X | z_{i} ; \\theta\\right) P\\left(z_{i}\\right) P(X)=i∑​P(X∣zi​;θ)P(zi​) 一般选择P(Z)P(Z)P(Z)服从一个高斯分布，而p(X∣z)p(X|z)p(X∣z)可以是任意分布，例如条件高斯分布或狄拉克分布，理论上讲，这个积分形式的分布可以拟合任意分布。 实际上，最大似然估计与最小化两个分布之间的KL距离是等价的: argminKL(p(x)∥q(x))=argmin∫p(x)logp(x)q(x)dx=argmax∫p(x)q(x)dx=argmaxEx∼p(x)q(x)\\begin{aligned} argmin{KL(p(x)\\|q(x))} &amp;= argmin \\int p(x)log \\frac{p(x)}{q(x)}dx \\\\ &amp;= argmax \\int p(x)q(x)dx \\\\ &amp;=argmaxE_{x \\sim p(x)}q(x) \\end{aligned} argminKL(p(x)∥q(x))​=argmin∫p(x)logq(x)p(x)​dx=argmax∫p(x)q(x)dx=argmaxEx∼p(x)​q(x)​ 但是这里的P(X)P(X)P(X)是积分形式的，很难进行计算。VAE从让人望而生畏的变分和贝叶斯理论出发，推导出了一个很接地气的公式： log⁡P(X)−D[Q(z∣X)∥P(z∣X)]=Ez∼Q[log⁡P(X∣z)]−D[Q(z∣X)∥P(z)](1)\\log P(X)-\\mathcal{D}[Q(z | X) \\| P(z | X)]=E_{z \\sim Q}[\\log P(X | z)]-\\mathcal{D}[Q(z | X) \\| P(z)] \\tag{1} logP(X)−D[Q(z∣X)∥P(z∣X)]=Ez∼Q​[logP(X∣z)]−D[Q(z∣X)∥P(z)](1) VAE并没有选择直接去优化P(X)P(X)P(X)，而是选择去优化他的一个变分下界（公式1右端）。 而VAE的自编码器性质也从这个公式里开始体现出来：我们可以将D[Q(z∣X)∥P(z)]\\mathcal{D}[Q(z | X) \\| P(z)]D[Q(z∣X)∥P(z)]视作编码器的优化，使由真实数据编码出的隐变量分布Q(z∣X)Q(z|X)Q(z∣X)去尽量近似P(z)P(z)P(z)（标准高斯分布），而将Ez∼Q[log⁡P(X∣z)]E_{z \\sim Q}[\\log P(X | z)]Ez∼Q​[logP(X∣z)]视作解码器的优化，使得服从分布QQQ的隐变量zzz解码出的xxx尽可能地服从真是数据分布，而将D[Q(z∣X)∥P(z∣X)]\\mathcal{D}[Q(z | X) \\| P(z | X)]D[Q(z∣X)∥P(z∣X)]视作误差项。 但VAE也因为它并没有直接去优化P(X)P(X)P(X)，而选择去优化它的变分下界，使得他只是一个近似模型，无法保证良好的生成效果。 VAE的优化过程 首先要确定概率密度Q(z∣X)Q(z|X)Q(z∣X)的形式，一般选择正态分布，即N(μ,σ2)\\mathcal{N}\\left(\\mu, \\sigma^{2}\\right)N(μ,σ2)，其中μ(X;θμ),σ2(X;θσ)\\mu\\left(X ; \\theta_{\\mu}\\right) , \\sigma^{2}\\left(X ; \\theta_{\\sigma}\\right)μ(X;θμ​),σ2(X;θσ​)通过两个神经网络(编码器)训练出来。公式中的D[Q(z∣X)∥P(z)]\\mathcal{D}[Q(z | X) \\| P(z)]D[Q(z∣X)∥P(z)]变为D[N(μ(X;θμ),σ2(X;θσ))∥N(0,I)]D\\left[\\mathcal{N}\\left(\\mu\\left(X ; \\theta_{\\mu}\\right), \\sigma^{2}\\left(X ; \\theta_{\\sigma}\\right)\\right) \\| \\mathcal{N}(0, I)\\right]D[N(μ(X;θμ​),σ2(X;θσ​))∥N(0,I)]，这个时候就可以通过两个正态分布的KL散度的计算公式来计算这一项。 对于第一项Ez∼Q[log⁡P(X∣z)]E_{z \\sim Q}[\\log P(X | z)]Ez∼Q​[logP(X∣z)]，对于一个batch来说，可以在QQQ中采样，然后将单个样本的log⁡P(X∣z)\\log P(X|z)logP(X∣z)求和取平均数作为期望的估计。但这样出现一个问题：把Q(z∣X)Q(z|X)Q(z∣X)弄丢了，也就是每次训练的时候梯度不传进QQQ里，论文里采用了一个称为重参数化技巧(reparamenterization trick)的方法，如图： 至此，整个VAE网络就可以训练了。 公式推导部分 D[Q(z∣X)∣∣P(z∣X)]=Ez∼Q[log⁡Q(z∣X)−log⁡P(z∣X)]=Ez∼Q[log⁡Q(z∣X)−log⁡P(z∣X)−log⁡P(X)]+log⁡P(X)\\begin{aligned} \\mathcal{D}[Q(z|X)||P(z|X)] &amp;= E_{z \\sim Q}[\\log Q(z|X) - \\log P(z|X)] \\\\ &amp;= E_{z \\sim Q}[\\log Q(z|X) - \\log P(z|X) - \\log P(X)] + \\log P(X) \\end{aligned} D[Q(z∣X)∣∣P(z∣X)]​=Ez∼Q​[logQ(z∣X)−logP(z∣X)]=Ez∼Q​[logQ(z∣X)−logP(z∣X)−logP(X)]+logP(X)​ 移项得 log⁡P(X)−D[Q(z∣X)∥P(z∣X)]=Ez∼Q[log⁡P(X∣z)]−D[Q(z∣X)∥P(z)]\\log P(X)-\\mathcal{D}[Q(z | X) \\| P(z | X)]=E_{z \\sim Q}[\\log P(X | z)]-\\mathcal{D}[Q(z | X) \\| P(z)] logP(X)−D[Q(z∣X)∥P(z∣X)]=Ez∼Q​[logP(X∣z)]−D[Q(z∣X)∥P(z)] GAN 模型构建 由于大家都对GAN比较熟悉，本文直接从变分推断的角度去理解GAN。 不同于VAE将P(X∣z)P(X|z)P(X∣z)选为高斯分布，GAN的选择是： P(x∣z)=δ(x−G(z)),P(x)=∫P(x∣z)P(z)dzP(x | z)=\\delta(x-G(z)), \\quad P(x)=\\int P(x | z) P(z) d z P(x∣z)=δ(x−G(z)),P(x)=∫P(x∣z)P(z)dz 其中δ(x)\\delta (x)δ(x)是狄拉克函数，G(z)G(z)G(z)为生成器网络。 在VAE中z被当作是一个隐变量，但在GAN中，狄拉克函数意味着单点分布，即x和z为一一对应的关系。于是在GAN中z没有被当作隐变量处理(不需要考虑后验分布P(z∣x)P(z|x)P(z∣x)) 判别器的理解： 在GAN中引入了一个二元的隐变量y来构成联合分布，其中p~(x)\\tilde{p}(x)p~​(x) 为真实样本的分布： q(x,y)={p~(x)p1,y=1p(x)p0,y=0q(x, y)=\\left\\{\\begin{array}{l} {\\tilde{p}(x) p_{1}, y=1} \\\\ {p(x) p_{0}, y=0} \\end{array}\\right. q(x,y)={p~​(x)p1​,y=1p(x)p0​,y=0​ 这里y是图像的真实标签，当图片为真实图片时，y=1，当图片是生成图片时，y=0。 其中p0,p1p_0, p_1p0​,p1​代表权重，在下面讨论中我们直接取p0=p1=1/2p_0=p_1=1/2p0​=p1​=1/2 另一方面，我们需要使判别器的判别结果尽可能真实，设p(x,y)=p(y∣x)p~(x)p(x,y)=p(y|x)\\tilde{p}(x)p(x,y)=p(y∣x)p~​(x)，p(y∣x)p(y|x)p(y∣x)为一个条件伯努利分布(判别器的判别结果)。优化目标是KL(q(x,y)∣∣p(x,y))KL(q(x,y)||p(x,y))KL(q(x,y)∣∣p(x,y))： KL(q(x,y)∥p(x,y))=∫p~(x)p1log⁡p~(x)p1p(1∣x)p~(x)dx+∫p(x)p0log⁡p(x)p0p(0∣x)p~(x)dx∼∫p~(x)log⁡12p(1∣x)dx+∫p(x)log⁡p(x)2p(0∣x)p~(x)dx=−Ex∼p~(x)[log⁡2p(1∣x)]−Ex∼p(x)[log⁡2p(0∣x)]+KL(p(x)∣∣p~(x))\\begin{aligned} K L(q(x, y) \\| p(x, y)) &amp;=\\int \\tilde{p}(x) p_{1} \\log \\frac{\\tilde{p}(x) p_{1}}{p(1 | x) \\tilde{p}(x)} d x+\\int p(x) p_{0} \\log \\frac{p(x) p_{0}}{p(0 | x) \\tilde{p}(x)} d x \\\\ &amp; \\sim \\int \\tilde{p}(x) \\log \\frac{1}{2p(1 | x)} d x+\\int p(x) \\log \\frac{p(x)}{2p(0 | x) \\tilde{p}(x)} d x\\\\ &amp; = -E_{x \\sim \\tilde{p}(x)}[\\log 2p(1|x)]-E_{x \\sim p(x)}[\\log 2p(0|x)]+KL(p(x)||\\tilde{p}(x)) \\end{aligned} KL(q(x,y)∥p(x,y))​=∫p~​(x)p1​logp(1∣x)p~​(x)p~​(x)p1​​dx+∫p(x)p0​logp(0∣x)p~​(x)p(x)p0​​dx∼∫p~​(x)log2p(1∣x)1​dx+∫p(x)log2p(0∣x)p~​(x)p(x)​dx=−Ex∼p~​(x)​[log2p(1∣x)]−Ex∼p(x)​[log2p(0∣x)]+KL(p(x)∣∣p~​(x))​ 一旦成功优化，就有q(x,y)→p(x,y)q(x,y)\\to p(x,y)q(x,y)→p(x,y)，对于x求边缘概率分布，有： 12p~(x)+12p(x)→p(1∣x)p~(x)+p(0∣x)p~(x)=p~(x)\\frac{1}{2}\\tilde{p}(x)+\\frac{1}{2}p(x)\\to p(1|x)\\tilde{p}(x)+p(0|x)\\tilde{p}(x)=\\tilde{p}(x) 21​p~​(x)+21​p(x)→p(1∣x)p~​(x)+p(0∣x)p~​(x)=p~​(x) 即： p(x)→p~(x)p(x)\\to \\tilde{p}(x) p(x)→p~​(x) 这就完成了对模型的构建。 目标优化 现在我们有优化目标：p(1∣x)p(1|x)p(1∣x)和G(z)G(z)G(z)，分别是判别器(p(y∣x)p(y|x)p(y∣x)服从条件伯努利分布，可以直接由p(1∣x)p(1|x)p(1∣x)确定)和生成器(p(x)p(x)p(x)由G(z)G(z)G(z)决定)。类似EM算法，我们进行交替优化：先固定G(z)G(z)G(z),这也意味着p(x)p(x)p(x)固定了，然后优化p(y∣x)p(y|x)p(y∣x)，优化目标为： D=arg⁡min⁡D{−Ex∼p~(x)[log⁡2D(x)]−Ex∼p(x)[log⁡2(1−D(x))]}D=\\underset{D}{\\arg \\min }\\{-E_{x \\sim \\tilde{p}(x)}[\\log 2D(x)]-\\mathbb{E}_{x \\sim p(x)}[\\log 2(1-D(x))]\\} D=Dargmin​{−Ex∼p~​(x)​[log2D(x)]−Ex∼p(x)​[log2(1−D(x))]} 当生成器固定时，p(x)p(x)p(x) 也固定，分别记p~(x),p(x),D(x)\\tilde{p}(x),p(x),D(x)p~​(x),p(x),D(x) 为a,b,ta,b,ta,b,t ,忽略常数项，优化目标变为： D=argmax∫p~(x)log⁡t+p(x)log⁡(1−t)dxD=argmax \\int \\tilde{p}(x)\\log t + p(x) \\log(1-t)dx D=argmax∫p~​(x)logt+p(x)log(1−t)dx 求导算出其理论最优解为t=D(x)=p~(x)p~(x)+p0(x)t=D(x)=\\frac{\\tilde{p}(x)}{\\tilde{p}(x)+p^0(x)}t=D(x)=p~​(x)+p0(x)p~​(x)​ 然后固定D(x)D(x)D(x)来优化G(x)G(x)G(x)，相关loss为： G=arg⁡min⁡G∫p(x)log⁡p0p(x)(1−D(x))p~(x)dxG=\\underset{G}{\\arg \\min } \\int p(x) \\log \\frac{p_0 p(x)}{(1-D(x)) \\tilde{p}(x)} d x G=Gargmin​∫p(x)log(1−D(x))p~​(x)p0​p(x)​dx 假设D(x)D(x)D(x)有足够的拟合能力，当D(x)=p~(x)p~(x)+p0(x)D(x)=\\frac{\\tilde{p}(x)}{\\tilde{p}(x)+p^0(x)}D(x)=p~​(x)+p0(x)p~​(x)​时，有 KL(q(x,y)∥p0(x,y))=∫p~(x)log⁡12D(x)dx+∫p0(x)log⁡p0(x)2(1−D(x))p~(x)dx=∫p~(x)log⁡p~(x)+p0(x)2p~(x)+p0(x)log⁡p~(x)+p0(x)2p~(x)=KL(p~(x)+p0(x)∣∣2p~(x))\\begin{aligned} K L(q(x, y) \\| p^0(x, y)) &amp;= \\int \\tilde{p}(x) \\log \\frac{1}{2D(x)} d x+\\int p^0(x) \\log \\frac{p^0(x)}{2(1-D(x)) \\tilde{p}(x)} d x\\\\ &amp;= \\int\\tilde{p}(x) \\log \\frac{\\tilde{p}(x)+p^0(x)}{2\\tilde{p}(x)}+p^0(x) \\log \\frac{\\tilde{p}(x)+p^0(x)}{2\\tilde{p}(x)}\\\\ &amp;= KL(\\tilde{p}(x) +p^0(x)||2\\tilde{p}(x) ) \\end{aligned} KL(q(x,y)∥p0(x,y))​=∫p~​(x)log2D(x)1​dx+∫p0(x)log2(1−D(x))p~​(x)p0(x)​dx=∫p~​(x)log2p~​(x)p~​(x)+p0(x)​+p0(x)log2p~​(x)p~​(x)+p0(x)​=KL(p~​(x)+p0(x)∣∣2p~​(x))​ 在优化判别器时，p0(x)p^0(x)p0(x)应该为上一阶段生成器优化的p(x)p(x)p(x) 。将这个D(x)D(x)D(x)代入生成器的相关loss： G=arg⁡min⁡G∫p(x)log⁡p0p(x)(1−D(x))p~(x)dx=arg⁡min⁡G∫p(x)log⁡p(x)2D(x)p0(x)dx=arg⁡min⁡G[−Ex∼p(x)2D(x)+KL(p(x)∣∣p0(x))]=arg⁡min⁡G[−Ex∼p(x)2D(G(z))+KL(p(x)∣∣p0(x))]\\begin{aligned} G &amp;= \\underset{G}{\\arg \\min } \\int p(x) \\log \\frac{p_0 p(x)}{(1-D(x)) \\tilde{p}(x)} d x\\\\ &amp;= \\underset{G}{\\arg \\min } \\int p(x) \\log \\frac{ p(x)}{2D(x) p^0(x)} d x\\\\ &amp;= \\underset{G}{\\arg \\min }[-E_{x \\sim p(x)}2D(x)+KL(p(x)||p^0(x))]\\\\ &amp;= \\underset{G}{\\arg \\min }[-E_{x \\sim p(x)}2D(G(z))+KL(p(x)||p^0(x))] \\end{aligned} G​=Gargmin​∫p(x)log(1−D(x))p~​(x)p0​p(x)​dx=Gargmin​∫p(x)log2D(x)p0(x)p(x)​dx=Gargmin​[−Ex∼p(x)​2D(x)+KL(p(x)∣∣p0(x))]=Gargmin​[−Ex∼p(x)​2D(G(z))+KL(p(x)∣∣p0(x))]​ 可以看到，此时的第一项−Ex∼p(x)2D(G(z))-E_{x \\sim p(x)}2D(G(z))−Ex∼p(x)​2D(G(z))就是标准的GAN所采用的loss之一。而我们知道，目前标准的GAN生成器的loss都不包含KL(p(x)∣∣p0(x))KL(p(x)||p^0(x))KL(p(x)∣∣p0(x))，这实际上造成了loss的不完备。 第二个loss是在限制要求新的生成器跟旧的生成器生成结果不能差别太大 ，也就是生成器不能剧烈变化。在loss不完备的情况下，假设有一个优化算法总能找到G(z)G(z)G(z)的理论最优解、并且G(z)G(z)G(z)具有无限的拟合能力，那么G(z)G(z)G(z)只需要生成唯一一个使得D(x)D(x)D(x)最大的样本（不管输入的zzz是什么），这就是模型坍缩。模型塌缩的视频(需要梯子)。 然后对第二项进行估算，得到一个可以在实验中使用的正则项： 记po(x)=qθ−Δθ(x),p(x)=qθ(x)p^{o}(x)=q_{\\theta-\\Delta \\theta}(x), \\quad p(x)=q_{\\theta}(x)po(x)=qθ−Δθ​(x),p(x)=qθ​(x)，其中Δθ\\Delta \\thetaΔθ为生成器的参数变化，对qo(x)=qθ−Δθ(x)q^{o}(x)=q_{\\theta-\\Delta \\theta}(x)qo(x)=qθ−Δθ​(x)做泰勒展开，有： qo(x)=qθ−Δθ(x)=qθ(x)−Δθ⋅∇θqθ(x)+O((Δθ)2)q^{o}(x)=q_{\\theta-\\Delta \\theta}(x)=q_{\\theta}(x)-\\Delta \\theta \\cdot \\nabla_{\\theta} q_{\\theta}(x)+O\\left((\\Delta \\theta)^{2}\\right) qo(x)=qθ−Δθ​(x)=qθ​(x)−Δθ⋅∇θ​qθ​(x)+O((Δθ)2) KL(q(x)∥qo(x))≈∫qθ(x)log⁡qθ(x)qθ(x)−Δθ⋅∇θqθ(x)dx=−∫qθ(x)log⁡[1−Δθ⋅∇θqθ(x)qθ(x)]dx≈−∫qθ(x)[−Δθ⋅∇θqθ(x)qθ(x)−(Δθ⋅∇θqθ(x)qθ(x))2]dx=Δθ⋅∇θ∫qθ(x)dx+(Δθ)2⋅∫(∇θqθ(x))22qθ(x)dx=(Δθ)2⋅∫(∇θqθ(x))22qθ(x)dx≈(Δθ⋅c)2\\begin{aligned} K L\\left(q(x) \\| q^{o}(x)\\right) &amp; \\approx \\int q_{\\theta}(x) \\log \\frac{q_{\\theta}(x)}{q_{\\theta}(x)-\\Delta \\theta \\cdot \\nabla_{\\theta} q_{\\theta}(x)} d x \\\\ &amp;=-\\int q_{\\theta}(x) \\log \\left[1-\\frac{\\Delta \\theta \\cdot \\nabla_{\\theta} q_{\\theta}(x)}{q_{\\theta}(x)}\\right] d x \\\\ &amp; \\approx-\\int q_{\\theta}(x)\\left[-\\frac{\\Delta \\theta \\cdot \\nabla_{\\theta} q_{\\theta}(x)}{q_{\\theta}(x)}-\\left(\\frac{\\Delta \\theta \\cdot \\nabla_{\\theta} q_{\\theta}(x)}{q_{\\theta}(x)}\\right)^{2}\\right] d x \\\\ &amp;=\\Delta \\theta \\cdot \\nabla_{\\theta} \\int q_{\\theta}(x) d x+(\\Delta \\theta)^{2} \\cdot \\int \\frac{\\left(\\nabla_{\\theta} q_{\\theta}(x)\\right)^{2}}{2 q_{\\theta}(x)} d x \\\\ &amp;=(\\Delta \\theta)^{2} \\cdot \\int \\frac{\\left(\\nabla_{\\theta} q_{\\theta}(x)\\right)^{2}}{2 q_{\\theta}(x)} d x \\\\ &amp; \\approx(\\Delta \\theta \\cdot c)^{2} \\end{aligned} KL(q(x)∥qo(x))​≈∫qθ​(x)logqθ​(x)−Δθ⋅∇θ​qθ​(x)qθ​(x)​dx=−∫qθ​(x)log[1−qθ​(x)Δθ⋅∇θ​qθ​(x)​]dx≈−∫qθ​(x)[−qθ​(x)Δθ⋅∇θ​qθ​(x)​−(qθ​(x)Δθ⋅∇θ​qθ​(x)​)2]dx=Δθ⋅∇θ​∫qθ​(x)dx+(Δθ)2⋅∫2qθ​(x)(∇θ​qθ​(x))2​dx=(Δθ)2⋅∫2qθ​(x)(∇θ​qθ​(x))2​dx≈(Δθ⋅c)2​ 上式中应用了log⁡(1+x)\\log(1+x)log(1+x)的泰勒展开式以及求导和积分可互换、可积分的假设。上面的粗略估计表明，生成器的参数不能变化太大。而我们用的是基于梯度下降的优化算法，所以Δθ\\Delta \\thetaΔθ正比于梯度，因此标准GAN训练时的很多trick，比如梯度裁剪、用Adam优化器、用BN，都可以解释得通了，它们都是为了稳定梯度，使得Δθ\\Delta \\thetaΔθ不至于过大，同时，G(z)G(z)G(z)的迭代次数也不能过多，因为过多同样会导致Δθ\\Delta \\thetaΔθ过大。 正则项 考虑如何添加正则项以改进GAN的稳定性： 直接对KL(q(x)∥qo(x))K L\\left(q(x) \\| q^{o}(x)\\right)KL(q(x)∥qo(x))进行估算是很困难的，但是我们上面提到q(z∣x)q(z|x)q(z∣x)和qo(z∣x)q^o(z|x)qo(z∣x)是狄拉克分布，而狄拉克分布可以看作方差为0的高斯分布，于是考虑用KL(q(x,z)∥qo(x,z))K L\\left(q(x,z) \\| q^{o}(x,z)\\right)KL(q(x,z)∥qo(x,z))进行估算： KL(q(x,z)∥q~(x,z))=∬q(x∣z)q(z)log⁡q(x∣z)q(z)q~(x∣z)q(z)dxdz=∬δ(x−G(z))q(z)log⁡δ(x−G(z))δ(x−Go(z))dxdz=∫q(z)log⁡δ(0)δ(G(z)−Go(z))dz\\begin{aligned} K L(q(x, z) \\| \\tilde{q}(x, z)) &amp;=\\iint q(x | z) q(z) \\log \\frac{q(x | z) q(z)}{\\tilde{q}(x | z) q(z)} d x d z \\\\ &amp;=\\iint \\delta(x-G(z)) q(z) \\log \\frac{\\delta(x-G(z))}{\\delta\\left(x-G^{o}(z)\\right)} d x d z \\\\ &amp;=\\int q(z) \\log \\frac{\\delta(0)}{\\delta\\left(G(z)-G^{o}(z)\\right)} d z \\end{aligned} KL(q(x,z)∥q~​(x,z))​=∬q(x∣z)q(z)logq~​(x∣z)q(z)q(x∣z)q(z)​dxdz=∬δ(x−G(z))q(z)logδ(x−Go(z))δ(x−G(z))​dxdz=∫q(z)logδ(G(z)−Go(z))δ(0)​dz​ 将狄拉克分布可以看作方差为0的高斯分布,并代入： δ(x)=lim⁡σ→01(2πσ2)d/2exp⁡(−x22σ2)\\delta(x)=\\lim _{\\sigma \\rightarrow 0} \\frac{1}{\\left(2 \\pi \\sigma^{2}\\right)^{d / 2}} \\exp \\left(-\\frac{x^{2}}{2 \\sigma^{2}}\\right) δ(x)=σ→0lim​(2πσ2)d/21​exp(−2σ2x2​) KL(q(x,z)∥q~(x,z))=∫q(z)log⁡δ(0)δ(G(z)−Go(z))dz=lim⁡σ→0∫q(x)log⁡[1/exp⁡(−(G(z)−G0(z))22σ2)]dx=lim⁡σ→0∫q(x)(−(G(z)−G0(z))22σ2)dx∼λ∫q(z)∥G(z)−Go(z)∥2dz\\begin{aligned} K L(q(x, z) \\| \\tilde{q}(x, z)) &amp;=\\int q(z) \\log \\frac{\\delta(0)}{\\delta\\left(G(z)-G^{o}(z)\\right)} d z \\\\ &amp;= \\lim _{\\sigma \\rightarrow 0} \\int q(x) \\log \\left[ 1/{\\exp \\left(-\\frac{(G(z)-G^0(z))^{2}}{2 \\sigma^{2}}\\right)} \\right]dx \\\\ &amp;= \\lim _{\\sigma \\rightarrow 0} \\int q(x) \\left(-\\frac{(G(z)-G^0(z))^{2}}{2 \\sigma^{2}}\\right)dx \\\\ &amp; \\sim \\lambda \\int q(z)\\left\\|G(z)-G^{o}(z)\\right\\|^{2} d z \\end{aligned} KL(q(x,z)∥q~​(x,z))​=∫q(z)logδ(G(z)−Go(z))δ(0)​dz=σ→0lim​∫q(x)log[1/exp(−2σ2(G(z)−G0(z))2​)]dx=σ→0lim​∫q(x)(−2σ2(G(z)−G0(z))2​)dx∼λ∫q(z)∥G(z)−Go(z)∥2dz​ 于是有 KL(q(x)∥qo(x))∼λ∫q(z)∥G(z)−Go(z)∥2dzK L\\left(q(x) \\| q^{o}(x)\\right) \\sim \\lambda \\int q(z)\\left\\|G(z)-G^{o}(z)\\right\\|^{2} d z KL(q(x)∥qo(x))∼λ∫q(z)∥G(z)−Go(z)∥2dz 从而完整的生成器loss可以选择为 Ez∼q(z)[−log⁡D(G(z))+λ∥G(z)−Go(z)∥2]\\mathbb{E}_{z \\sim q(z)}\\left[-\\log D(G(z))+\\lambda\\left\\|G(z)-G^{o}(z)\\right\\|^{2}\\right] Ez∼q(z)​[−logD(G(z))+λ∥G(z)−Go(z)∥2] 实验结果 FLOW 基本思路：直接硬算积分式 ∫zp(x∣z)p(z)dz\\int_{z} p(x | z) p(z) d z ∫z​p(x∣z)p(z)dz 流模型有一个非常与众不同的特点是，它的转换通常是可逆的。也就是说，流模型不 仅能找到从 A 分布变化到 B 分布的网络通路，并且该通路也能让 B 变化到 A，简言之流模 型找到的是一条 A、B 分布间的双工通路。当然，这样的可逆性是具有代价的——A、B 的 数据维度必须是一致的。 A、B 分布间的转换并不是轻易能做到的，流模型为实现这一点经历了三个步骤：最初 的 NICE 实现了从 A 分布到高斯分布的可逆求解；后来 RealNVP 实现了从 A 分布到条件非 高斯分布的可逆求解；而最新的 GLOW，实现了从 A 分布到 B 分布的可逆求解，其中 B 分 布可以是与 A 分布同样复杂的分布，这意味着给定两堆图片，GLOW 能够实现这两堆图片 间的任意转换。 NICE 两个一维分布之间的转化参考前言中的栗子，下面考虑高维分布： 类似一维分布，两个分布在映射前后的相同区域应该有相同的概率。 p(x′)∣det⁡(Jf)∣=π(z′)p\\left(x^{\\prime}\\right)\\left|\\operatorname{det}\\left(J_{f}\\right)\\right|=\\pi\\left(z^{\\prime}\\right) p(x′)∣det(Jf​)∣=π(z′) 其中JfJ_fJf​为雅可比行列式，函数fff将zzz上的分布变换到xxx上的分布。 根据雅可比行列式的逆运算，同样有： p(x′)=π(z′)∣det⁡(Jf−1)∣p\\left(x^{\\prime}\\right)=\\pi\\left(z^{\\prime}\\right)\\left|\\operatorname{det}\\left(J_{f^{-1}}\\right)\\right| p(x′)=π(z′)∣∣​det(Jf−1​)∣∣​ 至此，我们得到了一个比较重要的结论：如果 zzz 与 xxx 分别满足两种分布，并且 zzz 通过 函数 fff 能够转变为 xxx，那么 zzz 与 xxx 中的任意一组对应采样点 𝑧′𝑧′z′ 与 𝑥′𝑥′x′ 之间的关系为： {π(z′)=p(x′)∣det⁡(Jf)∣p(x′)=π(z′)∣det⁡(Jf−1)∣\\left\\{\\begin{array}{c} {\\pi\\left(z^{\\prime}\\right)=p\\left(x^{\\prime}\\right)\\left|\\operatorname{det}\\left(J_{f}\\right)\\right|} \\\\ {p\\left(x^{\\prime}\\right)=\\pi\\left(z^{\\prime}\\right)\\left|\\operatorname{det}\\left(J_{f^{-1}}\\right)\\right|} \\end{array}\\right. {π(z′)=p(x′)∣det(Jf​)∣p(x′)=π(z′)∣∣​det(Jf−1​)∣∣​​ 从这个公式引入了Flow_based_model 的基本思路：设计一个神经网络，将分布 xxx 映射到分布 zzz ，具体来说，流模型选择 q(z)q(z)q(z) 为高斯分布，q(x∣z)q(x|z)q(x∣z) 为狄拉克分布 δ(x−g(z)\\delta(x-g(z)δ(x−g(z) ，其中ggg 是可逆的： x=g(z)⇔z=f(x)x=g(z) \\Leftrightarrow z=f(x) x=g(z)⇔z=f(x) 要从理论上实现可逆，需要 xxx 和 zzz 的维数相同，将 zzz 的分布代入，则有： q(z)=1(2π)D/2exp⁡(−12∥z∥2)q(z)=\\frac{1}{(2 \\pi)^{D / 2}} \\exp \\left(-\\frac{1}{2}\\|z\\|^{2}\\right) q(z)=(2π)D/21​exp(−21​∥z∥2) q(x)=1(2π)D/2exp⁡(−12∥f(x)∥2)∣det⁡[∂f∂x]∣(2)q(\\boldsymbol{x})=\\frac{1}{(2 \\pi)^{D / 2}} \\exp \\left(-\\frac{1}{2}\\|\\boldsymbol{f}(\\boldsymbol{x})\\|^{2}\\right)\\left|\\operatorname{det}\\left[\\frac{\\partial \\boldsymbol{f}}{\\partial \\boldsymbol{x}}\\right]\\right|\\tag{2} q(x)=(2π)D/21​exp(−21​∥f(x)∥2)∣∣∣∣​det[∂x∂f​]∣∣∣∣​(2) 公式(2)(2)(2)对 fff 提出了三个基本要求： 可逆，且逆函数容易计算。 对应的雅可比行列式方便计算 拟合能力强 这样的话，就有 log⁡q(x)=−D2log⁡(2π)−12∥f(x)∥2+log⁡∣det⁡[∂f∂x]∣\\log q(x)=-\\frac{D}{2} \\log (2 \\pi)-\\frac{1}{2}\\|f(x)\\|^{2}+\\log \\left|\\operatorname{det}\\left[\\frac{\\partial f}{\\partial x}\\right]\\right| logq(x)=−2D​log(2π)−21​∥f(x)∥2+log∣∣∣∣​det[∂x∂f​]∣∣∣∣​ 这个优化目标是可计算的，并且因为 fff 可逆，那么我们在zzz 中取样，就可以生成相应的 xxx x=f−1(z)=g(z)x=f^{-1}(z)=g(z) x=f−1(z)=g(z) 为了满足这三个条件，NICE和REAL NVP、GLOW都采用了模块化思想，将 fff 设计成一组函数的复合，其中每个函数都满足要求一和要求二，经过复合之后函数也容易满足要求三。 f=fL∘…∘f2∘f1f=f_{L} \\circ \\ldots \\circ f_{2} \\circ f_{1} f=fL​∘…∘f2​∘f1​ 相对而言，雅可比行列式的计算要比函数求逆更加复杂，考虑第二个要求，我们知道三角行列式最容易计算，所以我们要想办法让变换 fff 的雅可比矩阵为三角阵。NICE的做法是：将 DDD 的 xxx 分为两部分 x1,x2x_1,x_2x1​,x2​，然后取下述变换： h1=x1h2=x2+m(x1)\\begin{array}{l} {\\boldsymbol{h}_{1}=\\boldsymbol{x}_{1}} \\\\ {\\boldsymbol{h}_{2}=\\boldsymbol{x}_{2}+\\boldsymbol{m}\\left(\\boldsymbol{x}_{1}\\right)} \\end{array} h1​=x1​h2​=x2​+m(x1​)​ 其中 mmm 为任意函数，这个变换称为“加性耦合层” ，这个变换的雅可比矩阵 [∂h∂x][\\frac{\\partial h}{\\partial x}][∂x∂h​] 是一个三角阵，且对角线元素全部为1，用分块矩阵表示为： [∂h∂x]=(IdO∂m∂x1ID−d)\\left[\\frac{\\partial \\boldsymbol{h}}{\\partial \\boldsymbol{x}}\\right]=\\left(\\begin{array}{cc} {\\mathrm{I}_{d}} &amp; {\\mathrm{O}} \\\\ \\frac{\\partial m}{\\partial x_1} &amp; I_{D-d} \\end{array}\\right) [∂x∂h​]=(Id​∂x1​∂m​​OID−d​​) 同时这个变换也是可逆的，其逆变换为 x1=xhx2=h2−m(h1)\\begin{array}{l} {\\boldsymbol{x}_{1}=\\boldsymbol{x}_{h}} \\\\ {\\boldsymbol{x}_{2}=\\boldsymbol{h}_{2}-\\boldsymbol{m}\\left(\\boldsymbol{h}_{1}\\right)} \\end{array} x1​=xh​x2​=h2​−m(h1​)​ 满足了要求一和要求二，同时这个雅可比行列式的值为1，行列式的值的物理含义是体积，所以这个变换暗含了变换前后的体积不变性。我们注意到：该变换的第一部分是平凡的（恒等变换），因此需要对调I1和I2两组维度，再输入加和耦合层，并将这个过程重复若干次， 以达到信息充分混合的目的，如图： 因为该变换需要满足 zzz 和 xxx 的维度相同，这会产生很严重的唯独浪费问题，NICE在最后一层里引入了一个尺度变换对维度进行缩放： z=s⊗h(n)z=s \\otimes h^{(n)} z=s⊗h(n) 其中s=(s1,s2,...,sD)s=(s_1,s_2,...,s_D)s=(s1​,s2​,...,sD​)也是一个要优化的参数向量，这个 sss 向量能够识别每个维度的重要程度， sss 越小，这个维度越不重要，起到压缩流形的作用。这个尺度变换层的雅可比行列式就不是一了，而是： [∂z∂h(n)]=diag⁡(s)\\left[\\frac{\\partial z}{\\partial \\boldsymbol{h}^{(n)}}\\right]=\\operatorname{diag}(\\boldsymbol{s}) [∂h(n)∂z​]=diag(s) 他的行列式的值为 ∏isi\\prod_{i} s_{i}∏i​si​,于是最后的对数似然为： log⁡q(x)∼−12∥s⊗f(x)∥2+∑ilog⁡si\\log q(\\boldsymbol{x}) \\sim-\\frac{1}{2}\\|\\boldsymbol{s} \\otimes \\boldsymbol{f}(\\boldsymbol{x})\\|^{2}+\\sum_{i} \\log \\boldsymbol{s}_{i} logq(x)∼−21​∥s⊗f(x)∥2+i∑​logsi​ 这个尺度变换实际上是将先验分布 q(z)q(z)q(z) 的方差也作为训练参数，方差越小，说明这个维度的“弥散”越小，若方差为0，这一维的特征就恒为均值，于是流行减小一维。 我们写出带方差的正态分布： q(z)=1(2π)D/2∏i=1Dσiexp⁡(−12∑i=1Dzi2σi2)q(z)=\\frac{1}{(2 \\pi)^{D / 2} \\prod_{i=1}^{D} \\sigma_{i}} \\exp \\left(-\\frac{1}{2} \\sum_{i=1}^{D} \\frac{z_{i}^{2}}{\\sigma_{i}^{2}}\\right) q(z)=(2π)D/2∏i=1D​σi​1​exp(−21​i=1∑D​σi2​zi2​​) 将 z=f(x)z=f(x)z=f(x) 代入，并取对数，类似得： log⁡q(x)∼−12∑i=1Dfi2(x)σi2−∑i=1Dlog⁡σi\\log q(\\boldsymbol{x}) \\sim-\\frac{1}{2} \\sum_{i=1}^{D} \\frac{\\boldsymbol{f}_{i}^{2}(\\boldsymbol{x})}{\\boldsymbol{\\sigma}_{i}^{2}}-\\sum_{i=1}^{D} \\log \\boldsymbol{\\sigma}_{i} logq(x)∼−21​i=1∑D​σi2​fi2​(x)​−i=1∑D​logσi​ 与之前那个公式对比，就有 si=1/σis_i=1/\\sigma_isi​=1/σi​ ，所以尺度变换层等价于将先验分布的方差作为训练参数，若方差足够小，则维度减一，暗含了降维的可能。 REALNVP NICE构思巧妙，但在实验部分只是采取了简单的加性耦合层和将全连接层进行简单的堆叠，并没有使用卷积。REALNVP一般化了耦合层，并在耦合模型中引入了卷积层，使得模型可以更好地处理图像问题。论文里还引入了一个多尺度结构来处理维度浪费问题。 将加性耦合层换成仿射耦合层： h1=x1h2=s(x1)⊗x2+t(x1)(x1)\\begin{array}{l} {\\boldsymbol{h}_{1}=\\boldsymbol{x}_{1}} \\\\ {\\boldsymbol{h}_{2}=\\boldsymbol{s}\\left(\\boldsymbol{x}_{1}\\right) \\otimes \\boldsymbol{x}_{2}+t\\left(\\boldsymbol{x}_{1}\\right)\\left(\\boldsymbol{x}_{1}\\right)} \\end{array} h1​=x1​h2​=s(x1​)⊗x2​+t(x1​)(x1​)​ 仿射耦合层的雅可比行列式仍然是一个对角阵 [∂h∂x]=(IdO[∂m∂x1]s)\\left[\\frac{\\partial \\boldsymbol{h}}{\\partial \\boldsymbol{x}}\\right]=\\left(\\begin{array}{cc} {\\mathbb{I}_{d}} &amp; {\\mathbb{O}} \\\\ {\\left[\\frac{\\partial m}{\\partial x_{1}}\\right]} &amp; {s} \\end{array}\\right) [∂x∂h​]=(Id​[∂x1​∂m​]​Os​) 雅可比行列式的值不再是1，没有保持变换前后的体积不变。 在NICE中，通过交错的方式来混合信息流(直接反转原来的向量)，在REALNVP中发现：随机打乱维度可以使信息混合的更加充分。 引入卷积层：使用卷积的条件是具有局部相关性，因此指定向量的打乱和重排都是在channel维度上进行，在height和width维度上进行卷积。对通道的分割论文里还提出棋盘式分割的策略，但较为复杂，对模型的提升也不大，因此在GLOW中被舍弃了。 一般的图像通道数只有三层，MNIST等灰度图只有一层，因此REALNVP引入了squeeze操作来增加通道数。 其思想很简单：直接 reshape，但 reshape 时局部地进行。具体来说，假设原来图像为 h×w×c 大小，前两个轴是空间维度，然后沿着空间维度分为一个个 2×2×c 的块（ 2 可以自定义），然后将每个块直接 reshape 为 1×1×4c，最后变成了 h/2×w/2×4c。 REALNVP中还引入了一个多尺度结构： 最终的输出 z1,z3,z5z_1,z_3,z_5z1​,z3​,z5​ 怎么取？ p(z1,z3,z5)=p(z1∣z3,z5)p(z3∣z5)p(z5)p\\left(z_{1}, z_{3}, z_{5}\\right)=p\\left(z_{1} | z_{3}, z_{5}\\right) p\\left(z_{3} | z_{5}\\right) p\\left(z_{5}\\right) p(z1​,z3​,z5​)=p(z1​∣z3​,z5​)p(z3​∣z5​)p(z5​) 由于 z3,z5z_3,z_5z3​,z5​ 是由 z2z_2z2​ 完全决定的，z5z_5z5​ 也是由 z4z_4z4​ 完全决定的，因此条件部分可以改为： p(z1,z3,z5)=p(z1∣z2)p(z3∣z4)p(z5)p\\left(z_{1}, z_{3}, z_{5}\\right)=p\\left(z_{1} | z_{2}\\right) p\\left(z_{3} | z_{4}\\right) p\\left(z_{5}\\right) p(z1​,z3​,z5​)=p(z1​∣z2​)p(z3​∣z4​)p(z5​) RealNVP 和 Glow 假设右端三个概率分布都是正态分布，类似VAE， p(z1∣z2)p(z_1|z_2)p(z1​∣z2​) 的均值方差由 z2z_2z2​ 算出来，p(z3∣z4)p(z_3|z_4)p(z3​∣z4​) 的均值方差由 z4z_4z4​ 算出来，p(z5)p(z_5)p(z5​) 的均值方差直接学习出来。这相当于做了变量代换： z^1=z1−μ(z2)σ(z2),z^3=z3−μ(z4)σ(z4),z^5=z5−μσ\\hat{z}_{1}=\\frac{z_{1}-\\mu\\left(z_{2}\\right)}{\\sigma\\left(z_{2}\\right)}, \\quad \\hat{z}_{3}=\\frac{z_{3}-\\mu\\left(z_{4}\\right)}{\\sigma\\left(z_{4}\\right)}, \\quad \\hat{z}_{5}=\\frac{z_{5}-\\mu}{\\sigma} z^1​=σ(z2​)z1​−μ(z2​)​,z^3​=σ(z4​)z3​−μ(z4​)​,z^5​=σz5​−μ​ 然后认为 [z^1,z^3,z^5][\\hat{z}_1,\\hat{z}_3,\\hat{z}_5][z^1​,z^3​,z^5​]服从标准正态分布。类似NICE，这三个变换会导致一个非1的雅可比行列式，也就是往loss中加入 Σi=1Dlog⁡σi\\Sigma_{i=1}^{D} \\log \\sigma_{i}Σi=1D​logσi​ 这一项。 多尺度结构相当于抛弃了 p(z)p(z)p(z) 是标准正态分布的直接假设，而采用了一个组合式的条件分布，这样尽管输入输出的总维度依然一样，但是不同层次的输出地位已经不对等了，模型可以通过控制每个条件分布的方差来抑制维度浪费问题（极端情况下，方差为 0，那么高斯分布坍缩为狄拉克分布，维度就降低 1），条件分布相比于独立分布具有更大的灵活性。而如果单纯从 loss 的角度看，多尺度结构为模型提供了一个强有力的正则项。 GLOW 效果好的令人惊叹的生成模型： 改变图像属性 采样展示 潜在空间的插值 总体来说，GLOW引入1*1可逆卷积来代替通道维度的打乱和重排操作，并对 REALNVP 的原始模型做了简化和规范。 向量之间的元素置换操作可以用简单的行变换矩阵来操作： (badc)=(0100100000010010)(abcd)\\left(\\begin{array}{l} {b} \\\\ {a} \\\\ {d} \\\\ {c} \\end{array}\\right)=\\left(\\begin{array}{llll} {0} &amp; {1} &amp; {0} &amp; {0} \\\\ {1} &amp; {0} &amp; {0} &amp; {0} \\\\ {0} &amp; {0} &amp; {0} &amp; {1} \\\\ {0} &amp; {0} &amp; {1} &amp; {0} \\end{array}\\right)\\left(\\begin{array}{l} {a} \\\\ {b} \\\\ {c} \\\\ {d} \\end{array}\\right) ⎝⎜⎜⎛​badc​⎠⎟⎟⎞​=⎝⎜⎜⎛​0100​1000​0001​0010​⎠⎟⎟⎞​⎝⎜⎜⎛​abcd​⎠⎟⎟⎞​ GLOW中用一个更一般的矩阵 WWW 来代替这个置换矩阵 h=xWh=xW h=xW 这个变换的雅可比矩阵就是det(W)det(W)det(W)，因此需要将 −log∣det(W)∣-log|det(W)|−log∣det(W)∣ 加入到loss中，WWW 的初始选择要求可逆，不引入loss，因此选为随即正交阵。 这个变换引入了 det(W)det(W)det(W) 的计算问题，GLOW中逆用LU分解克服了这个问题，若 W=PLUW=PLUW=PLU (其中P是一个置换矩阵),则 log⁡∣det⁡W∣=∑log⁡∣diag⁡(U)∣\\log |\\operatorname{det} W|=\\sum \\log |\\operatorname{diag}(U)| log∣detW∣=∑log∣diag(U)∣ 这就是GLOW中给出的技巧：先随机生成一个正交矩阵，然后做 LULULU 分解，得到 P,L,UP,L,UP,L,U，固定 P，也固定 U 的对角线的正负号，然后约束 L 为对角线全 1 的下三角阵，U 为上三角阵，优化训练 L,U 的其余参数。 也可以理解为：在NICE和REALNVP中都是通过交换、打乱、重排等操作混合各个通道的信息，但通道信息的混合可直接通过1*1卷积实现。 整个GLOW模型如下： 对比 比较反转、打乱和1*1逆卷积的loss： 缺点 模型庞大，参数量极大，NICE模型在MNIST数据集上的训练参数就大概有两千万个。 再贴两个Glow模型在Gayhub Github上的issue感受下： 256*256的高清人脸生成，用一块GPU训练的话，大概要一年…… 一图对比GAN，VAE和FLOW 参考文献 Variational Inference: A Unified Framework of Generative Models and Some Revelations Tutorial on Variational Autoencoders 用变分推断统一理解生成模型（VAE、GAN、AAE、ALI） NICE: Non-linear Independent Components Estimation NOTE_FLOW Glow: Generative Flow with Invertible 1×1 Convolutions 细水长flow之NICE：流模型的基本概念与实现 RealNVP与Glow：流模型的传承与升华 Density estimation using Real NVP","categories":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}],"tags":[{"name":"gan","slug":"gan","permalink":"/tags/gan/"},{"name":"vae","slug":"vae","permalink":"/tags/vae/"},{"name":"flow","slug":"flow","permalink":"/tags/flow/"}],"keywords":[{"name":"学习","slug":"学习","permalink":"/categories/学习/"}]},{"title":"shell脚本","slug":"shell脚本","date":"2020-02-10T05:32:00.000Z","updated":"2020-03-15T04:34:47.342Z","comments":true,"path":"2020/02/10/shell脚本/","link":"","permalink":"/2020/02/10/shell脚本/","excerpt":"","text":"# 指定解释器 #！/bin/bash # 向窗口输出文本 echo \"Hello world!\" printf \"Hello world!\" # for循环示例,使用变量要加$符号 for file in `ls /etc` do echo \"${file}\" done # 双引号和单引号 # 双引号中可以有变量，单引号中的变量是无效的 # if-else语句 if condition1 then command1 elif condition2 then commed2 else command3 fi","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"shell","slug":"shell","permalink":"/tags/shell/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"emacs基本操作","slug":"Emacs笔记","date":"2020-02-10T03:16:00.000Z","updated":"2020-03-15T04:18:17.714Z","comments":true,"path":"2020/02/10/Emacs笔记/","link":"","permalink":"/2020/02/10/Emacs笔记/","excerpt":"","text":"Emacs基本操作 C = Ctrl, M = Alt 光标移动 C-v 向下翻页 M-v 向上翻页 C-b 向左(back) C-f 向右(forward) C-n 向下(next) C-p 向上(previous) M-b 上一个单词 M-f 下一个单词 C-a 行首 C-e 行尾 M-a 句首 M-e 句尾 M-&lt; 文件头 M-&gt; 文件尾 M-g g 跳到某一行 选择区域 C-@ 标记 删除剪切复制粘贴 C-d 向后删除(delele) C-k 删掉光标后至行尾 M-w 复制区域 C-w 剪切/删除区域 C-y 粘贴 M-y 滚动选择粘贴内容 查找替换 C-s 向前查找 C-s C-r 向后查找 M-% 替换 文件操作 C-x C-f 打开文件(find) C-x C-s 保存文件(save) C-x C-w 另存为(write) C-k 关闭文件 窗口操作 C-x b 切换文件 C-x 1 关闭其它窗口 C-x 2/C-x 3 打开其它窗口 C-x o 跳到另一个窗口(other) 其它 C-/ 撤销 M-$ 拼写检查 M-x 输入命令 C-g 取消命令","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"emacs","slug":"emacs","permalink":"/tags/emacs/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"科学上网","slug":"科学上网","date":"2020-02-09T03:19:00.000Z","updated":"2020-09-12T10:46:07.846Z","comments":true,"path":"2020/02/09/科学上网/","link":"","permalink":"/2020/02/09/科学上网/","excerpt":"","text":"插件篇 如果只是想访问谷歌服务，可以直接在谷歌浏览器里安装谷歌上网助手插件。 这个插件只能访问谷歌旗下网站，YouTube等不能访问。 还有一个不错的谷歌浏览器插件VeePN，也能实现科学上网 机场篇 机场很多……随便推荐几个(不一定还能用) 免费机场 付费机场 付费的速度会比免费机场快，而且解锁奈非等 VPS篇 喜欢自己折腾的可以看，需要有VPS，以我的为例: ssh进行端口动态转发 # 本地1080端口和服务器动态转发，可添加参数-v打印一些数据流 $ ssh -D 1080 root@66.152.179.100 # 查看端口是否打开 $ netstat -nat ssh -D容易把VPS IP弄没……可以临时使用，长期使用换v2ray V2ray 在服务器端安装V2ray: 可以用一键脚本安装： bash &lt;(curl -s -L https://git.io/v2ray.sh) 也可以用Docker安装： 1.配置Docker环境： $ apt-get update $ apt-get -y install ca-certificates wget $ curl -sSL https://get.docker.com/ | sh 2.配置Portainer管理界面： $ docker run -d -p 9000:9000 --label owner=portainer \\ --restart=always --name=ui \\ --label owner=portainer \\ -v /var/run/docker.sock:/var/run/docker.sock \\ lihaixin/portainer -l owner=portainer 3.配置加速服务： $ wget https://github.com/chiakge/Linux-NetSpeed/raw/master/tcp.sh $ chmod +x tcp.sh $ ./tcp.sh 4.登入Web管理界面&lt;ip&gt;:9000 创建V2ray模板并启用 进入容器logs日志查看VMESS，复制下来，接下来会用 客户端使用V2ray： 下载对应客户端: Windows:·v2rayN Mac:v2rayU Linux:v2rayL 上面复制了vmess，然后点击v2ray客户端——&gt;从剪贴板批量导入URL 配置浏览器代理设置 在浏览器中安装Proxy SwitchyOmega扩展，新建PAC情景模式，在PAC网址中粘贴https://raw.githubusercontent.com/breakwa11/gfw_whitelist/master/proxy.pac 立即更新，应用更改。 或者新建情景模式——&gt;代理服务器——&gt;协议选择Socks5，代理服务器填127.0.0.1，代理端口为ssr或者V2ray的本地代理端口，一般默认为1080 浏览器切换到代理模式后，正常访问外网。 注意事项 谷歌上网助手和我的V2ray配置文件都选用了本地1080端口进行监听，在浏览器中同时开启Pro SwitchyOmega插件和谷歌上网助手插件可能会发生端口冲突。 解决方案:两个插件不要同时开，或者修改v2ray配置文件的本地端口。","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"实验室","slug":"实验室","permalink":"/tags/实验室/"},{"name":"服务器","slug":"服务器","permalink":"/tags/服务器/"},{"name":"科学上网","slug":"科学上网","permalink":"/tags/科学上网/"},{"name":"翻墙","slug":"翻墙","permalink":"/tags/翻墙/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"服务器使用tensorboard和visdom","slug":"服务器使用tensorboard和visdom","date":"2020-01-28T03:27:21.351Z","updated":"2020-03-15T04:36:53.050Z","comments":true,"path":"2020/01/28/服务器使用tensorboard和visdom/","link":"","permalink":"/2020/01/28/服务器使用tensorboard和visdom/","excerpt":"","text":"服务器使用tensorboard和visdom 以tensorboard为例： 创建容器时开放6006端口 # 运行容器时将服务器docker容器的6006端口暴漏到自己主机ip下的16006端口(可自己指定) $ docker run -p &lt;ip&gt;:16006:6006 -it -v /data:/workspace/data --runtime=nvidia --net=host --name=temp /bin/bash 或者 # 在连接ssh时，将docker容器中的6006端口重新定向到自己机器上 $ ssh -p 1001 -L 16006:&lt;ip&gt;:6006 root@10.7.60.40","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"实验室","slug":"实验室","permalink":"/tags/实验室/"},{"name":"服务器","slug":"服务器","permalink":"/tags/服务器/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"服务器使用教程","slug":"服务器使用说明","date":"2020-01-24T03:38:00.000Z","updated":"2020-09-12T11:35:21.066Z","comments":true,"path":"2020/01/24/服务器使用说明/","link":"","permalink":"/2020/01/24/服务器使用说明/","excerpt":"The article has been encrypted, please enter your password to view.","text":"Please enter the password to read the blog. Incorrect Password! No content to display! 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","categories":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}],"tags":[{"name":"服务器","slug":"服务器","permalink":"/tags/服务器/"}],"keywords":[{"name":"实验室","slug":"实验室","permalink":"/categories/实验室/"}]},{"title":"docker基本使用","slug":"docker使用","date":"2020-01-19T12:48:00.000Z","updated":"2020-09-12T11:01:33.726Z","comments":true,"path":"2020/01/19/docker使用/","link":"","permalink":"/2020/01/19/docker使用/","excerpt":"","text":"Docker基本使用 docker和nvidia-docker 安装 略 安装后查看安装信息和测试docker是否安装正确 $ sudo docker --version $ sudo docker run hello-world # 验证nvidia-docker $ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi docker hub 链接:dockerhub 在dockerhub上搜索自己需要的镜像 选择自己要用的镜像，点进去，点Tags会出现不同的版本 复制命令，在终端中执行，就可以将镜像下载到本地 docker基本命令 # 查看主机下有多少镜像 $ sudo docker images # 删除镜像 $ sudo docker rmi &lt;image_id&gt; # 查看主机下的容器,不加-a表示查看运行中的容器 $ sudo docker ps -a # 启动、重启和停止容器 $ sudo docker start/restart/stop &lt;container_id&gt; # 进入容器 $ sudo docker attach &lt;container_id&gt; # 删除容器(需要先停止容器) $ sudo docker rm &lt;container_id&gt; ctrl+d退出并停止容器，ctrl+p+q退出但不停止容器 根据镜像新建并启动容器 $ sudo docker run -it [options] &lt;image_id&gt; bash 说明：-it为为容器分配一个输入终端，以交互式模式运行,bash为调用镜像里的bash 可选选项： --name 为容器指定名字 -p 端口映射 -v 给容器挂载存储卷 --net 指定容器网络 --runtime=nvidia 可调用gpu 例如： $ sudo docker run -it -p 8022:22 --name=tensorflow --runtime=nvidia -v /home/yu/code:/home --net=host ufoym/deepo bash 删除所有镜像和容器 $ sudo docker rmi `sudo docker images -q` $ sudo docker rm `sudo docker ps -a -q` 导出容器和保存加载镜像 容器导出为镜像 # 容器导出为镜像 $ docker commit &lt;continer_name&gt; &lt;image_name&gt; # 镜像导出为文件 $ docker save image_name&gt; /dir/name.tar # 文件导入为镜像 $ docker load &lt; /dir/filename docker和宿主机的文件拷贝 $ docker cp &lt;container_name&gt;:/dir/filename /hostdir/ $ docker cp /hostdir/filename &lt;container_name&gt;:/dir 不管容器有没有启动，拷贝命令都会生效","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"docker","slug":"docker","permalink":"/tags/docker/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"OpenPAI安装记录","slug":"OpenPai安装记录","date":"2020-01-16T02:48:00.000Z","updated":"2020-03-15T04:33:53.506Z","comments":true,"path":"2020/01/16/OpenPai安装记录/","link":"","permalink":"/2020/01/16/OpenPai安装记录/","excerpt":"","text":"OpenPAI安装记录 环境准备 一台master主机和多台worker主机，一台维护机 所有节点不要安装CUDA驱动，具有统一的登录账户和密码 开启ssh功能和ntp功能(互相访问，时间同步) 部署过程 安装docker-ce $ sudo apt-get -y install docker.io $ sudo docker pull docker.io/openpai/dev-box:v0.14.0 运行dev-box $ sudo docker run -itd \\ -e COLUMNS=$COLUMNS -e LINES=$LINES -e TERM=$TERM \\ -v /var/run/docker.sock:/var/run/docker.sock \\ -v /pathConfiguration:/cluster-configuration \\ -v /hadoop-binary:/hadoop-binary \\ --pid=host \\ --privileged=true \\ --net=host \\ --name=dev-box \\ docker.io/openpai/dev-box:v0.14.0 登录dev-box $ sudo docker exec -it dev-box /bin/bash $ cd /pai/deployment/quick-start/ 修改配置信息 $ cp quick-start-example.yaml quick-start.yaml $ vim quick-start.yaml 修改内容： machines: - &lt;ip-of-master&gt; - &lt;ip-of-worker1&gt; - &lt;ip-of-worder2&gt; ssh-username: &lt;username&gt; ssh-password: &lt;password&gt; 生成OepnPai配置文件 $ cd /pai $ python paictl.py config generate -i /pai/deployment/quick-start/quick-start.yaml -o ~/pai-config -f $ cd ~/pai-config/ 修改kubernetes-configuration.yaml 将docker-registry替换为国内镜像库 docker-registry: docker.io/mirrorgooglecontainers 修改layout.yaml 修改自己机器的配置信息 machine-sku: GENERIC: mem: 256G gpu: type: TITAN V count: 1 cpu: vcore: 4 os: ubuntu16.04 Worker1: mem: 256G gpu: type: GeForce RTX 2080Ti count: 4 cpu: vcore: 4 os: ubuntu16.04 Worker2: mem: 256G gpu: type: GeForce RTX 2080Ti count: 4 cpu: vcore: 4 os: ubuntu16.04 修改services-configuration.yaml 解除common和data-path两个字段的注释，将data-path赋值到真实位置，作为服务数据存储路径 cluster: common: # cluster-id: pai-example # # # HDFS, zookeeper data path on your cluster machine. data-path: \"/data\" tag字段修改为真实版本 v014.0 可修改cluster-id,后面会用到 修改rest-server下的用户名和密码，作为登录平台的账户密码 指定显卡驱动版本，不指定的话默认安装384.11，这个驱动是不支持图灵核心显卡的，安装到后面会出现’nvidia-drm’ not found 错误，驱动版本只能从注释里的版本选择 drivers: set-nvidia-runtime: false # You can set drivers version here. If this value is miss, default value will be 384.111 # Current supported version list # 384.111 # 390.25 # 410.73 version: \"410.73\" 部署Kubernetes http::9090查看进度 $ cd /pai $ python paictl.py cluster k8s-bootup -p ~/pai-config 更改配置文件到kubernetes $ cd /pai python paictl.py config push -p ~/pai-config/ -c ~/.kube/config 若报错，卸载openpai组件和ks组件，检查之前的配置文件，重新安装 $ python paictl.py service [delete|start|stop] -c ~/.kube/config [-n name] # 卸载openpai组件 $ python paictl.py service delete -c ~/.kube/config # 卸载k8s组件 $ python paictl.py cluster k8s-clean -p ~/pai-config/ 启动Openpai $ python paictl.py service start -c ~/.kube/config 界面 http://&lt;master-ip&gt;:9090 http://&lt;master-ip&gt;:80 Reference https://github.com/kangapp/openPAI https://github.com/microsoft/pai https://zhuanlan.zhihu.com/p/64061072","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"openpai","slug":"openpai","permalink":"/tags/openpai/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"NVIDIA,CUDA,CUDNN,Anaconda","slug":"Ubuntu命令记录","date":"2020-01-11T12:32:00.000Z","updated":"2020-03-15T04:35:55.578Z","comments":true,"path":"2020/01/11/Ubuntu命令记录/","link":"","permalink":"/2020/01/11/Ubuntu命令记录/","excerpt":"","text":"NVIDIA,CUDA,CUDNN ppa安装NVIDIA驱动 $ sudo add-apt-repository ppa:graphics-drivers/ppa $ sudo apt-get update $ ubuntu-drivers devices $ sudo apt-get install nvidia-driver-xxx 自动安装NVIDIA驱动 # 卸载残余驱动 sudo apt-get --purge remove \"*nvidia*\" # 查看推荐驱动版本 ubuntu-drivers devices # 自动安装 sudo ubuntu-drivers autoinstall .deb安装CUDA 下载deb文件 $ sudo dpkg -i cuda-repo-ubuntu1604-10-0-local-10.0.130-410.48_1.0-1_amd64.deb $ sudo apt-get update $ sudo apt-get install cuda 安装CUDNN 下载符合自己cuda版本的cudnn 安装cudnn 安装过程实际是将cudnn的头文件复制到CUDA的头文件目录里 $ sudo cp cuda/include/* /usr/local/cuda-10.0/include/ $ sudo cp cuda/lib64/* /usr/local/cuda-10.0/lib64/ # 添加可执行权限 $ sudo chmod +x /usr/local/cuda-10.0/include/cudnn.h $ sudo chmod +x /usr/local/cuda-10.0/lib64/libcudnn* 检验 $ cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2 指定运行程序使用的GPU 在程序中添加 import os os.environ['CUDA_VISIBLE_DEVICES]='0' 或者在终端中 $ CUDA_VISIBLE_DEVICES=0 python main.py 命令行安装Anaconda $ wget https://repo.continuum.io/archive/Anaconda3-5.0.1-Linux-x86_64.sh $ bash Anaconda3-5.0.1-Linux-x86_64.sh # 添加环境变量，可选 $ echo 'export PATH=\"~/anaconda3/bin:$PATH\"' &gt;&gt; ~/.bashrc $ source .bashrc","categories":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}],"tags":[{"name":"nvidia","slug":"nvidia","permalink":"/tags/nvidia/"},{"name":"cuda","slug":"cuda","permalink":"/tags/cuda/"},{"name":"cudnn","slug":"cudnn","permalink":"/tags/cudnn/"},{"name":"anaconda","slug":"anaconda","permalink":"/tags/anaconda/"}],"keywords":[{"name":"瞎折腾","slug":"瞎折腾","permalink":"/categories/瞎折腾/"}]},{"title":"安利","slug":"安利区","date":"2020-01-11T02:48:00.000Z","updated":"2020-03-15T04:36:19.214Z","comments":true,"path":"2020/01/11/安利区/","link":"","permalink":"/2020/01/11/安利区/","excerpt":"","text":"一些软件 softdownloader: 一款布局清爽的下载工具 Fences: 桌面管理工具 copytranslator: 一款翻译软件 天若OCR文字识别 Snipaste: 一款简洁的截图和贴图软件 Mathpix: 每个月50次识别次数，快速识别图片中的公式，转化为 LaTeX\\LaTeXLATE​X 格式 Windows 的内置 Liunx 系统，支持 Linux 命令 TexStudio + Texlive 编辑LaTeX\\LaTeXLATE​X公式 Axmath: 个人感觉优于mathtype, Office中的公式编辑器 亿寻:百度云破解限速 Google浏览器插件 momentum: 浏览器壁纸标签页 LastPass: 密码记录插件 SwitchyOmega: 浏览器代理插件 OneTab: 标签页管理 一键管理扩展: 管理所有插件 AdblockPlus: 强烈安利，拦截广告 Read Viewer: 网页阅读模式 划词翻译 Tampermonkey:传说中的油猴 又在Github上找到个操作系统软件集合: Windows linux Mac","categories":[{"name":"安利","slug":"安利","permalink":"/categories/安利/"}],"tags":[{"name":"安利","slug":"安利","permalink":"/tags/安利/"}],"keywords":[{"name":"安利","slug":"安利","permalink":"/categories/安利/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-01-11T02:16:02.000Z","updated":"2020-03-15T04:19:40.002Z","comments":true,"path":"2020/01/11/hello-world/","link":"","permalink":"/2020/01/11/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick Start Create a new post $ hexo new \"My New Post\" More info: Writing Run server $ hexo server More info: Server Generate static files $ hexo generate More info: Generating Deploy to remote sites $ hexo deploy More info: Deployment","categories":[{"name":"其它","slug":"其它","permalink":"/categories/其它/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"/tags/hexo/"}],"keywords":[{"name":"其它","slug":"其它","permalink":"/categories/其它/"}]}]}